






DATA-DRIVEN
CONSTRUCTION

Навигация в эпоху данных 
в строительной отрасли




АРТЕМ БОЙКО








«If "data is the new oil", we need to learn to define it, find it, mine it, refine it, to make it valuable. I've found the book DataDrivenConstruction very informative and insightful. The book provides a useful historical background and explains working with data in plain language, For those who are interested in digital transformation, it gives a good understanding of data - how it works, how it is structured and how it can be used.» 
— Ralph Montague 
Director ARCDOX, Director BIM Coordinators Summit

«For anyone in the construction industry, from rookies to seasoned pros, this book is a game-changer! It's not your typical dusty read—it's packed with insights, strategies, and a touch of humor to keep you engaged. From ancient data recording methods to cutting-edge digital technologies, it covers the evolution of data usage in construction. It's like taking a time machine through the evolution of construction data—minus the wonky flux capacitor. Whether you're an architect, engineer, project manager or data analyst, this comprehensive guide will revolutionize the way you approach projects. Get ready to optimize processes, enhance decision-making, and manage projects like never before!»
— Pierpaolo Vergati 
Lecturer Sapienza Università di Roma, Senior Construction Project Manager at Fintecna

«I highly recommend DataDrivenConstruction book that addresses, as the title says, a data driven information management approach for AECO. I am currently using it to help initiate a number of discussions with various groups. I have found it a very accessible reference.  As well as a thorough overview of the history context of tools in AECO, data and introducing several key technologies the book contains a number of very useful diagrams, that outline the scope of data sources and end user artefacts with sample workflows. It strikes me that these are the types of diagrams we need more of when developing and monitoring information strategies and contribute to BEP's - defining the overall enterprise data model onto which the boundary for a PIM and AIM can be overlaid.»
— Paul Ransley
Principal Consultant at Acmena Systems Engineer at Transport for London


«As it was also emphasized in the book, information is a crucial asset for the construction sector, and having it in accessible formats greatly facilitates accurate decision-making and expedites project timelines. The book offers a neutral and efficient approach to accessing and taking advantage of this source in decision-making. The methodology presented in the book leverages a contemporary approach that combines artificial intelligence-driven programming with accessible open-source tools. By harnessing the power of AI and utilizing open-source software, the methodology aims to enhance automation, optimize processes, and promote accessibility and collaboration within the field. The language of the book is clear and easy to follow.»

— Salih Ofluoğlu
Dean, Faculty of Fine Arts and Architecture, Antalya Bilim University


«All I can say is, WOW! The way you incorporated history, ChatGPT, the graphics, and the overall ease of understanding your points is truly remarkable. The flow of the book is amazing. There are so many brilliant aspects to this book; it’s genuinely a game-changer. It’s a great source of information, and I commend you for the effort and passion you’ve put into it. Congratulations on creating such a remarkable work. I could go on, but suffice it to say, I’m incredibly impressed!»

— Natasha Prinsloo
BIM Coordinator at energylab_ 



«I read the book in one breath, in less than 6 hours. The presentation of information is as simple as possible, but for deep perception and coverage of the materials requires an expanded horizon of knowledge from the construction and IT industries. The manufacturing quality of the book is excellent, dense glossy paper, color schemes, a pleasant font. The large number of practical examples on how to work with ChatGPT specific to the construction industry will save you months, if not years, of self-study. Work examples are very diverse, ranging from simple to complex, without requiring you to purchase complex and expensive software. The book will allow owners of any business in the construction industry to take a fresh look at their business strategy, digitalization and development prospects. And for smaller companies to increase efficiency with affordable and free tools.»

— Mikhail Kosarev
TIM-ASG | Digital transformation expert

"DATA DRIVEN CONSTRUCTION," is a game-changer for anyone curious about where the construction industry is headed in the age of data. Whether you're deeply involved in construction or simply intrigued by its evolution, this book offers a captivating exploration of how technology is reshaping the field. Artem doesn't just scratch the surface; he delves deep into the current developments, challenges, and promising opportunities in construction. What sets this book apart is its accessibility—Artem explains complex ideas using relatable analogies that make the content easy to grasp. I found the book to be incredibly informative yet engaging. It's clear that Artem has a profound understanding of both the industry and the transformative power of data analytics. His writing style is approachable yet authoritative, making "DATA DRIVEN CONSTRUCTION" a must-read for anyone looking to stay ahead in this rapidly changing landscape. In summary, Artem has crafted a valuable resource that not only informs but also inspires. Whether you're a seasoned professional or a newcomer to construction, this book will broaden your perspective and deepen your understanding of where the industry is heading. Highly recommended!
— Moayad Saleh
BIM Manager at TMM GROUP Gesamtplanungs GmbH

«DataDrivenConstruction book is one of the first steps beyond the boundaries of the usual world of builders, with their complex design and management systems, when, it would seem, the complexity and saturation of data does not even give a chance for radical simplification and increased transparency of work with construction data. In his book, Artem shows in simple language what opportunities modern technologies of working with data open before us, and literally gives concrete steps that you can immediately apply in your work. I urge everyone who wants to understand where automation systems will go in the construction industry to study this small book carefully in order to realize that the data revolution in construction is already knocking on our door. It's only of interest to geeks now, but in a few years, like BIM, such approaches and software will be ubiquitous!»
— Ihor Rogchew
Head of IMT Competence Center at RGD, Head of InfraBIM.Pro portal


«I should say that Data-Driven Construction is worthy of being taught as a textbook in universities and is a book that will make valuable contributions to the developing BIM field. Data-Driven Construction book contains a technical glossary that explains the concepts very well. Topics that are extremely difficult to explain are made simple and understandable with a very beautiful visual language. I think that what is intended to be explained in the visuals should be expressed to the reader, even if briefly. The comprehensibility of some visuals, in other words, reading the visual requires separate information. I would also like to say that I am happy to introduce Artem Boiko's valuable work in my lectures and seminars at universities.»

— Ediz Yazicioglu
Owner ArchCube



Первое издание, март 2024 г. 
© 2024 | Артем Бойко | Карлсруэ

ISBN 978-3-9826255-9-1




Английская версия: ISBN 978-3-00-078229-9
Немецкая версия: ISBN 979-8-8845-9082-3

Артем Бойко Авторские права
boikoartem@gmail.com
info@datadrivenconstruction.io

Все права защищены. Никакая часть этой книги не может быть воспроизведена или передана в любой форме или любыми средствами, электронными или механическими, включая фотокопирование, запись или любую систему хранения и поиска информации, без письменного разрешения автора, за исключением кратких цитат в рецензии. 
Автор тщательно подошел к подготовке этой книги, но не дает никаких явных или подразумеваемых гарантий и не несет ответственности за ошибки или упущения. Автор не несет ответственности за случайные или косвенные убытки в связи с использованием информации, кода или программ, содержащихся в этой книге.
Все торговые марки и названия продуктов являются торговыми марками, зарегистрированными торговыми марками или знаками обслуживания соответствующих компаний, являются собственностью их соответствующих владельцев и должны рассматриваться как таковые. Несмотря на то что при подготовке этой книги были приняты все меры предосторожности, автор не несёт никакой ответственности за ошибки или упущения, а также за ущерб, возникший в результате использования содержащейся в ней информации











 

 С искренней благодарностью я посвящаю эту 
книгу своей семье, которая с ранних лет привила 
мне глубокую любовь к строительству, и моей жене, 
чья неизменная поддержка была моим 
постоянным вдохновением.

ДЛЯ КОГО ЭТА КНИГА

Написанная доступным языком, эта книга рассчитана на широкий круг читателей в строительной отрасли - от студентов и новичков, желающих постичь основы современных строительных процессов, до профессионалов, стремящихся углубить свое понимание управления данными и новых инструментов работы с ними. Будь вы архитектором, инженером, прорабом, менеджером по строительству или аналитиком данных, это всеобъемлющее руководство с множеством уникальных иллюстраций и графиков предлагает ценные сведения о том, как использовать данные в бизнесе для оптимизации и автоматизации процессов, улучшения процесса принятия решений и управления строительными проектами на разных уровнях с помощью современных инструментов.



КРАТКИЙ ОБЗОР ЧАСТЕЙ КНИГИ

Эта книга построена вокруг идеи движения данных в цепочке создания ценности. Сначала рассматриваются сами данные: история появления, как выбрать надежные источники и обеспечить их качество. Затем внимание переключается на их анализ и извлечение полезных инсайтов с рассмотрением популярных инструментов и концептов по работе с данными.
Начало формы
Часть 1: от зарождения данных в строительстве до цифровой эпохи - исследует историческое развитие использования данных в строительстве, начиная с древних методов записи данных и заканчивая появлением цифровых технологий и ERP-систем.

Часть 2: типы данных, системы и инструменты, используемые в строительной отрасли - посвящена различным типам данных, относящимся к строительству, и знакомит с инструментами и структурами для эффективного управления данными.

Часть 3: использование данных в бизнес-процессах - рассказывает о практическом применении данных в строительных бизнес-процессах, включая расчет стоимости проекта, составление смет, составление графиков и расчет "углеродного следа", а также показывает, как выглядят процессы, основанные на данных, и как они меняют способы принятия решений в компаниях.

Часть 4: аналитика, автоматизация и машинное обучение - рассматривает строительный бизнес через призму аналитики данных, автоматизации, ETL-процессов, использования машинного обучения и того, как современные подходы к хранению и обработке данных меняют управление проектами в строительной отрасли.

Книга не содержит сложных технических вычислений, но затрагивает практические аспекты работы с данными в строительстве. Основная цель — сформировать глубокое понимание современных методов управления информацией, а не просто дать общий обзор. Изложение построено так, чтобы материал был понятен и применим на практике.

Основная цель книги — показать, как использовать данные для решения ключевых задач в строительстве и управлении проектами. Она помогает взглянуть на бизнес-процессы с точки зрения данных и освоить принципы их анализа для принятия более точных и обоснованных решений.

В книге раскрывается фундаментальная структура аналитического мышления, основанного на данных, и ключевые принципы работы с информацией, которые необходимы для оптимизации процессов, прогнозирования рисков и повышения эффективности в строительной отрасли.



ДРУГИЕ НАВЫКИ И КОНЦЕПЦИИ

Помимо ключевых принципов работы с данными в строительной отрасли, в книге "DataDrivenConstruction" рассматривается широкий спектр дополнительных концепций и навыков, которые необходимы специалисту, работающему с данными. В Части II подробно разбираются такие темы, как обработка структурированных и неструктурированных данных, работа с Pandas DataFrame, автоматизация процессов с помощью LLM и ChatGPT, преобразование данных в структурированную форму и стандартизация данных в строительстве.
Заинтересованный читатель может посетить веб-сайт книги DataDrivenConstruction.io, где представлены ссылки на дополнительные материалы по ключевым навыкам: работа с Python и Pandas, обработка данных в строительных проектах CAD, и системы обработки больших данных, а также современные подходы к визуализации и аналитике строительных данных.

При подготовке книги "DataDrivenConstruction" и всех практических примеров использовалось много инструментов и программного обеспечения с открытым исходным кодом. Автор выражает благодарность разработчикам и соавторам следующих решений:
• Python и Pandas – основа работы с данными и автоматизации
• Scipy, Numpy, Matplotlib и Scikit-Learn – библиотеки для анализа данных и машинного обучения
• SQL и Apache Parquet – инструменты для хранения и обработки больших объемов строительных данных
• IfcOpenShell и BIM Data Tools – работа с CAD/BIM-данными в открытых форматах
• DeepSeek, LlaMa – OpenSource LLM модели
Рекомендуем читателям следить за обновлениями книги, новыми главами, исправлениями и дополнительными материалами на сайте DataDrivenConstruction.io, где также публикуются обучающие слайды и примеры практического применения.






ВВЕДЕНИЕ

Как долго ваша компания сможет оставаться на плаву в мире, где технологии стремительно меняются, и где каждый аспект бизнеса, включая расчёты времени и стоимости может быть автоматизирован при помощи моделей машинного обучения? 
Строительная отрасль, существующая столько же, сколько само человечество, стоит на пороге революционных изменений, которые обещают полностью изменить наши представления о традиционном строительстве. Мы уже наблюдаем, как в других секторах экономики цифровая трансформация не просто меняет правила игры, но и безжалостно вытесняет тех, кто не смог адаптироваться к новым реалиям работы с данными и увеличить скорость принятия решений в компании.

   Рисунок 1–1. Скорость принятия решений в строительной отрасли чаще чем в других отраслях зависит от человеческого фактора 

Банковский сектор, розничная торговля, логистика и агропромышленный комплекс стремительно движутся к полной цифровизации, где больше нет места неточностям и субъективным мнениям. Современные алгоритмы способны анализировать колоссальные массивы данных и предоставлять клиентам точные прогнозы – будь то вероятность возврата кредита, оптимальные маршруты доставки или лучшее время для сбора урожая.
Очевидно, что строительство — одна из последних отраслей, неизбежно переходящих от решений, основанных на мнении высокооплачиваемых сотрудников, к принятию решений на основе данных. Роботизация, автоматизация процессов, открытые данные и прогнозы на их основе — всё это уже не просто возможности, а неизбежность. Большинство компаний строительной отрасли, которые ещё недавно отвечали перед клиентов за расчёты объемов, стоимости проектов и качество, теперь рискуют превратиться в безмолвных исполнителей, не принимающих ключевых решений.
 
   Рисунок 1–2. Клиент не заинтересован в избыточном человеческом факторе на пути к своему объекту
С развитием вычислительных мощностей и алгоритмов машинного обучения стало возможным автоматическое объединение данных из разных источников, что позволяет глубже анализировать процессы, прогнозировать риски и оптимизировать затраты ещё на этапах обсуждения строительного проекта. 
Переход к бизнес-процессам, основанным на данных, будет сложным и долгим. Многие строительные компании так и не достигнут этого уровня, поскольку управленцы не смогут понять, как превратить хаотичные массивы данных в мощные инструменты для роста и повышения эффективности.
Быстрый рост объема данных и сложности процессов уже становится головной болью для руководства компаний, и главная проблема заключается в том, что данные, несмотря на их обилие, остаются разрозненными, неструктурированными и зачастую несовместимыми между различными системами и программными продуктами.
Решение проблем, связанных с интеграцией данных в бизнес-процессы, заключается в обеспечении высокого качества информации, использовании подходящих форматов данных и применении эффективных методов создания, хранения, анализа и обработки данных.
В мире управления и менеджмента данные являются стратегическим активом и фундаментальным ресурсом, который питает и направляет процессы компаний. Только качественные и проверенные данные способствуют эффективности и точности в принятии решений.

   Рисунок 1-3. Данные и процессы являются основополагающими для управления проектами и принятия решений 
Осознание ценности данных заставляет различные отрасли отказаться от разрозненных приложений и сложных бюрократических структур управления. Вместо этого акцент смещается на создание новых подходов к информационной архитектуре, превращающих компании в современные предприятия, управляемые данными. Этот же логический шаг рано или поздно сделает и строительная отрасль, перейдя от цифровой эволюции к цифровой революции, которая затронет все компании отрасли.
Строительная отрасль - одна из немногих сфер экономики, которая последней приступила к процессу цифровой трансформации.
По-настоящему понять сложную концепцию — значит уметь объяснить ее простыми словами, несмотря на присущую ей сложность. Именно поэтому данная книга намеренно написана простым языком и снабжена иллюстрациями по каждой теме, что делает ее доступной для тех, кому ранее подобные темы казались слишком запутанными или сложными. Все иллюстрации, схемы и графики в этой книге созданы автором и разработаны специально для визуализации ключевых концепций, описанных в тексте.
Чтобы совместить теоретические термины с практическими реализациями, мы будем использовать LLM чаты - помощники, которые будут разрабатывать решения за нас, не погружаясь в код и термины программирования.
В этой книге мы погрузимся в мир данных, где информация является стратегическим активом, который питает и направляет бизнес-процессы компании. Мы увидим, как компании преодолевают проблемы, связанные с информационным взрывом, и как цифровая трансформация становится не просто новым трендом, а необходимостью. От анализа различных типов данных и методов их обработки до разработки уникального "технологического принтера", способного автоматически создавать документы и прогнозы, - эта книга откроет для вас новую эру управления и обработки данных в строительстве, когда данные и технологии будут эффективно работать на ваш бизнес.
Однако, чтобы извлечь ценные знания, необходимо не только собрать релевантные данные, но и обеспечить их достоверность, провести качественный анализ, учитывать полученные инсайты при принятии решений и предпринять конкретные шаги для реализации выявленного потенциала.
"Подход, основанный на данных, — это не продукт, который можно просто купить. Это стратегия, которую нужно выстроить. Она начинается с нового взгляда на существующие процессы и проблемы, а затем требует дисциплинированного движения в выбранном направлении.
Эта ваш шанс не только переждать грядущую бурю датафикации, но и взять ее под контроль. В книге вы найдете не просто анализ текущего состояния отрасли, но и конкретные рекомендации по переосмыслению и реструктуризации вашего бизнеса, чтобы стать лидером в новой эре строительства. 
Остается вопрос: готовы ли вы к завтрашнему дню?




Contents
ЧАСТЬ I  ОТ РОЖДЕНИЯ ДАННЫХ ДО ЦИФРОВОЙ ЭПОХИ  В СТРОИТЕЛЬСТВЕ	17
Рождение эры данных в строительстве	1
От глины и папируса до цифровых технологий	2
Цифровая революция и появление ERP-систем	3
Процесс как инструмент опыта, управляемого данными	5
Опастность мнения в процессах компании	9
Датафикация и дижитализация строительного процесса	12
Данные как главный двигатель технологий	15
ГЛАВА 1.2  ТЕХНОЛОГИИ И СИСТЕМЫ УПРАВЛЕНИЯ В СОВРЕМЕННОМ СТРОИТЕЛЬСТВЕ	18
От бизнес-проблем к задачам добычи данных	18
Системы управления данными	18
Управление данными и интеграция информационных потоков	22
REV Начало бума объемов данных	25
REV Объем данных, генерируемых в современной компании	27
Стоимость хранения данных: экономический аспект	30
Границы накопления данных	31
Данные — новое золото в строительстве	33
Сбор данных в строительстве: От хаоса к структуре	35
Дилемма данных: качество против количества	39
Силосы данных	43
Снижение сложности	47
         ЧАСТЬ II   ТИПЫ ДАННЫХ, СИСТЕМЫ И ИНСТРУМЕНТЫ, ИСПОЛЬЗУЕМЫЕ В СТРОИТЕЛЬНОЙ ОТРАСЛИ	49
ГЛАВА 2.1  ТИПЫ ДАННЫХ В СТРОИТЕЛЬСТВЕ	50
REV Наиболее важные типы данных в строительной отрасли	50
Структурированные данные	56
Реляционная база данных RDBMS и язык запросов SQL	58
Неструктурированные данные	61
Текстовые данные	62
Полуструктурированные данные	64
Геометрические данные	66
REV BIM-данные и концепция BOM-BIM	68
ГЛАВА 2.2  ДОМИНИРОВАНИЕ ОТКРЫТЫХ ДАННЫХ	76
Хранилище данных	76
Наполнение систем данными в строительной отрасли	76
Различия в объемах данных	78
REV Появление семантики и онтологии в строительстве	80
REV Семантика и онтология: как заставить данные говорить?	83
REV От графов к таблицам: трудозатраты в группировки и фильтрации	86
REV Открытые структурированные данные	88
ГЛАВА 2.3  PANDAS DATAFRAME И LLM CHATGPT	92
Pandas: незаменимый инструмент для работы с данными	92
DataFrame: универсальный формат табличных данных	93
LLM и ChatGPT для автоматизации процессов обработки данных	98
LLM без передачи данных во вне и OpenSource	100
RAG	104
Выбор IDE: Погружение в ИИ и LLM через Практику	104
От индустриальной революции к революции данных: параллели и перспективы	107
ГЛАВА 2.4  ПРЕОБРАЗОВАНИЕ ДАННЫХ В СТРУКТУРИРОВАННУЮ ФОРМУ	110
REV Преобразование неструктурированных данных в структурированные	110
Пример преобразования PDF-документа в таблицу	112
Преобразование изображения в структурированную форму	116
Преобразование текстовых данных в структурированную форму	120
REV Перевод данных САПР (BIM) в структурированную форму	123
REV Что за данные хранятся в CAD	132
REV Где рождается БИМ или любая CAD (BIM) программа — это компилятор данных, визуализирующий геометрию через геометрическое ядро	133
ГЛАВА 2.5  МОДЕЛИРОВАНИЕ ДАННЫХ И ПОЯВЛЕНИЕ СТАНДАРТОВ  Скорость принятия решений	150
Стандартизация и интеграция данных о строительстве	151
Появление требований к данным	154
Моделирование данных: концептуальная, логическая и физическая модель	156
Центр передового опыта (COE) по моделированию данных	160
Создание базы данных с помощью ChatGPT	164
ГЛАВА 2.6  ТРЕБОВАНИЯ К КАЧЕСТВУ ДАННЫХ И ЕГО ОБЕСПЕЧЕНИЕ	168
Сбор и анализ требований: основные участники	168
REV Блок-схемы процессов и эффективность концептуальных схем	172
Структурированные требования и регулярные выражения RegEx	177
Сбор данных для проверки	183
Проверка данных и результаты проверки	186
Визуализация результатов проверки	191
         ЧАСТЬ III   РАСЧЁТЫ НА ОСНОВЕ ДАННЫХ И ДАННЫЕ В БИЗНЕС-ПРОЦЕССАХ	194
ГЛАВА 3.1  РАСЧЕТЫ СТОИМОСТИ И СМЕТЫ СТРОИТЕЛЬНЫХ ПРОЕКТОВ	195
Основы строительства: оценки количества, стоимости и времени	195
Методы расчета сметной стоимости проектов. Ресурсный метод	196
База данных строительных ресурсов	198
Статьи калькуляции и состав работ	199
Составление сметы расходов на проект	203
ГЛАВА 3.2  QUANTITY TAKE-OFF И АВТОМАТИЧЕСКОЕ СОЗДАНИЕ СМЕТ И ГРАФИКОВ РАБОТ	207
3D-интеграция: 5D стоимость и 4D время	207
Атрибуты 5D и получение объемов атрибутов из САПР (BIM)	208
QTO Quantity Take-Off: группировка данных по атрибутам	209
QTO группировка атрибутов структурированных данных САПР (BIM)	214
QTO расчеты по проекту с использованием правил из таблицы Excel	218
ГЛАВА 3.3  4D, 6D-8D И РАСЧЕТ ВЫБРОСОВ УГЛЕКИСЛОГО ГАЗА CO2	224
Ввод данных о последовательности и расчёт оценки времени выполнения работ в строительном проекте	224
Графики строительства и данные 4D-проекта	225
Расширенные атрибутивные слои 6D-8D: от энергоэффективности до обеспечения безопасности	228
Оценка CO2 и расчет выбросов углекислого газа в строительных проектах	230
ГЛАВА 3.4  СТРОИТЕЛЬНАЯ ERP СИСТЕМА	235
REV Строительные ERP-системы на примере расчетов и смет	235
Мультимодульность строительных ERP-систем	243
Спекуляции, прибыль, закрытость и отсутствие  прозрачности ERP	245
ERP или всё же DWH и дата аналитика	247
ГЛАВА 3.5  ПРОБЛЕМЫ РАБОТЫ С ДАННЫМИ В СТРОИТЕЛЬНОЙ ОТРАСЛИ	249
Проблема закрытых и проприетарных данных	249
REV Существует ли BIM, openBIM, BIM 3 level, noBIM на самом деле или это маркетинговый трюк?	253
REV Миф о интероперабельности CAD	265
Проблема неоднородности данных	275
Постоянное повышение сложности и динамичности бизнес-процессов	278
Четвертая промышленная революция (Индустрия 4.0) и пятая промышленная революция (Индустрия 5.0) в строительстве	283
          ЧАСТЬ IV   ПРИНЯТИЕ РЕШЕНИЙ  НА ОСНОВЕ ДАННЫХ, АНАЛИТИКА, АВТОМАТИЗАЦИЯ И МАШИННОЕ ОБУЧЕНИЕ	287
ГЛАВА 4.1  АНАЛИТИКА ДАННЫХ И  ПРИНЯТИЕ РЕШЕНИЙ НА ОСНОВЕ ДАННЫХ	288
Принятие решений на основе данных	288
Визуализация данных	290
Показатели KPI и информационные панели	293
Аналитика и анализ данных	298
Titanic dataset is Hello World в мире аналитики данных и больших данных	300
ГЛАВА 4.2  ETL И АВТОМАТИЗАЦИЯ ПРОЦЕССОВ	302
ETL: переход от ручного управления к автоматизации	302
ETL Extract: сбор данных	307
ETL Transform: применение правил проверки и трансформации	309
ETL Load: Визуализация результатов в виде диаграмм и графиков	312
ETL Load: Автоматическое создание PDF-документов	316
ETL Load: Составление отчетов и загрузка в другие системы	318
ETL с помощью ChatGPT: Визуализация данных из PDF-документов	319
REV DAG и Apache Airflow: автоматизация и оркестрация рабочих процессов	324
REV Apache Nifi для маршрутизации и преобразования данных	328
ГЛАВА 4.3  АВТОМАТИЧЕСКИЙ ETL КОНВЕЕР (PIPELINES) ДЛЯ ВАЛИДАЦИЯ ДАННЫХ   Автоматический конвейер данных -ETL	330
REV Процесс проверки данных Pipeline-ETL с помощью ChatGPT	332
Pipeline-ETL: проверка данных и информации элементов проекта в САПР (BIM)	335
Новые концепции ETL - AIA, BEP, IDS, LOD, COBie	339
Сравнение проверок качества данных с жизненными потребностями человека	343
ГЛАВА 4.4  СОВРЕМЕННЫЕ ТЕХНОЛОГИИ РАБОТЫ С ДАННЫМИ В СТРОИТЕЛЬНОЙ ОТРАСЛИ	347
Форматы хранения данных и работа с Apache Parquet	347
REV DWH хранилища данных и архитектура Data Lakehouse	352
Проблемы озёр данных	356
REV Облачные решения, SaaS, CRUD b	358
REV ые базы данных - DataOps и VectorOps	360
Управления данными (Data Governance), минимализм данных (Data Minimalism) и болота данных (Data Swamp)	364
REV Lowcode- no code	367
REV Параметрическое создание проектов	367
IOT Интернет вещей и смарт-контракты	368
REV Большие данные	371
Статистика	373
Применение больших данных в строительстве	374
Большие данные: анализ данных датасета миллиона разрешений на строительство Сан-Франциско	376
Пример больших данных на основе данных САПР (BIM)	383
ГЛАВА 4.5  БУДУЩЕЕ: ПРОГНОЗЫ И МАШИННОЕ ОБУЧЕНИЕ	390
BlackRock: Машинное обучение и искусственный интеллект изменят то, как мы работаем и как строим	390
Предсказания и прогнозы на основе исторических данных	394
REV Ключевые концепции машинного обучения	397
Пример использования машинного обучения для нахождения стоимости и сроков проекта	399
Прогноз стоимости и времени проекта при помощи линейной регрессия и ChatGPT	402
Прогнозы стоимости и времени проекта при помощи алгоритма K-nearest neighbor (k-NN)	405
Глава 5. Угрозы строительному бизнесу и что делать	410
REV Уберизация и открытые данные это угроза для строительного бизнеса	410
REV С ЧЕГО СТОИТ НАЧАТЬ	415
Культура	415
REV ЗАКЛЮЧЕНИЕ	426
ОБ АВТОРЕ	431
ОТЗЫВЫ ЧИТАТЕЛЕЙ	433
ССЫЛКИ	434
Bibliography	435





























ЧАСТЬ I 
ОТ РОЖДЕНИЯ ДАННЫХ ДО ЦИФРОВОЙ ЭПОХИ 
В СТРОИТЕЛЬСТВЕ
ГЛАВА 1.1 
ЭВОЛЮЦИЯ ИСПОЛЬЗОВАНИЯ ДАННЫХ В СТРОИТЕЛЬНОЙ ОТРАСЛИ
Рождение эры данных в строительстве
О
коло 10 000 лет назад, в эпоху неолита, человечество совершило революционный переход в своем развитии, отказавшись от кочевого образа жизни в пользу оседлости, что привело к появлению первых простых построек из глины, дерева и камня [1]. С этого момента начинается история строительной индустрии.
По мере развития цивилизаций архитектура становилась все более сложной, что привело к появлению первых ритуальных храмов и общественных зданий. Усложнение архитектурных проектов потребовало от инженеров и управленцев древности создания первых записей и расчетов. Первые записи на глиняных табличках и папирусах часто включали описание логики расчета количества необходимых строительных материалов, их стоимости и расчета оплаты выполненной работы [2]. Так зародилась эра использования данных в строительстве.

   Рисунок 1.1-1. Переход к сидячему образу жизни повлиял на развитие строительства, архитектуры и первых проектных данных
От глины и папируса до цифровых технологий
П
ервые документальные свидетельства в строительстве относятся к периоду возведения пирамид, около 3000-4000 гг. до н.э. [2]. С тех пор ведение письменных записей облегчало и сопровождало прогресс в строительной отрасли, позволяя накапливать и систематизировать знания, которые в течение последующих 10 000 лет привели к значительным инновациям в методах строительства и архитектуре.
Использование первых физических носителей в строительстве, таких как глиняные таблички, папирус тысячелетней давности или бумага формата А0, для записи данных изначально не предполагало применения этой информации в новых проектах. Основной целью таких записей было подробное описание текущего состояния проекта, включая расчеты необходимых материалов и стоимости работ. Точно так же в современном мире наличие цифровых проектных данных и моделей не всегда гарантирует их применение в будущих проектах и также часто служит в основном в качестве информации для текущих расчетов необходимых материалов и стоимости строительства.
   

Рисунок 1.1-2. Папирус III века до н. э., описывающий стоимость 
росписи различных типов окон в королевском дворце с 
использованием техники энкаустики
Как торговые и денежные отношения в свое время способствовали развитию письменности и созданию первых юридических документов, так и первые записи о стоимости материалов и объемах работ в строительстве привели к появлению первых менеджеров в строительной отрасли, в обязанности которых входило документирование, мониторинг и ответственность за ключевую информацию о сроках и стоимости проекта.
Человечеству потребовалось около 5 000 лет, чтобы перейти от устных разговоров к письменным документам в управлении строительными проектами, и столько же времени, чтобы перейти от ведения записей на физических носителях к использованию цифровой информации.
Сегодня данные не только фиксируют прошлые решения, но и становятся инструментом предсказания будущего. Именно на этом принципе строится процессный подход в управлении проектами – превращение накопленного опыта в структурированную систему принятия решений.

Процесс как инструмент опыта, управляемого данными
В основе любого процесса лежит трансформация прошлого опыта в инструмент планирования будущего. Опыт в современном понимании представляет собой структурированный набор данных – пары "параметр-значение", хранящиеся например в списках, словарях или базах данных. 
Именно анализ исторических данных позволяет делать обоснованные прогнозы и принимать взвешенные решения.
Рассмотрим конкретный пример из монолитного строительства: при планировании сроков учитываются объем бетона, сложность конструкции и погодные условия. Если исторические данные компании показывают, что на заливку 200 кубометров бетона в дождливую погоду требовалось 5 дней, эта информация становится основой для калькуляций ресурсов аналогичных работ в будущих проектах (рис. 1.1-3).
Данные и процессы – это единая экосистема, где одно не может существовать без другого. Процесс выступает как механизм преобразования разрозненных данных в структурированный опыт, а затем – в точный инструмент планирования.
Когда процессы интегрируются в структуру организации, критически важные знания перестают быть привязанными к конкретным личностям. Носителем экспертизы становится вся организация, а не отдельные, пусть даже высококвалифицированные специалисты.


   Рисунок 1.1-3. Исторические данные выступают как тренировочный набор данных для предсказания одной из величин
В информационном обществе данные играют ту же роль, что и топливо в индустриальной экономике. Они питают инновации, ускоряют развитие технологий и становятся основой продуктивности. 
Данные становятся ключевым инструментом прогнозирования и оптимизации. Они позволяют заранее видеть тенденции, снижать риски и повышать эффективность в различных сферах. Многие компании говорят, что они ориентированы на данные, но это не всегда означает, что их решения действительно зависят от данных. Именно компании, использующие аналитические методы, получают значительное конкурентное преимущество, так как их решения основаны не на предположениях, а на фактах.
Без доступа к качественным данным и эффективным инструментам их обработки творческий и экономический потенциал компании снижается. Чем богаче информационная среда, тем больше возможностей для прогресса, автоматизации и интеллектуального роста.
Современная наука всё больше подтверждает, что информация — основа реальности. Принцип Ландауэра связывает её с энергией, а идея Уилера «It from Bit» [3] утверждает, что всё в мире сводится к бинарным решениям. Квантовая физика и голографическая теория подтверждают, что информация управляет материей. Так и бизнес которым управляют, создания состоящие из октиллиона молекул, управляемых ДНК - также построен на бинарных решениях.

   Рисунок 1.1-4. Данные являются фундаментом бизнеса, который в свою очередь основан на процессах принятия решений
Быть управляемым данными – значит использовать данные как основу для принятия решений. В таких компаниях ключевую роль играет анализ и доказательства, полученные из данных.
В условиях информационного общества данные становятся не просто вспомогательным инструментом, а основой принятия решений, прогнозирования и оптимизации. Однако их ценность особенно проявляется в отраслях, где традиционно доминировали аналоговые процессы и интуитивные методы управления. Одной из таких сфер является строительство, где цифровая трансформация приводит к кардинальным изменениям в подходах к проектированию, управлению и эксплуатации объектов.
Этот процесс получил название датафикации — превращения различных аспектов строительного процесса в цифровую форму, пригодную для анализа. Сегодня строительная отрасль сталкивается с лавинообразным ростом данных, охватывающих все этапы жизненного цикла проекта — от проектной документации и расчетов до данных с датчиков и автоматизированных систем управления.

Датафикация и дигитализация строительного процесса 
На протяжении тысячелетий объём записываемой в строительстве информации почти не менялся, но за последние десятилетия он вырос стремительно. Ежедневно серверы заполняются проектной документацией, графиками работ, расчётами и калькуляциями и финансовыми отчётами. Для 2D/3D-чертежей применяются DWG, DXF и DGN, а для 3D-моделей — RVT, NWC, PLN и IFC. Текстовые документы, таблицы и презентации сохраняются в DOC, XLS и PPT. Дополнительно к видео и изображениям со строительной площадки — в MPG и JPEG, в реальном времени поступают данные от RFID-меток (идентификация и отслеживание) и систем управления зданиями BMS (мониторинг и контроль).
В современном мире, все более ориентированном на данные, строительная отрасль переживает период так называемой «датафикации» — процесса превращения различных аспектов реальности в цифровой формат, пригодный для анализа. 
Датафикация означает получение информации обо всех cущностях и элементах строительного проекта и самого строительного процесса - включая те, которые мы раньше вообще не считали информацией - и преобразование ее в формат данных, чтобы сделать ее количественно измеримой и удобной для анализа.
В контексте строительства это означает фиксацию информации обо всех элементах проектов и всех процессов — от перемещения техники и людей на строительной площадке до климатических условий на объекте и процентной ставки центрального банка — с целью формирования аналитических моделей.

Рисунок 1.1-2. Параболический рост количества данных связан
[ https://x.com/SkanskaUSA/status/1720167220817588714/photo/1]
Современные технологии упростили сбор данных: информация фиксируется автоматически, зачастую без участия человека. При этом стоимость хранения настолько низка, что компании предпочитают сохранять весь массив данных, вместо того чтобы изначально отбирать только важную информацию.
Датафикация выходит за рамки традиционного сбора данных, когда фиксировались лишь ключевые показатели вроде отработанных человеко-часов или фактических затрат на материалы. Теперь любое явление способно превратиться в поток информации, который затем можно анализировать с помощью аналитики данных и машинного обучения. 
Еще недавно отрасль полагалась на бумажные чертежи, сметы в Excel и устные инструкции, но сегодня каждый объект и в том числе люди в инженерных отделах и на строительной площадке могут быть представлены в виде переменных, значений и массива данных. 
При правильном подходе данные нужно грамотно использовать повторно и превратить их в фонтан инноваций и новых услуг.
В будущем датафикация в строительстве, вероятно, приведет к полному отказу от бумажной отчетности, внедрению самоуправляемых строительных процессов и возникновению новых профессий — специалистов по аналитике  данных строительных объектов, экспертов по AI-управлению и цифровых инженеров. Датафикация превратит строительные объекты в источники данных, позволяя принимать решения на основе объективных фактов, а не субъективных предположений. 
Датафикация и дигитализация позволит нам раскрыть неявную, скрытую ценность информации, которой мы раньше пренебрегали. 
Те, кто первыми адаптируются к этим изменениям, получат конкурентное преимущество в стремительно развивающемся мире цифрового строительства.
По мере ускорения датафикации и увеличения объема данных руководство проектов сталкивается с необходимостью хранить и обрабатывать огромный объем информации, описанный в бумажных документах и чертежах, требующих подписей, регулярного просмотра и архивирования в офисных шкафах. В ответ на эту проблему, начиная с середины 1990-х годов, компании строительной отрасли стали массово переходить на электронное создание и хранение документов, электронных таблиц и чертежей.

ГЛАВА 1.2 
ТЕХНОЛОГИИ И СИСТЕМЫ УПРАВЛЕНИЯ В СОВРЕМЕННОМ СТРОИТЕЛЬСТВЕ
Начало формыКонец формы
Цифровая революция и появление ERP-систем
Н
овая эра современного хранения и обработки данных началась с появлением в 1950-х годах магнитной ленты, открывшей возможность хранения и использования больших объемов информации. Следующим прорывом стало появление дисковых накопителей, которые радикально изменили подход к управлению данными в строительной отрасли. 
С развитием хранилищ данных на рынок решений вышло большое количество компаний, которые начали разрабатывать программное обеспечение для создания, хранения, обработки данных и автоматизации рутинных задач.  
Экспоненциальный рост объема информации и инструментов привел к необходимости разработки интегрированных решений, которые не работают с отдельными файлами, а помогают управлять и контролировать поток данных в рамках разных проектов.
Первые комплексные инструменты платформы должны были не только хранить документы, но и документировать все запросы на изменения и операции в процессах: кто их инициировал, каков был объем запроса и что в итоге было записано в виде значения или атрибута. Для этих целей требовалась система, которая могла бы отслеживать точные расчеты и принятые решения. Такими платформами стали первые системы MRP (Material Requirements Planning) и ERP (Enterprise Resource Planning), получившие популярность в начале 1990-х годов [3]. 

   Рисунок 1.1-3. Достижения в области технологий хранения данных привели к появлению ERP-систем в 1980-х годах
Первые MRP- и ERP-системы заложили основу для эпохи цифровизации в управлении бизнес-процессами и строительными проектами. MRP- и ERP-системы, изначально предназначенные для автоматизации ключевых бизнес-процессов, со временем стали интегрироваться с дополнительными, более гибкими и адаптивными программными решениями. 
Эти дополнительные решения были предназначены для обработки данных и управления содержанием проектов (рис. 1.1-4), они либо заменяли определенные модули ERP-систем, либо эффективно дополняли их, расширяя функциональность всей системы.


   Рисунок 1.1-4. Новые программные решения привлекли в бизнес целую армию менеджеров для управления потоками данных
Компании, инвестируя сотни тысяч евро в ERP- или CRM-системы, воспринимают их как долгосрочные решения, хотя на деле они временны. В идеале такие вложения не нужны вовсе, но если деньги уже потрачены, важно признать их невозвратными и двигаться дальше.
Одна из причин глубокой интеграции прикладных систем — их контроль над данными. Во многих компаниях данные зависят от приложений, а не наоборот. В ориентированных на данные подходах всё иначе: данные — главный актив, независимый и долговечный, а приложения — лишь инструменты, которые можно менять без потери ключевой информации.
Развитие ERP- и MRP-систем дало бизнесу мощные инструменты для управления процессами и данными, однако их внедрение привело к новой проблеме — лавинообразному росту сотрудников, которые должны управлять этими потоками. 



Несмотря на технологические достижения, во многих организациях ключевые решения до сих пор принимаются на основе мнений, а не фактов. В строительной отрасли это особенно заметно, поскольку исторически она опиралась на опыт и интуицию специалистов. Но в современном мире, где успех все больше зависит от способности анализировать большие объемы данных, такой подход несет серьезные риски.

Системы управления данными: от добычи данных к бизнес-задачам 
К
лючевым аспектом науки о данных является ее применение для решения бизнес-задач. На практике данные могут быть разрозненными, неполными или иметь ошибки. Это требует гибкости и адаптации подходов к их обработке. Компании должны быть готовы работать с теми данными, которые у них есть, аналогично тому, как команда «Аполлона-13» решала проблему с ограниченным количеством ресурсов на борту. 
Переход от абстрактных данных к решению реальных бизнес-проблем — сложный процесс, требующий тщательного анализа, структурирования и интеграции информации в процессы компании.
Современные компании сталкиваются с необходимостью интеграции множества систем управления данными. В строительной отрасли это особенно актуально, так как компании используют десятки или даже сотни специализированных инструментов. Выбор системы и концепции управления данными и грамотное управление этими системами и интеграция разрозненных источников данных становится критически важной задачей для эффективности бизнеса.
В середине 2020-х годов в средних строительных компаниях можно найти сотни (а в крупных - тысячи) различных систем (рис. 1.2-1), которые должны работать в гармонии, чтобы все аспекты строительного процесса протекали гладко и слаженно.
Ниже приведен список популярных систем для средних и крупных компаний строительной отрасли, которые играют важную роль в эффективном управлении строительными проектами:

● ERP (Enterprise Resource Planning) обеспечивают интеграцию бизнес-процессов, включая бухгалтерский учет, закупки и управление проектами.
● CAPEX (Capital Expenditure Planning Software) используется для составления бюджета и управления финансовыми инвестициями в строительные проекты, помогает определить стоимость основных средств и инвестиций в долгосрочные активы.
● CAD (Computer-Aided Design) и BIM (Building Information Modeling) используются для создания подробных и точных технических чертежей и 3D-моделей проектов. Основное внимание в этих системах уделяется работе с геометрической информацией.
● MEP (Mechanical, Electrical, Plumbing) инженерные системы, включающие механические, электрические и сантехнические системы, детализируют внутреннюю "кровеносную" систему проекта.
● ГИС (географические информационные системы) используются для анализа и планирования местности, включая картографию и пространственный анализ.
● CQMS (программное обеспечение для управления качеством строительства) обеспечивает соответствие строительных процессов установленным стандартам и нормам, помогая в устранении дефектов.
● CPM (управление строительными проектами) включает в себя планирование, координацию и контроль строительных процессов.
● CAFM (Computer-Aided Facility Management), системы управление и обслуживание зданий.
● SCM (Supply Chain Management) необходимо для оптимизации потока материалов и информации между поставщиками и строительной площадкой.
● EPM (Enterprise Performance Management) направлено на улучшение бизнес-процессов и производительности.
● Программное обеспечение AMS (Asset Management Software) используется для оптимизации использования, управления и обслуживания оборудования и инфраструктуры на протяжении всего жизненного цикла активов.
● RPM (Real Property Management) включает в себя задачи и процессы, связанные с управлением и эксплуатацией зданий и земли, а также связанных с ними ресурсов и активов.
Эти и многие другие системы, включающие в себя различные программные решения, являются жизненно важным компонентом для компаний, работающих сегодня в строительной отрасли. Эти системы, по сути, являются специализированными базами данных с пользовательскими интерфейсами, которые обеспечивают удобное внесение, обработку и анализ информации.

   Рисунок 1.2-1. Каждая бизнес-система требует профессиональной команды и ответственного менеджера для качественного управления данными


   Рисунок 1.2-2. Взаимосвязь систем, связывающая процессы компании с потоком информации между различными подразделениями
Для обслуживания каждой системы, внедренной в бизнес компании, тщательно подбирается команда специалистов во главе с ключевым менеджером. 
Ключевой системный менеджер играет решающую роль в направлении потока данных в нужном направлении и отвечает за качество конечных данных для руководства, подобно тому, как первые менеджеры тысячи лет назад отвечали за цифры, записанные на папирусе или глиняных табличках.
Чтобы превратить хаотичный поток информации в структурированный инструмент для принятия решений, необходимо эффективное управление данными и их интеграция между системами.
   
Управление данными и интеграция информационных потоков
П
роцесс интеграции данных в приложения и базы данных строится на агрегации информации, получаемой от разнообразных источников, включая различные отделы и специалистов. Специалисты активно выискивают необходимые данные, обрабатывают их и передают в свои системы и приложения для дальнейшего использования. 
Каждая система компании, состоящая из набора инструментов и баз данных — это дерево знаний, уходящее корнями в почву необработанных данных и растущее, чтобы принести плоды в виде готовых решений: документов, таблиц, графиков и приборных панелей. Системы в компании, подобно деревьям в определенном участке леса, взаимодействуют и общаются друг с другом, представляя собой сложную и хорошо структурированную систему, в которой каждая ветвь и лист не просто представляют различные типы данных или процессов, а являются частью более крупного, взаимосвязанного целого, поддерживаемого и управляемого экспертами.
Система поиска и передачи информации в компании работает как сложная лесная сеть, состоящая из деревьев систем и мицелия грибов - менеджеров, которые выступают в роли проводников и переработчиков, обеспечивая передачу информации и ее поступление в нужные системы. Это помогает поддерживать здоровый и эффективный поток и распределение данных внутри компании.
Как и в природе, где каждый элемент экосистемы играет свою роль, в бизнес-ландшафте компании каждый участник процесса - от инженера до аналитика - вносит свой вклад в рост и плодородие информационной среды, питающей лес систем компании. Системные деревья данных — это не просто механизмы для сбора информации, но и конкурентное преимущество, обеспечивающее устойчивый рост и развитие компании.


   Рисунок 1.2-6. Интеграция данных через различные системы подобна мицелию, соединяющему менеджеров и специалистов в единую информационную сеть
Эксперты, подобно корням, впитывают сырые данные, превращая их в питательные вещества для корпоративной экосистемы. Системы управления данными и контентом (ERP, CPM BIM и др.) выступают в роли мощных магистралей, которые поддерживают информационные потоки и позволяют знаниям циркулировать по всей структуре компании.
Сегодня значение масштаба изменилось — теперь важно не просто быть крупной компанией, а обладать большим объемом данных. Чем больше информации удается собрать и обработать, тем выше ценность бизнеса.
Компании, которые накапливают данные и умеют извлекать из них полезные инсайты, получают стратегическое преимущество. Информация превращается в новый вид капитала, обеспечивая рост, оптимизацию процессов и конкурентное превосходство. В этом мире побеждают не те, кто больше, а те, кто знает больше.

Однако если в последние 10 000 лет основной проблемой для менеджеров данных была нехватка данных, то с лавинообразным ростом количества данных и систем управления данными пользователи и менеджеры столкнулись с новой проблемой - избытком данных, затрудняющим поиск юридически корректной и качественной информации. 
Чтобы решить проблемы качества и корректности данных, менеджерам приходится преодолевать такие трудности, как разнородные системы, форматы данных, методы хранения и использования данных, а также подходы к управлению в рамках различных решений, которые были внедрены и реализованы в разное время.



HIPPO или опасность мнений в принятии решений
Традиционно в строительной отрасли важные решения принимаются на основе опыта и субъективных оценок. Без своевременных и достоверных данных решения приходится принимать вслепую, полагаясь на интуицию самых высокооплачиваемых сотрудников (HIOPPO – Highest Paid Person`s Opinion) вместо фактов.


   Рисунок 1.1-4. В отсутствии аналитики бизнес зависит от субъективного мнения опытных специалистов
Большие данные меняют этот подход, заменяя субъективные догадки объективным анализом. Теперь успех зависит не от авторитета и уровня зарплаты экспертов, а от способности работать с массивами информации и выявлять закономерности, которые раньше оставались скрытыми.
То, что в компании на уровне принятий решений выдается за разумные дебаты, на самом деле часто не основано ни на чем конкретном.
Внедрение процессов делает возможной передачу любой роли, включая руководящие позиции, благодаря четко определенному порядку преемственности. Более того, процессы создают основу для непрерывного обновления знаний и методологий, обеспечивая постоянную адаптацию к изменениям рынка.
Показательным примером служит процесс контроля качества бетона. Вместо опоры на интуицию отдельного инженера, организация внедряет строгие регламенты: систематические измерения прочности, влагостойкости и температуры с фиксацией в информационной системе. Такой подход обеспечивает сохранность опыта даже при уходе ключевых специалистов и позволяет новым сотрудникам быстро включаться в работу. 
В эпоху цифрового строительства ключевыми факторами успеха становятся скорость, эффективность и точность, а не стаж работы или положение в иерархии. Оптимальным считается решение, обеспечивающее наилучший результат при имеющихся ресурсах. Конкурентное преимущество достигается не просто соответствием стандартам, а способностью превзойти конкурентов в эффективности использования одинаковых для всех ресурсов.
Без данных вы просто еще один человек с мнением

- У. Эдвардс Деминг
В бизнесе решения, основанные на HiPPO интуиции, могут быть не просто ошибочными, но и критически опасными. Они часто опираются на неподтвержденные гипотезы или плохо интерпретируемые метрики, что ведет к неверным выводам.
Необходимо отказаться от концепции HIPPO (Highest Paid Person's Opinion – мнение самого высокооплачиваемого сотрудника), где авторитет или опыт автоматически означают правильность решения.
Однако слепая вера в данные также может привести к катастрофе. Данные сами по себе — это просто набор чисел, лишенных смысла. Без грамотного анализа, осмысленного контекста и рассказанной истории - они не могут ни направлять, ни управлять процессами.
Ключ к успеху — не в выборе между интуицией и данными, а в создании интеллектуальных инструментов, которые превращают информацию в четкие, управляемые решения. 
В будущем навык работы с данными будет так же важен, как когда-то грамотность или владение математикой. Специалисты, умеющие анализировать и интерпретировать информацию, смогут принимать более точные и взвешенные решения, вытесняя тех, кто полагается лишь на личный опыт. Это фундаментальный сдвиг в понимании ценности знаний и компетенций.

   Рисунок 1.1-5. Решения должны приниматься на основе объективного анализа данных, а не интуиции самого высокооплачиваемого 
Цифровая трансформация часто трактуется расплывчато, адаптируясь под предложения конкретных консалтинговых компаний. Однако, работая с проектами цифровой трансформации, можно выделить ключевые закономерности.
Строительная организация должна функционировать как точно настроенный механизм, где каждое решение основано на системном анализе данных. В этой книге мы рассмотрим ключевые аспекты управления данными в строительной сфере:
• Мониторинг входящих и исходящих данных (Глава 1.3 "Цифровизация строительной отрасли")
• Моделирование информационных потоков (Глава 2.5 "Моделирование данных и появление стандартов")
• Оценка производительности и эффективности (Глава 3.5 "Проблемы работы с данными в строительной индустрии")
• Выявление ключевых факторов влияния (Глава 4.1 "Аналитика данных и управление на основе данных")
• Автоматизация и оптимизация процессов (Глава 4.2 "ETL и автоматизация процессов")
В следующих главах мы рассмотрим ключевые темы, реальные примеры внедрения и покажем, как эффективно использовать данные для стратегического управления.
Лидеры подразделений станут драйверами трансформации, поскольку именно они получат наибольшую выгоду. Это требует нового подхода: вместо точности важна полнота данных, корреляции ценнее причинных связей, а интуиция уступает аналитике больших данных.
Менеджеры, специалисты и инженеры будут выступать как аналитики, изучая структуру, динамику и ключевые показатели проектов. Человеческие ресурсы станут элементами системы, требующими гибкой настройки на основе данных для достижения максимальной эффективности.
Ошибки при использовании неадекватных данных гораздо меньше, чем при отсутствии данных.

-Чарльз Бэббидж
Но также и не стоит забывать что данные — это инструмент, а не абсолютная истина. Они должны дополнять человеческое мышление, а не заменять его, помогая принимать более точные и осознанные решения.
Большие данные, про которые мы будем говорить в конце книги, меняют не только способы решения задач, но и саму логику принятия решений. Вместо поиска ответа на вопрос «почему» всё важнее знать «что» — выявлять закономерности, позволяющие прогнозировать будущее без детального понимания их механизма.
Компании, которые эффективно собирают, анализируют и используют данные, получат конкурентное преимущество. Их успех будет обусловлен стремительным ростом объемов информации, который коренным образом поменяет как отдельный бизнес компаний так и всю строительную отрасль.

Силосы данных и их влияние на эффективность компании
Каждый год объем данных, обрабатываемых в подобных системах, удваивается, но при этом способность эффективно использовать эту информацию только падает. Мы тратим до 10% валового дохода на бизнес-системы, которые крайне сложно адаптировать, хотя скорость изменений в мире только растет.
Представьте, что вы строите жилой комплекс, но вместо единого проекта каждая бригада работает по своему плану. Одни строят стены, другие проводят коммуникации, третьи укладывают дороги — и никто не сверяет свои действия. В итоге трубы не совпадают с закладными в стенах, лифтовые шахты не соответствуют этажности, а дороги приходится разбирать и прокладывать заново.
Так и с корпоративными системами: сначала создаются изолированные решения, а потом приходится тратить огромные бюджеты на их объединение. Если бы с самого начала был продуман единый цифровой проект, интеграция не потребовалась бы вовсе. Разрозненные данные — это тот же строительный хаос, но в цифровом мире.
Дизайнеры, менеджеры, бим координаторы и it разработчики часто избегают сложностей координации, предпочитая работать автономно и решать задачи в рамках своих проектов. Это естественное стремление приводит к разобщенности и созданию информационных "силосов".
Так запускается замкнутый круг: чем больше системы отдаляются друг от друга, тем чаще каждая из них получает свою собственную базу данных. А если новое приложение — это готовое решение, оно может использовать вообще другую СУБД (например, Oracle вместо Microsoft SQL или DB2 от IBM). Со временем эти системы развиваются независимо, без общего связующего звена, что делает их интеграцию все сложнее.
В основе этой проблемы — замкнутый круг. Чем больше компании вкладывают в сложные системы, тем дороже становится внедрение новых решений, а затраты на интеграцию продолжают расти.
Высокая стоимость интеграции заставляет разработчиков уходить в изоляцию, что лишь усиливает разрозненность систем. Давление сроков вынуждает идти по пути наименьшего сопротивления, откладывая изменения, которые могли бы реально улучшить ситуацию. В итоге компании оказываются в ловушке: чем дальше, тем сложнее и дороже выбраться из этого цикла.

Менеджеры часто критикуют разобщенные системы данных, но редко анализируют, почему они возникают и как их можно избежать. В результате даже при попытках борьбы с этой проблемой компании продолжают её усугублять.
Основная причина – приоритет приложений над данными. Фразы вроде "Не будем изобретать велосипед" или "Сначала купим, потом разработаем" приводят к созданию новых изолированных баз данных. Каждая такая база неизбежно дублирует часть информации из других систем (например, данные о клиентах или товарах), но в изменённом и несовместимом формате.
В конечном итоге, когда данные из старых систем переносятся в новую, а также добавляются новые сведения, появляется ещё один информационный "силос". Однако мало кто задумывается о том, какой долг по интеграции данных это создаёт и как он усложняет работу компании.






ГЛАВА 1.2. 
ЦИФРОВАЯ РЕВОЛЮЦИЯ И ВЗРЫВ ДАННЫХ
Начало бума объемов данных как эволюционная волна
С
егодня отрасль переживает настоящий информационный взрыв. Если представить бизнес как дерево знаний, питающееся данными, этот процесс напоминает бурный рост растительности в угольную эпоху. Объем информации удваивается ежегодно, следуя глобальной тенденции цифрового роста.
Данные собираются автоматически и в фоновом режиме, анализируются в реальном времени и доступны в беспрецедентных масштабах. Их накопление стало не столько необходимостью, сколько следствием технологических возможностей и экономической выгоды.
Закон Мура, названный в честь Гордона Мура (соучредителя компании Intel), предсказывает, что плотность и сложность интегральных схем, а также объем обрабатываемых и хранимых данных будут удваиваться примерно каждые два года.

   Рисунок 1.3-1. Начало цифровизации привело к быстрому распространению данных, подобно бурному росту лесов в угольную эпоху
Древние проекты, такие как Гёбекли-Тепе (Турция), не оставили после себя никаких записей для использования в будущем, так же как ранние растения не могли размножаться без семян. Однако благодаря цифровым технологиям мы можем извлекать данные из прошлых проектов, чтобы использовать их в новых, используя цифровые "семена", подобно тому, как миллионы лет назад цветковые растения (ангиоспермы) произвели революцию в жизни на Земле.
Цифровые данные, рожденные в современных системах благодаря технологиям машинного обучения и большим языковым моделям (таким как ChatGPT, Llama и DeepSeek), служат ценным ресурсом для автоматического наполнения новых проектов данными, подобно тому, как семена произвели революцию в распространении жизни на ранее пустой планете.

   Рисунок 1.3-2. Цифровые технологии, подобно первым цветущим растениям, вызвали взрывной рост массы данных
Мы стоим на пороге новой эры в строительстве, когда взрыв данных не просто наблюдается - он активно формирует цифровое будущее всей строительной отрасли. 
Исследование McKinsey Global Institute (2016) демонстрирует, что строительная отрасль отстает от других секторов в цифровой трансформации [https://www.mckinsey.com/~/media/mckinsey/business%20functions/operations/our%20insights/reinventing%20construction%20through%20a%20productivity%20revolution/mgi-reinventing-construction-a-route-to-higher-productivity-full-report.pdf]. Согласно отчету, внедрение автоматизированного управления данными и цифровых платформ может значительно повысить производительность и снизить потери, связанные с несогласованностью процессов. Эту необходимость цифровой трансформации подчеркивает и отчет Игана (UK, 1998) [https://constructingexcellence.org.uk/wp-content/uploads/2014/10/rethinking_construction_report.pdf] , который выделяет ключевую роль интегрированных процессов и совместного подхода в строительстве. 

Рост объема данных в информационную эпоху напоминает эволюционные процессы в природе: как развитие лесов изменило древний ландшафт планеты, так и нынешний информационный взрыв меняет ландшафт всей строительной отрасли.

Объем данных, генерируемых в современной компании
З
а последние два года было создано 90 % всех существующих в мире данных [4]. По состоянию на 2023 год каждый человек, включая специалистов строительной отрасли, генерирует около 1,7 мегабайта данных в секунду [5], а общий объем данных в мире достигнет 64 зеттабайт в 2023 году и, по прогнозам, превысит 180 зеттабайт, или 180*10^15 мегабайт, к 2025 году [6].




Исторический пример, который иллюстрирует подобный скачок в доступности информации, — изобретение печатного станка Гутенберга в XV веке. Спустя всего пятьдесят лет после его появления количество книг в Европе выросло вдвое: за несколько десятилетий было напечатано столько же, сколько ранее создавалось вручную за 1200 лет. Сегодня объем данных удваивается каждые три года, а в строительной отрасли этот процесс идет еще динамичнее. 
За несколько следующих десятилетий строительная отрасль создаст столько же данных, сколько было накоплено за последние тысячи лет. Каждый человек в среднем генерирует около 1,7 МБ данных в секунду, что составляет примерно 146 ГБ в день или 53 ТБ в год (рис. 1.3-3).


   Рисунок 1.3-3. Ежедневное хранение данных каждым сотрудником на серверах компании способствует постоянному росту объема данных
В современном мире строительного бизнеса даже в небольших компаниях ежедневно генерируется огромное количество разноформатной информации. Если каждый сотрудник небольшой компании из 10 человек, работающий 3 часа в день, производит около 1,7 МБ данных в секунду, то в день компания генерирует примерно 180 гигабайт данных (рис. 1.3-4): 1,7 МБ (генерируемые каждым сотрудником в секунду) за 60 секунд в минуту, 60 минут в час и 3 часа работы одного сотрудника.


   Рисунок 1.3-4. Компания из 10 человек генерирует примерно 
50-200 гигабайт данных в день
Если предположить, что около 60 % этой информации или "объема данных" часто перезаписывается или удаляется, то, по грубым подсчетам, средняя компания с 10 сотрудниками ежемесячно генерирует около 500-2000 гигабайт новых данных.
Однако накопление информации — это лишь первая часть уравнения. Важным аспектом становится не только генерация данных, но и эффективное управление ими, включая хранение, обработку и анализ. Один из ключевых вопросов, с которым сталкиваются современные компании, — это стоимость хранения данных.


Стоимость хранения данных: экономический аспект
Р
ассматривая последние тенденции в области хранения данных, предположим, что компания передает вопросы хранения данных специализирующимся на этом облачным компаниям и размещает половину своих данных в облачных хранилищах. Стоимость хранения данных в этом случае составляет в среднем 0,015 доллара за гигабайт в месяц [7], а ежемесячные расходы на хранение будут линейно расти на 10-50 долларов каждый месяц.
Это означает, что для небольшой компании из 10 человек, где данные часто используются только один раз, а затем архивируются, ежемесячные расходы только на хранение половины генерируемых данных могут достичь 2000-3000 долларов в месяц в течение нескольких лет, создавая значительное финансовое бремя для бизнеса.

   Рисунок 1.3-5. Перемещение данных в облако увеличивает ежемесячные расходы компании из 10 человек на хранение данных до 2 000 долларов в месяц
Ускоренное распространение облачных технологий САПР (BIM) и облачных ERP-систем еще больше подстегивает рост расходов компании, что рано или поздно отражается на необходимости поиска решений по оптимизации существующих или поиску новых методов хранения и обработки данных. Эта смена парадигмы приводит к тому, что компании начинают искать способы не только минимизировать расходы на облачное хранение, но и обеспечить автономность своих данных, снижая зависимость от внешних поставщиков.
С развитием технологий больших языковых моделей (LLM) начиная с 2023 года правила хранения данных начинают меняться. Компании вновь задумываются о возврате контроля над данными, поскольку обработка информации на собственных серверах становится более выгодной и безопасной альтернативой облачным сервисам. 
В этом контексте на первый план выходит тенденция к отказу от SaaS-модели в пользу локального развертывания корпоративных LLM и ИИ-решений. Как отметил генеральный директор Microsoft в одном из своих интервью [https://jetsoftpro.com/blog/saas-is-dead/] вместо того чтобы полагаться на несколько отдельных приложений для выполнения различных задач, агенты ИИ будут управлять этими правилами и процессами в нескольких базах данных, автоматизируя функции разных систем.
SaaS is dead. All software applications that we know today are just fancy interfaces sitting on databases.
— Microsoft CEO Satya Nadella.
Такой подход устранит необходимость в традиционных внутренних системах, поскольку агенты ИИ будут напрямую взаимодействовать с данными и логикой, оптимизируя работу и повышая эффективность. 
И как только компании достигнут уровня, при котором LLM смогут подключаться к базам-источникам данных и обрабатывать данные в реальном времени, станет очевидно, что мы приблизились к пределу традиционных методов сбора информации.

Границы накопления данных
С
ложные системы компаний хорошо растут и функционируют в условиях управляемого роста, когда объем данных и приложений находится в равновесии с возможностями ИТ-отделов и менеджеров. Но в последнее десятилетие активной цифровизации наступил неконтролируемый рост объема и сложности данных, что привело к перенаселению лесов систем компании.
Сегодня на серверы и хранилища данных обрушивается лавина информации, которая быстро теряет актуальность и нарушает хрупкий баланс в экосистеме с и без того ограниченными ресурсами. Не в силах справиться с потоком данных, информация скапливается в силосах, из которых вручную вырезается удобоваримая информация, подобно созданию статуи из глыбы мрамора.
В результате, подобно лесу, поросшему плющом и плесенью, сложные системы управления компаниями сегодня часто страдают от перегрузки и, как следствие, от снижения эффективности.

   Рисунок 1.3-6. Массы данных позволяет перейти от накопления к 
анализу и стратегическому планированию
За фазой активного роста последует фаза охлаждения. Период активного накопления данных не бесконечен, и за десятилетиями экспоненциального роста объема данных следует обратная тенденция. Когда хранилища данных достигают точки насыщения, происходит серьезный сдвиг: данные перестают быть просто элементом хранения, а становятся важным ресурсом для стратегического планирования и прогнозирования.
Искусственный интеллект и машинное обучение уменьшит стоимость труда и наступит время, когда компаниям строительной отрасли придется сместить акцент в управлении данными с количества на качество и на управляемую форму для использования в потоке данных между системами. Важность будет заключаться не в количественном росте данных, а в их автоматической обработке и анализе для получения ценных сведений, которые станут для компаний основным средством принятия бизнес-решений.
Чтобы анализировать и извлекать выводы из устаревших данных, необходимо правильно собрать, обработать и подготовить информацию.
Процесс анализа данных в компании похож на цикл жизни и распада деревьев в лесу и появления новых молодых и сильных деревьев. Готовые и завершенные процессы по окончании своего применения попадают в информационную экосистему компании, становясь в итоге информационным гумусом, питающим рост новых систем и данных.
Поэтому в любой компании, прежде чем внедрять новые жизнеспособные инструменты и процессы, необходимо правильно собрать, качественно обработать и проанализировать уже существующие процессы и данные различных форматов и типов. И в этом бизнесу помогает использование различных систем и концепций управления данными.
ГЛАВА 1.3 
ЦИФРОВИЗАЦИЯ СТРОИТЕЛЬНОЙ ОТРАСЛИ

Дилемма данных: качество против количества
К
аждый год объем данных, доступных компаниям, удваивается, но их способность эффективно использовать эту информацию только падает. Мы тратим 3–8 % валового дохода на бизнес-системы, которые крайне сложно адаптировать, хотя скорость изменений в мире только растет. Руководители жалуются на устаревшие IT-решения, но попытки их заменить часто оборачиваются колоссальными затратами и редкими успехами.
С появлением множества программных приложений и систем, которые растут как грибы после дождя, проблема ненадлежащего качества данных становится все более актуальной для конечных пользователей, которым в итоге приходится использовать их для принятия решений в компании.
Одни и те же данные, но с разными значениями, теперь можно найти в разных системах и приложениях (рис. 1.2-3). Это приводит к трудностям для конечных пользователей, когда они пытаются определить, какая версия данных является актуальной и правильной среди множества доступных. Это приводит к ошибкам при анализе и, в конечном счете, принятии решений.

   Рисунок 1.2-3. Пытаясь найти нужные данные, менеджеры 
должны обеспечить качество и юридическую надежность 
данных между различными системами
Чтобы застраховаться от проблем с поиском нужных данных, руководители компаний создают многоуровневую бюрократию из менеджеров, которые должны научиться быстро находить нужные данные в лабиринте систем.
Чем больше данных, тем сложнее извлечь из них пользу. Принятие решений замедляется, так как каждый шаг приходится многократно подтверждать и проверять.
Поскольку руководству приходится снова и снова решать одни и те же проблемы, связанные с ненадежными данными, рано или поздно приходит понимание, что получение точной и актуальной информации через пирамиду ответственных менеджеров — это узкое место и слишком сложная задача, если данные управляются вручную и обрабатываются в различных системах.
Эта проблема широко раскрыта в так называемой «Черной книге» (Германия), в которой рассматриваются последствия фрагментации строительных данных и необходимость единых структурированных форматов. В документе подчеркивается, что без стандартизированной интеграции данные теряют свою ценность и создают дополнительные препятствия при принятии решений.
Проблема усугубляется тем, что рынок программного обеспечения для управления данными продолжает пополняться все новыми и новыми решениями, а без четкой стратегии управления данными новые инструменты обречены стать лишь еще одним слоем в многослойной информационной лазанье.


   Рисунок 1.2-4. Сложность систем и разнообразие форматов данных приводят к потере согласованности в процессе строительства
Все эти проблемы с комплексным управлением большим количеством разнообразных решений рано или поздно приводят руководство и лидеров компаний к пониманию того, что проблема не в количестве данных или новых решениях для их обработки, а в качестве данных и в том, как организация эти данные получает, хранит и использует.
Ключ к успеху заключается не в поиске нового "волшебного" инструмента, а в создании культуры, в которой данные рассматриваются как ценный актив, а их качество и целостность являются приоритетами для каждого сотрудника на всех уровнях организации.
Ответ на дилемму качества и количества данных кроется в качестве и удобоваримости структуры данных для интеграции в бизнес-процессы. Правильная структура позволяет объединить информационные потоки, устранить противоречия и дублирование, тем самым обеспечивая единый, надежный источник данных для принятия обоснованных бизнес-решений.

Чем больше инструментов, тем эффективнее бизнес?
Разрозненные наборы данных накапливаются как слои различных ископаемых под подошвой леса. Каждое приложение (старая система, новый облачный сервис, Excel-отчёты) оставляет после себя свой «геологический слой». Один слой — глина (устаревшие и забытые на серверах данные), другой — песок (разрозненные таблицы), третий — твёрдый гранит (проприетарные форматы закрытых системы). Со временем эти слои накапливаются, как пласты породы.
Чтобы добраться до ценной «породы» — полезной информации — нужно копать через все эти слои, очищать их, дробить на удобоваримые фракции и при помощи химических реакций превращать в ценный ресурс. Но каждый новый проект добавляет ещё один слой, а не упрощает добычу. 

   Рисунок 1.2-5. Данные превращаются в «грунт», где даже золото ценной информации теряется в грязи разноформатных данных.
Полезные и ценные данные — как уголь и нефть: они формируются годами, «спрессовываясь» под слоями хаоса бизнес-процессов. Чтобы добыть эти ценные данные, нужно пробиться через пласты устаревших систем, пыляшихся на серверах и забытых уже давно данных, когда-то созданных или уметь до
Создать «месторождение» DWH, Data Lake или другое хранилище данных, где данные станут не побочным продуктом приложений, а основой в бизнес процессах. Как нефтяники строят инфраструктуру для добычи, так и компании должны будут научится в своих недрах неиспользованных и давно устаревших данных научится искать месторождения этих ценных и полезных данных. 
В итоге новые компании, которые появились без предрасположенности к тракторам или кто во время не вкладывался в добычу полезных ископаемых в конечном итоге вытеснили своих более устоявшихся конкурентов, оказавшись более проворными и эффективными. 
В итоге каждая команда в компании описывает общение с «клиентом» и задачей по-своему: для отдела калькуляций это email и таблицы Excel с ценами, для логистического отдела — размеры и сроки , для проектировщика — геометрия в CAD баз данных и нормативы в PDF формате. Когда эти системы пытаются «поговорить» друг с другом, возникают ошибки, ручные правки и бесконечные доработки. Чем упорнее компании множат приложения, тем сильнее они погружаются в технический долг, где каждый новый проект лишь усугубляет хаос.

Снижение сложности и стандартизация данных
Количество данных неуклонно растёт, растёт и количество вопросов
Снижение сложности, прямое и косвенное, уменьшает количество кода, который необходимо создавать и поддерживать. 
Наибольшая экономия достигается при непосредственном сокращении количества кода за счет замены его данными. Мы заметили, что переход к разработке, ориентированной на модели (и отказ от разработки, ориентированной на код приложений), часто сопровождается переходом к подходам, ориентированным на данные. Это неудивительно, если принять во внимание менталитет и образ мышления, лежащие в основе этих двух концепций. Когда кто-то вступает на путь Data-Centric, он начинает по-другому относиться к своим данным. Они видят иные отношения между данными и приложениями, а также между данными и архитектурой.

В традиционном прикладном программном обеспечении значительная часть кода выполняет лишь одну задачу — перемещает данные между базой данных, API, пользовательским интерфейсом и промежуточными уровнями системы. Этот процесс не добавляет ценности сам по себе, а лишь поддерживает работу существующей архитектуры.
Принято считать, что наибольшую ценность в программных системах представляет код, отражающий сложную бизнес-логику. Однако большая часть кода в приложениях занята рутинной передачей данных между различными уровнями системы. Он необходим, но его польза для бизнеса минимальна.
От хаоса к структуре в работе с данными
За последние 15 лет строительная отрасль активно инвестировала в цифровизацию, что расширило возможности сбора и анализа данных на всех этапах жизненного цикла проекта. Сегодня строительные компании используют датчики, BIM-модели, ERP-системы и другие инструменты для мониторинга производственных процессов, управления цепочками поставок, контроля качества, анализа затрат и прогнозирования рисков.
Кроме внутренних данных, компании получают доступ к внешней информации: рыночным трендам, изменениям в законодательстве, движениям конкурентов и инновациям в отрасли. Такая доступность данных усилила интерес к методам их анализа, автоматизации процессов и внедрению решений на основе науки о данных, что позволяет строить быстрее, эффективнее и с меньшими затратами.

В строительстве данные так же ценны, как и материалы. Их нужно собирать на каждом этапе — от проектирования до эксплуатации. Часто у вас есть только один шанс зафиксировать важную информацию: погодные условия во время заливки бетона, показатели вибрации несущих конструкций или фактические сроки выполнения работ. Если эти данные не сохранить, впоследствии их невозможно будет восстановить.
Чем больше информации собирается, тем лучше можно моделировать процессы, прогнозировать риски и повышать эффективность проектов. Контекст здесь — ключевой фактор: зная, как ведут себя материалы, техника и люди в разных условиях, компания получает возможность не просто строить, а делать это быстрее, дешевле и безопаснее, персонализируя решения под каждый проект.



"Без качественных данных любые расчёты — просто догадки."
Современное строительство сталкивается с лавиной информации: чертежи, 3D-модели, финансовые отчёты, графики работ, отчёты по безопасности. Однако чаще всего эти данные разрознены, хранятся в разных системах и не используются эффективно. Эта глава посвящена тому, как правильно организовать сбор данных в строительстве, чтобы они стали инструментом для принятия решений, а не головной болью.
Данные должны соответствовать поставленной задаче, быть актуальными, точными и очищенными от ошибок. Важно, чтобы они были объективными и, главное, заслуживали доверия, иначе любые выводы на их основе окажутся сомнительными.
Начало формы
Качеству и актуальности данных посвящены следующие главы этой книги 
специалисты по исследованию данных тратят 80 % своего времени на
получение, очистку и подготовку данных и только 20 % - на построение
моделей, анализ, визуализацию и формирование на основе этих данных
Конец формы



1. Основы сбора данных: Что, откуда и зачем?
В строительстве данные поступают из множества источников:
📌 BIM-модели и CAD-файлы – содержат геометрию, материалы, объём работ.
📌 Датчики IoT – отслеживают состояние стройплощадки, оборудование, условия окружающей среды.
📌 ERP и CRM-системы – хранят информацию о финансах, закупках, подрядчиках.
📌 Люди – отчёты инженеров, прорабов, бухгалтеров, аудиторов.
Ключевой вызов: эти данные хранятся в разных форматах, системах и файлах. Как их собрать в единую картину?

2. Методы сбора данных: Как избежать хаоса?
Чтобы данные работали на вас, их сбор должен быть организован. Рассмотрим основные подходы:
📍 Автоматический сбор данных
✅ Использование датчиков, камер и дронов для мониторинга стройки.
✅ Интеграция ERP, BIM и бухгалтерских систем через API.
✅ Извлечение информации из PDF-файлов и таблиц с помощью ETL (Extract, Transform, Load).
📍 Ручной ввод данных
✍️ Обновление данных на планшетах вместо бумажных отчётов.
✍️ Формы обратной связи от сотрудников на стройке.
✍️ Автоматизированные чек-листы для инспекций.
📍 Использование открытых данных
🌍 Геоданные, климатические условия, рыночные индексы – всё это можно анализировать для предсказания сроков и стоимости строительства.
"Мы не можем автоматизировать хаос. Начните с того, чтобы организовать поток данных, прежде чем строить модели и отчёты."

3. Структурирование данных: Превращаем хаос в порядок
Собранные данные должны быть:
✔ Структурированными (таблицы, базы данных, DataFrames).
✔ Доступными (API, облачные хранилища, BI-системы).
✔ Актуальными (система обновления в реальном времени).
Пример:
Раньше компания X вела подсчёт затрат в Excel, и каждое изменение бюджета требовало обновления вручную. После перехода на автоматизированную систему сбора данных из ERP и BIM, время подготовки отчётов сократилось в 5 раз.

4. Ошибки и подводные камни
❌ "Чем больше данных – тем лучше." Нет! Важна не их масса, а качество.
❌ Игнорирование валидации данных. Если в отчёте ошибка, её понесут дальше, и бюджет "потечёт".
❌ Отсутствие единой платформы. Разрозненные файлы = хаос и дублирование.

Заключение
Строительство – это не просто физические процессы, но и управление информацией. Без качественного сбора данных невозможно внедрять аналитику, автоматизацию и машинное обучение.
📢 Что делать прямо сейчас?
✅ Определить, какие данные у вас есть и где они хранятся.
✅ Выбрать инструменты автоматизации (BIM, ERP, API, ETL).
✅ Организовать сбор данных в единые форматы (таблицы, базы данных).
"Будущее строительной индустрии — за теми, кто умеет работать с данными." 🚀











ЧАСТЬ II
 
ТИПЫ ДАННЫХ, СИСТЕМЫ И ИНСТРУМЕНТЫ, ИСПОЛЬЗУЕМЫЕ В СТРОИТЕЛЬНОЙ ОТРАСЛИ




ГЛАВА 2.1 
ТИПЫ ДАННЫХ В СТРОИТЕЛЬСТВЕ
REV Наиболее важные типы данных в строительной отрасли
В
 современной строительной отрасли системы, приложения и хранилища данных компаний активно наполняются информацией и данными различных типов и форматов (рис. 2.1-2).
Раньше интеграция разных типов данных казалась недостижимой целью — амбициозной, но нереализуемой идеей. Сегодня это уже привычная практика.
В главе 2.4 мы разберём ключевые стандарты, которые позволяют объединять структурированные, полуструктурированные и неструктурированные данные в единое представление. Пока же важно понимать: эта задача уже решена.
Давайте подробнее рассмотрим основные типы данных, которые формируют информационный ландшафт современной компании, работающей в строительной отрасли:
● Структурированные данные: эти данные имеют четкую организационную структуру, например, электронные таблицы Excel и реляционные базы данных.
● Неструктурированные данные: это информация, которая не организована в соответствии со строгими правилами или форматами. Примерами таких данных являются текст, видео, фотографии и аудиозаписи. 
● Слабоструктурированные данные: эти данные занимают промежуточное положение между структурированными и неструктурированными данными. Они содержат элементы структуры, но эта структура не всегда ясна или полностью структурирована. Примерами полуструктурированных данных в строительстве являются: технические спецификации, проектная документация или отчеты о проделанной работе.
● Текстовые данные: включают в себя все, что получено в результате устных и письменных коммуникаций, например электронные письма, стенограммы совещаний и встреч.
● Геометрические данные: эти данные поступают из программ САПР (BIM), в которых специалисты создают геометрические данные элементов проекта для подтверждения значений объемов или проверки столкновений.

Важно отметить, что геометрические и текстовые (буквенно-цифровые) данные не являются отдельной категорией, а могут присутствовать во всех трех типах данных. Геометрические данные, например, могут быть как частью структурированных данных (BIM-модели с параметрами), так и неструктурированных данных (отсканированные чертежи). Текстовые данные аналогично могут быть как организованы в базы данных (структурированные данные), так и существовать в виде документов без четкой структуры.

Каждый тип данных в строительной компании — это уникальный элемент в мозаике информационных активов компании. От неструктурированных данных, таких как изображения со строительных площадок и аудиозаписи совещаний, до структурированных записей, включая таблицы и базы данных, - каждый элемент играет важную роль в формировании информационного ландшафта компании.


   Рисунок 2.1-1. ИТ-специалисты и менеджеры по работе с данными 
должны научиться работать со всеми типами данных, 
используемых в строительной отрасли
Вот список лишь некоторых систем и связанных с ними типов данных (рис. 2.1-2), используемых в строительстве:
● ERP (Enterprise Resource Planning) - обрабатывает структурированные данные, помогая управлять ресурсами предприятия и интегрировать различные бизнес-процессы.
● CAD (Computer-Aided Design) в сочетании с BIM (Building Information Modeling) - использует геометрические и полуструктурированные данные для проектирования и моделирования строительных проектов, обеспечивая точность и согласованность информации на этапе проектирования.
● GIS (Geographic Information Systems) - работает с геометрическими и структурированными данными для создания и анализа картографических данных и пространственных отношений.
● RFID (Radio-Frequency Identification) - использует полуструктурированные данные для эффективного отслеживания материалов и оборудования на строительной площадке с помощью радиочастотной идентификации.
● ECM (Engineering Content Management) — это система управления инженерными данными и документацией, включая полуструктурированные и неструктурированные данные, такие как технические чертежи и проектная документация.

Эти и многие другие системы компании управляют широким спектром данных, от структурированных табличных данных до сложных геометрических моделей, обеспечивая интегрированное взаимодействие в процессах проектирования, планирования и управления строительством.
В примере упрощенного диалога (рис. 2.1-3) между специалистами по строительному проекту происходит обмен различными типами данных:
➤ Архитектор: "Учитывая пожелания клиента, я добавил зону отдыха на крыше. Пожалуйста, посмотрите новый дизайн" (геометрические данные - модель).
➤ Инженер-конструктор: "Проект получен. Я рассчитываю несущую способность крыши для новой зоны отдыха" (структурированные и полуструктурированные данные - расчетные таблицы).
➤ Менеджер по закупкам: "Нужны спецификации и количество материалов для зоны отдыха, чтобы организовать закупку" (текстовые и полуструктурированные данные - списки и спецификации).
➤ Инженер по охране труда и технике безопасности: "Получил данные о новой зоне. Оцениваю риски и обновляю план безопасности" (полуструктурированные данные - документы и планы).
➤ Специалист по BIM-моделированию: "Внесение изменений в общую модель проекта для корректировки рабочей документации" (геометрические данные и полуструктурированные данные).
➤ Руководитель проекта: "Включаю новую зону отдыха в график работ. Я обновляю графики и ресурсы в системе управления проектом" (структурированные и полуструктурированные данные - графики и планы).
➤ Специалист по обслуживанию объектов (FM): "Я готовлю данные для будущего обслуживания зоны отдыха и ввожу их в систему управления имуществом" (структурированные и полуструктурированные данные - инструкции и планы технического обслуживания).
Каждый специалист работает с различными типами данных, обеспечивая эффективное взаимодействие команды и успешное выполнение проекта. 

   
   Рисунок 2.1-2. Различные форматы и данные заполняют различные системы, требуя перевода в форму, пригодную для комплексной интеграции

   Рисунок 2.1-3. Общение между специалистами происходит как на уровне текста, так и на уровне данных
Давайте подробно рассмотрим каждый тип данных, который используется в бизнес-процессах компаний строительной отрасли, уделив особое внимание структурированным данным и реляционным базам данных, которые играют ключевую роль в процессах хранения и обработки информации.
   
Структурированные данные
О
дними из наиболее распространенных примеров структурированных данных, используемых в различных областях для обработки и анализа информации, являются форматы файлов XLSX и CSV. Эти форматы обеспечивают четкую организацию данных в электронных таблицах, где информация разделена на строки и столбцы, что облегчает ее чтение, редактирование и анализ с помощью программного обеспечения для работы с электронными таблицами.
• Формат XLSX, широко используемый на различных организационных уровнях в строительной отрасли, заключает табличные данные в сжатые XML-файлы в ZIP-архиве (XML+ZIP=XLSX). 
• Формат CSV (значения, разделенные запятыми) обеспечивает простоту и универсальность хранения и обмена данными между реляционными базами данных, обмена данными внутри приложений и выполнения массовых обновлений. 
XLSX и CSV характеризуются прежде всего тем, что широко используются в приложениях, где требуется удобство чтения, ручное редактирование и базовая совместимость, но они не оптимизированы для хранения данных и задач высокопроизводительных вычислений.
Используя запятые или точки с запятой в качестве разделителей, CSV обеспечивает универсальную совместимость с различными операционными системами, отличаясь от более специфического формата XLSX гибкими возможностями обработки и передачи данных.

   Рисунок 2.1-4. Структурированные данные: основа хранения 
и обработки данных
Независимость от платформы делает формат CSV самым популярным инструментом для передачи данных в гетерогенных ИТ-средах и системах.
Excel в основном используется для решения небольших задач и автоматизации мелких процессов, а для более сложных процессов применяются системы управления данными.
В строительной отрасли системы управления данными, включая ERP, САПР (BIM), CAFM, CPM, SCM и другие системы, выполняют важнейшие функции (рис. 2.1-5), а структурированные данные, часто хранящиеся в базах данных этих систем, служат основой для четкой организации и эффективного управления практически всеми аспектами информационных потоков компании.


   Рисунок 2.1-5. Практически каждая система или приложение, используемое в строительном бизнесе, имеет в своей основе базу данных
 Большинство современных баз данных и приложений так или иначе работают с популярными традиционными реляционными базами данных (РСУБД), в которых данные организованы в четко определенные таблицы, строки и столбцы.

Реляционная база данных RDBMS и язык запросов SQL
Р
еляционные системы управления базами данных (РСУБД) - это системы хранения данных, которые организуют информацию в таблицы с определенными отношениями между ними.
Данные, организованные в таблицы и базы данных, не просто представляют собой цифровую информацию; они являются основой для транзакций и взаимодействия между различными системами.
Вот несколько наиболее распространенных реляционных систем управления базами данных (РСУБД):
● MySQL, входящий в состав известного стека LAMP (Linux, Apache, MySQL, PHP/Perl/Python), предпочитают в мире веб-приложений благодаря его простоте и эффективности.
● PostgreSQL выделяется своими мощными объектно-реляционными возможностями, предлагая расширенные функции и надежность для сложных систем.
● Microsoft SQL Server, коммерческий продукт компании Microsoft, широко ценится в корпоративной среде благодаря широкому набору инструментов и безопасности.
● Oracle Database, используемая на крупных предприятиях, является символом мощности и надежности для критически важных приложений.
● IBM DB2, также ориентированная на крупные корпорации, предлагает высокую производительность и надежность.
● SQLite — это легкий вариант, идеально подходящий для мобильных приложений и других ситуаций, когда требуется минимальная настройка базы данных. Он часто используется в программах для проектирования САПР (BIM) 

Популярные системы управления базами данных в строительном бизнесе - MySQL, PostgreSQL, Microsoft SQL Server, Oracle Database, IBM DB2 и SQLite - работают со структурированными данными. Все эти СУБД представляют собой мощные и гибкие решения для управления широким спектром бизнес-процессов и приложений, от небольших веб-сайтов до масштабных корпоративных систем. С их помощью организации могут эффективно хранить, обрабатывать и анализировать данные, на основе которых принимаются решения. 

   Рисунок 2.1-6. Опрос разработчиков на StackOverFlow [8] (крупнейшем ИТ-форуме) о том, какие базы данных они использовали в прошлом году и какие хотят использовать в следующем (РСУБД выделены синим цветом) 
Стандартным языком запросов, используемым для управления и манипулирования данными в реляционных базах данных, является SQL (Structured Query Language). Эволюция систем SEQUEL-SQL проходит через такие значимые продукты и компании, как Oracle, IBM DB2, Microsoft SQL Server, SAP, PostgreSQL и MySQL, и завершается появлением SQLite и MariaDB в последние два десятилетия [9].
SQL — это специальный язык как ключ для доступа ко всей необходимой информации и ее удобной обработки, который помогает хранить, находить и анализировать информацию в реляционных базах данных.

   Рисунок 2.1-7. Язык запросов SQL: быстрая обработка, группировка и агрегирование для мгновенного создания сгруппированных данных
Основное преимущество языка SQL, часто используемого в реляционных базах данных, перед другими видами управления информацией (например, с помощью классических электронных таблиц Excel, часто используемых в строительной отрасли) в поддержке очень больших объемов баз данных при высокой скорости обработки запросов.

Excel облегчает работу с данными благодаря своей визуальной и интуитивно понятной структуре. В отличие от реляционных баз данных на SQL, где дата может быть разделена на несколько полей, Excel хранит такие данные, как "3 января 2020 года", в одной ячейке, что упрощает их восприятие. Это делает Excel более доступным для пользователей, поскольку они могут непосредственно взаимодействовать с данными, не прибегая к написанию кода.
Однако с увеличением объема данных производительность Excel снижается. Инструмент сталкивается с ограничениями по объему хранимых данных – максимум один миллион строк, и производительность снижается задолго до достижения этого предела. Поэтому, хотя Excel и выглядит предпочтительнее для визуализации и манипуляций с небольшими объемами данных, для работы с большими массивами данных лучше подходит SQL. SQL обеспечивает скорость, точность, согласованность данных, а также возможность работы с большим объемом и мощность обработки, что делает его идеальным инструментом для управления крупными базами данных.


Неструктурированные данные
Н
еструктурированные данные в строительстве включают в себя отсканированные документы, изображения и видео со стройплощадок. Они необходимы для отслеживания хода работ, обеспечения безопасности и анализа рабочих процессов. Устройства Интернета вещей (IoT), собирающие информацию о различных параметрах, таких как температура, влажность, уровень шума и расположение оборудования, также предоставляют значительный объем неструктурированных данных (частично являющихся также полуструктурированными данными). Эти данные очень важны для мониторинга эксплуатации зданий и работы оборудования.
Благодаря широкому распространению таких данных, именно автоматизированный сбор, обработка, анализ неструктурированных данных и их интеграция в процессы управления строительством открывают возможности для снижения человеческого фактора во многих процессах, в которых сегодня задействовано большое количество менеджеров и вспомогательного персонала.

   Рисунок 2.1-8. Работа с неструктурированными данными начинается с их преобразования в полуструктурированные и структурированные данные
Текстовые данные, хотя и являются разновидностью неструктурированных данных, заслуживают отдельной категории из-за своего широкого распространения и значительной важности в бизнес-процессах компаний, работающих в строительной отрасли.

Текстовые данные
Т
екстовые данные в строительной отрасли охватывают широкий спектр форматов и типов информации, от бумажных документов до неформальных методов общения, таких как письма, разговоры, рабочая переписка и устные встречи на строительной площадке. Все эти текстовые данные несут в себе важную информацию для управления строительными проектами - от деталей проектных решений и изменений в планах до обсуждения проблем безопасности и переговоров с подрядчиками и клиентами.
В строительной отрасли встречаются самые разные текстовые форматы - от документов Word (.doc, .docx) и PDF-файлов технической документации до текстовых файлов, стенограмм совещаний в Teams, Zoom или Google Meet (.txt) и аудиозаписей обсуждений и совещаний (.mp3, .wav), которые затем распознаются или переписываются в текст.



   Рисунок 2.1-9. Текстовые данные, один из самых популярных типов информации, используемой в общении между участниками проекта
Но если письменные документы, такие как официальные запросы, условия контрактов и электронные сообщения, обычно уже имеют определенную структуру, то устные сообщения и рабочая переписка часто остаются неструктурированными, что затрудняет их анализ и интеграцию в системы управления проектами.
Ключом к эффективному управлению такими данными является преобразование этой разнообразной текстовой информации в структурированную форму (рис. 2.1-10). Такое преобразование позволяет автоматически интегрировать обработанную информацию в существующие системы управления, которые уже работают со структурированными данными.

   Рисунок 2.1-10. Преобразование текстового контента 
в структурированные данные





Полуструктурированные данные 
П
олуструктурированные данные, хотя и содержат определенный уровень организации, не имеют строгой структуры. Примерами таких данных являются журналы учета рабочего времени, отчеты о проделанной работе и графики работы, которые могут быть представлены в различных форматах. Хотя такая информация и содержит определенную структуру (например, даты, имена сотрудников и список выполненных задач), формат ее представления может сильно различаться в разных проектах или даже у отдельных работников. Их легче анализировать, чем неструктурированные данные, однако они требуют дополнительной обработки для интеграции в стандартизированные системы управления проектами.
Работа с полуструктурированными данными, характеризующимися наличием постоянно меняющейся структуры, представляет значительные трудности. Это связано с тем, что изменчивость структуры данных требует индивидуальных подходов к их обработке и анализу. 
Но если работа с неструктурированными данными требует больших усилий, то обработка полуструктурированных данных может быть выполнена с помощью относительно простых методов и инструментов.
САПР (BIM) данные являются характерными представители полуструктуированных данных в ландшафте систем данных, используемых в строительстве. Преобразование данных из полуструктурированных форматов, таких как DWG (AutoCAD), IFC и RVT (Revit®), в структурированный формат открывает возможности для межплатформенного обмена. Подробнее о преобразовании данных САПР (BIM) в структурированные форматы читайте в главе "Преобразование данных САПР (BIM) в структурированную форму".
Не нативный формат IFC (Industry Foundation Classes), экспортируемый из систем автоматизированного проектирования (BIM), является примером полуструктурированных данных. Эти данные можно эффективно обрабатывать с помощью языков запросов SPARQL и RDF [14], которые специально разработаны для работы с полуструктурированными данными.







   Рисунок 2.1-11. Эволюция данных в САПР (BIM) от первоначальных неструктурированных форматов к структурированным форматам

Геометрические данные, производимые системами САПР (BIM), которые редко встречаются вне специализированных областей, можно классифицировать так же, как полуструктурированные данные. Однако мы будем выделять геометрические данные в отдельный тип, поскольку они, как и текстовые данные, часто рассматриваются в процессах компании как отдельный тип данных.

Геометрические данные и их применение
Е
сли метаинформация об элементах проекта практически всегда хранится в виде таблиц и структурированных данных, то геометрические данные элементов проекта в большинстве случаев создаются с помощью специальных САПР (BIM) инструментов, позволяющих детально визуализировать элементы проекта в виде набора линий (2D) или геометрических тел (3D).



При работе с геометрическими данными в строительстве и архитектуре можно выделить три основные области применения геометрических данных САПР (BIM):
● Подтверждение объемов: Геометрические данные, генерируемые программами САПР (BIM), необходимы для автоматического и точного определения объемов и размеров элементов проекта. Эти данные включают автоматически рассчитанные площади, объемы, длины и другие важные атрибуты, необходимые для планирования, составления бюджета и заказа ресурсов и материалов.
● Визуализация проекта: Визуализация элементов проекта позволяет, в случае каких-либо изменений в проекте, автоматически генерировать обновленные чертежи в различных плоскостях. Визуализация проекта на начальных этапах позволяет ускорить взаимопонимание между всеми участниками, сэкономить драгоценное время и ресурсы в процессе строительства.
● Проверка столкновений: В сложных строительных и инженерных проектах, где взаимодействие нескольких элементов (например, труб и стен) без "геометрических конфликтов" является критически важным, проверка столкновений играет ключевую роль. Использование программного обеспечения для обнаружения коллизий позволяет заблаговременно выявлять потенциальные геометрические коллизии между элементами проекта, предотвращая дорогостоящие ошибки в процессе строительства.

   Рисунок 2.1-12. Геометрия является основой для получения объемов элементов, которые затем используются для расчета стоимости и сроков
С самого начала появления инженерно-конструкторских бюро, инженеры-конструкторы предоставляли геометрическую информацию в виде чертежей линий и плоских геометрических элементов (на папирусе, ватмане А0 или в форматах DWG, PDF, PLT), на основании которых прорабы и сметчики, на протяжении последних тысячелетий, с помощью линеек и транспортиров собирали атрибутивные объемы или количество элементов (сущностей).
Эта ручная и трудоемкая задача теперь решается путем полной автоматизации благодаря появлению объемного моделирования в современных инструментах САПР (BIM), которое позволяет автоматически получить объемные атрибуты любого элемента, без необходимости рассчитывать эти значения вручную. 
"Нам нужно уметь управлять всеми этими данными (проектными данными САПР (BIM) - прим. автора), хранить их в цифровом виде и продавать программное обеспечение для управления жизненным циклом и процессами, потому что на каждого инженера, который что-то создает (в САПР (BIM) - прим. автора), приходится десять человек, которые работают с этими данными" [10].
К.Б. Генеральный директор Autodesk®, 2005 г.
Современные инструменты САПР (BIM) присваивают элементам проекта точные формы и размеры и автоматически генерируют из них таблицы спецификаций для использования в различных системах, например, для оценки стоимости, составления графиков или расчета СО2. Подробнее о получении спецификаций, таблиц QTO и объемов, а также о практических примерах мы поговорим в главе "Получение объемов и количественный расчет".

   Рисунок 2.1-13. Инструменты САПР (BIM) сохраняют данные в базах данных, которые предназначены для интеграции и взаимодействия с другими системами 



Помимо объемного моделирования элементов в инструментах САПР, существует дополнительный информационный слой, обусловленный концепцией BOM из машиностроения, которую производители САПР обозначили для строительной отрасли специальной маркетинговой аббревиатурой BIM (Building Information Modeling) - аббревиатурой, активно продвигаемой с 2003 года [11].

Благодаря усилиям поставщиков САПР (BIM) данные, созданные в САПР (BIM) решениях, стали отдельным, как бы существующим, новым типом данных, сочетающим в себе как геометрическую информацию об элементах, так и метаинформацию (структурированную или полуструктурированную), собранную в специальном САПР (BIM) формате.

REV BIM-данные и концепция BOM-BIM
К
онцепция BIM (Building Information Modeling), изложенная в Whitepaper BIM 2003 года [11], возникла благодаря маркетинговым инициативам производителей программного обеспечения САПР. Вдохновением для нее послужило внедрение концепции BOM (Bill of Materials) из машиностроения в строительную отрасль. Это нововведение последовало за появлением в 2002 году программного обеспечения Revit® CAD, которое было разработано той же командой, что и Pro/ENGINEER для машиностроения (концепция BOM), но было специально адаптировано для строительной отрасли [12]. Pro/ENGINEER произвел революцию на рынке MCAD (Mechanical Computer Aided Design). Элементное параметрическое моделирование, лежащее в основе Pro/ENGINEER, доминировало в отрасли на протяжении четверти века, и все ведущие MCAD-системы стали концептуальными преемниками Pro/ENGINEER.
Цитата :
Цель состоит в том, чтобы создать систему, которая была бы достаточно гибкой, чтобы побудить инженера легко рассматривать различные конструкции. А затраты на внесение изменений в проект должны быть как можно ближе к нулю. Традиционные CAD / CAM программное обеспечение того времени нереально ограничивает внесение недорогих изменений только в самый начальный этап процесса проектирования

Самуэль Гейзенберг — основателя компании PTC, разработчика MCAD-продукта Pro/ENGINEER и наставника Леонида Райца, создателя Revit

Уже в конце 1980-х годов цель состояла в устранении ограничений, существовавших в тогдашних CAD-программах. Основной задачей было снизить трудозатраты на внесение изменений параметров элементов проекта и обеспечить возможность обновления модели на основе данных вне CAD программ. При этом ключевую роль должна была играть параметризация задачи и автоматическое поступление параметров из базы данных для актуализации модели в CAD-системе.
В машиностроении и, в частности, в MCAD-продукте Pro/ENGINEER - PDM и PLM системы стали ключевыми платформами в начале 2000-х годов, собирая информацию из CAx (автоматизированных технологических систем) и моделируя управление проектами с помощью BOM (eBOM, pBOM, mBOM), минимизируя ошибки и дублирование данных.

   Рисунок 2.1-14. BOM родился в 1960 году из необходимости использовать данные из CAx-систем в системах управления данными.
С середины 2000-х годов активное продвижение концепции BIM-BOM в строительной отрасли значительно повысило интерес к программному обеспечению Revit® (BOM-BIM), и рост популярности во многих странах был настолько массовым, что Revit® практически вытеснил другие CAD-программы в области планирования, "закрепив" свое доминирование на мировом рынке САПР (BIM) к началу 2020-х годов [13].
На сайте с опубликованным WhitePaper по BIM компания Autodesk фактически воспроизвела маркетинговые материалы концепта BOM (Bills of Materials) из продуктов Pro/ENGINEER, использованных ещё в начале 1990-х годов.
BIM описывается как управление информацией о здании, где все обновления и все изменения происходят в базе данных. Таким образом, имеешь ли ты дело со схемами, разрезами или чертежами на листах, все всегда скоординировано, согласовано и актуально.

В стандарте ISO 19650 аббревиатура BIM также упоминается, но к сожалению не имеет чёткого определения. Понимание же специалистов того что за CAD (BIM) скрываются базы данных, могут быть в последствии недовольны BSI за усложнение стандартного процесса ETL, который был переименован в строительстве в расплывчатую терминологию БИМ.
Пользователи и разработчики в строительной отрасли, подобно своим коллегам из других отраслей экономики, будут неизбежно отходить от расплывчатой терминологии поставщиков ПО, которая доминировала последние 20 лет, сосредотачиваясь на ключевых аспектах цифровизации — «данных» и «процессах». 



   Рисунок 2.1-15. Популярность поискового запроса в Google: "Revit®" (BOM-BIM) набрал популярность практически в большинстве стран мира
Современная маркетинговая концепция BIM (Building Information Modeling), представляет собой интегрированную в САПР (BIM) программы базу данных, содержащую исчерпывающую информацию об элементах проекта. 


Эти проблемы с изобретением «нового велосипеда» в строительной отрасли во многом связаны с отсутствием доступа к данным. Это привело к постоянной разработке новых квазиформатов и технологий, в то время как другие отрасли давно и успешно работают с открытыми, устоявшимися форматами данных и оптимизированными процессами.
Эра «новых изобретений» в строительстве началась с концепции маркетингового BIM, которую представили поставщики САПР. За ней последовало продвижение openBIM, также созданного и запатентованного теми же вендорами. И в результате большая часть сообщества разработчиков - купившись на грамотный маркетинг с аббревиатурой «открытый» - решила, что это единственно возможный способ работы с данными. Но, к сожалению, openBIM выглядит как подход «разделяй и властвуй», при котором интересы вендоров ставятся во главу угла, а не общеиндустриальное сотрудничество.

Что нам действительно нужно, так это не больше CDE или новых форматов, а скорее возможность эффективно работать с базами данных проектов, как это принято в других отраслях. Вместо того чтобы изобретать колесо, нам следует сосредоточиться на внедрении проверенных методов эффективной и открытой работы с проектными данными, которые ничем не отличаются от других данных в других отраслях. 



В такой базе данных не только хранится геометрия элементов, но и регистрируются дополнительные атрибуты и свойства каждого элемента, предназначенные для передачи и экспорта во внешние системы. Особенностью баз данных САПР (BIM), отличающей их от других систем и баз данных, используемых в строительстве, является необходимость использования специализированных инструментов для доступа к этим данным.
Поскольку в BIM (CAD) данные геометрической информации и атрибутивная метаинформация теперь находятся в одном формате, а не разбиты на файлы уже существующих форматов (полуструктурированные и структурированные форматы), специалистам приходится использовать специализированные BIM-инструменты, которые помогают работать с этими особыми BIM-форматами.
Для хранения проектных данных современные САПР (BIM) программы обычно предлагают использовать закрытые форматы данных, доступ к которым пользователь может получить только через дополнительные платные САПР (BIM) инструменты или ограниченные API (Application Programming Interface) соединения (рис. 2.1-16). API — это инструмент запроса и посредник, который позволяет различным компьютерным программам взаимодействовать друг с другом, отправляя запросы и получая ответы.
Любая система автоматизированного проектирования (BIM) предлагает качественный и безопасный способ работы с данными, что облегчает создание цепочек автоматизации и обработки данных, но этот процесс сопровождается необходимостью приобретать подписки и платить за каждый запрос данных.
Кроме того, поставщики САПР (BIM) предоставляют возможность экспорта некоторых данных проекта в полуструктурированные форматы или открытый формат IFC (IGES-STEP). 
Проблемы качества данных и сложность полуструктурированного "открытого BIM" формата IFC не позволяют напрямую использовать эти данные для автоматизации и анализа процессов, обработки данных, что часто приводит разработчиков к неизбежной необходимости использования закрытых BIM-решений с "качественным" доступом к данным [10].

   Рисунок 2.1-16. В то время как другие отрасли работают с открытыми данными, строительная отрасль вынуждена работать с закрытыми или полуструктурированными форматами САПР (BIM)
Редакторы векторной графики, например, Adobe® Illustrator, схожи с программами для создания конструкционных чертежей, основное отличие которых заключается в параметре высоты у 3D элементов, позволяющем вычислять их объем. Изначально оба направления полагались на проприетарные форматы файлов, такие как PSD, AI, NEF, CR2 и TIFF, что аналогично строительным форматам RVT, DWG, PLN, SKP и NWS для строительства, но со временем появились открытые форматы (например, GIMP, OpenEXR для графики и IFC, CPIXML для строительства), способствующие более легкому обмену и совместимости данных. 
Без свободного доступа к качественным структурированным данным в будущем невозможно будет выстроить эффективные процессы и автоматизировать их. Поэтому первоочередной задачей станет открытие, упорядочение, унификация и организация данных, что создаст основу для автоматизации и оптимизации бизнес-процессов.
Открытые форматы, такие как JPEG и PNG, стали стандартом для обмена изображениями благодаря их универсальности и широкой поддержке, упрощая их использование на разнообразных платформах. Аналогичный переход наблюдается в видео и аудио, где универсальные форматы, как MPEG и MP3, выделяются за эффективность сжатия и широкую совместимость. Этот переход к стандартизации упростил обмен и воспроизведение контента и информации, сделав их доступными для всех пользователей на различных платформах (рис. 2.1-17).
Строительной отрасли еще предстоит договориться о принятии общего упрощенного формата данных для использования вне платформ САПР (BIM). Например, многие крупные компании в Центральной Европе и немецкоязычных регионах, работающие в строительном секторе, используют формат CPIXML в своих ERP-системах [26]. Этот формат, представляющий собой разновидность XML, известный как CPIXML, объединяет все данные проекта САПР (BIM), включая геометрические и метаданные, в единую организованную структуру. 

Мы рассмотрим подходы, при которых данные проекта САПР (BIM) разделяются на структурированные табличные форматы (XLSX, CSV) для метаданных, а менее структурированные геометрические данные выделяются в отдельный формат (рис. 2.1-17), содержащий только геометрическую информацию (XML, OBJ, DAE, GLTF). Наличие уникальных идентификаторов для связи этих двух файлов, метаданных и геометрических данных, позволяет независимо управлять атрибутивной информацией проекта. Такая система также позволяет использовать дополнительные визуализации геометрических элементов в различных бизнес-логиках по мере необходимости.

   Рисунок 2.1-17. Упрощенные форматы без сложных функций редактирования, стали популярными для обмена и использования данных
Изучение основных типов данных и осознание различий между структурированными, полуструктурированными и неструктурированными данными позволяет понять уникальную роль каждого из них в информационных бизнес-процессах. Понимание функций и масштабов использования каждого типа данных имеет ключевое значение.

ГЛАВА 2.2 
ОТКРЫТЫЕ ДАННЫЕ И СТАНДАРТЫ
Хранилище данных 
Хранилища данных собирают и объединяют данные со всего предприятия, часто из нескольких систем обработки транзакций, каждая из которых имеет собственную базу данных. Аналитические системы могут работать с хранилищами данных. Хранилища данных можно рассматривать как технологию, облегчающую добычу данных. Это не всегда необходимо, так как большинство аналитических систем не обращаются к хранилищу данных, но компании, решившие инвестировать в хранилища данных, часто могут применять аналитику данных более широко и более глубоко в организации. Например, если хранилище данных объединяет записи из отделов продаж и выставления счетов, а также из отдела кадров, его можно использовать для поиска характерных особенностей эффективных продавцов.
Почему файлы — это прошлое
До сих пор строительные компании оперировали файлами. PDF-документы, чертежи в DWG, модели в RVT, сметы в Excel — вся информация о проекте хранится в разрозненных форматах, требующих ручного поиска, сверки и анализа.
Файл — это контейнер, внутри которого находятся данные. Но сам по себе файл ничего не значит, пока из него не извлечена и не обработана информация. Тонны файлов на серверах строительных компаний чаще всего остаются неизмененными после завершения проекта, превращаясь в "цифровые кладбища" информации.
Наступает новый этап: переход от файлового управления к данному управлению. Это не просто удобство — это стратегический сдвиг, который уже начинает менять строительную индустрию.

2. Файлы vs. данные: ключевые различия
Файлы и данные — это не одно и то же. Разница между ними лежит в гибкости использования и доступности информации.
ФайлыДанныеЗакрытые структурыОткрытые и доступные потоки информацииХранятся в папках, доступ к которым имеют единицы сотрудниковДоступны в централизованных базах и могут использоваться в разных процессахТребуют ручного поиска, открытия и анализаАвтоматически обрабатываются и анализируются в реальном времениСложны в интеграции между системамиЛегко объединяются и сопоставляются для аналитикиСтроительная отрасль стоит перед выбором: продолжать работать с отдельными файлами или извлекать из них данные, создавая новый цифровой фундамент для управления проектами.

3. Данные уже есть: где их искать
Компании уже генерируют колоссальные объемы информации, но зачастую они остаются скрытыми в файлах. Вот основные источники данных, которые можно использовать уже сегодня:
• BIM-модели (Revit, ArchiCAD, Tekla) — содержат геометрию, свойства элементов, объемы материалов.
• Сметы (Excel, ERP) — включают стоимости, нормы расхода, цены на материалы.
• Графики работ (Primavera, MS Project) — показывают последовательность выполнения задач.
• Фактические данные (IoT, датчики, камеры) — мониторинг процессов на стройплощадке.
Проблема не в отсутствии данных, а в том, что они остаются неструктурированными и недоступными для анализа.

4. Почему управление данными повышает эффективность
Работа с файлами — это постоянные потери времени. Проверка объемов, поиск актуальных версий документов, ручная сверка данных требуют сотен часов.
Но если данные структурированы и доступны в одном месте, компания получает существенные преимущества:
✅ Автоматическое сопоставление смет и BIM-моделей.
✅ Гибкое обновление графиков работ в зависимости от фактической ситуации.
✅ Прогнозирование затрат на основе исторических данных.
✅ Упрощенная проверка качества и соответствия данных.
Это не будущее — это реальность, которая становится доступной компаниям, готовым выйти за рамки файлового мышления.

5. Как перейти от файлов к данным
Переход к управлению данными не требует сложных изменений. Достаточно сделать три ключевых шага:
1️⃣ Освободить данные из файлов.
Перевести данные в открытые структуры — таблицы, базы данных, JSON, Parquet.
2️⃣ Создать единую среду для работы с данными.
Использовать ETL-процессы, DataFrame-структуры и SQL для организации данных.
3️⃣ Автоматизировать обработку и аналитику.
Настроить системы, которые автоматически анализируют данные, а не требуют ручной работы с файлами.

6. Заключение: данные — новая нефть строительной индустрии
В ближайшие годы компании, которые научатся извлекать данные из файлов и использовать их для автоматизации процессов, получат конкурентное преимущество.
Те, кто продолжит работать в "файловом" формате, рискуют отстать в гонке за эффективностью.
❓ Готова ли ваша компания перейти от файлов к данным? 🚀


Наполнение систем данными в строительной отрасли
В
 контексте компаний строительной отрасли мы ежедневно сталкиваемся с огромным количеством различных бизнес-кейсов и систем управления данными, которые необходимо наполнить разноформатной информацией.
Будь то крупные корпорации или средние компании, высококвалифицированные специалисты ежедневно занимаются наполнением программных систем с различными интерфейсами информацией, которая с помощью менеджеров должна слаженно взаимодействовать друг с другом. Именно этот комплекс взаимодействующих систем и процессов в конечном итоге делает компанию прибыльной.
Каждая из категорий систем, о которых мы говорили ранее и которые используются в строительной отрасли, загружает и обрабатывает различные типы данных, характерные для их функций. К существующему списку систем и типов данных (рис. 1.2-2) мы добавим типы форматов и документов:
• Инвестор (CAPEX)
-	Финансовые данные: бюджеты, прогнозы расходов (структурированные данные).
- Данные о тенденциях рынка: анализ рынка (структурированные и неструктурированные данные).
- Юридические и договорные данные: контракты (Текстовые данные).
• Системы управления (PMS, CAFM, CQMS)
- Данные проекта: графики, задачи (структурированные данные).
- Данные о техническом обслуживании объекта: планы технического обслуживания (текстовые и полуструктурированные данные).
- Данные контроля качества: стандарты, отчеты о проверках (текстовые и неструктурированные данные).
• CAD, FEM и BIM
- Технические чертежи: архитектурные, структурные планы (геометрические данные, неструктурированные данные).
- Модели зданий: 3D-модели, данные о материалах (геометрические и полуструктурированные данные).
- Инженерные расчеты: анализ нагрузки (структурированные данные).



• Системы управления строительной площадкой (EHS, SCM)
- Данные о безопасности и здоровье: протоколы безопасности (текстовые и структурированные данные).
- Данные о цепочке поставок: запасы, заказы (структурированные данные).
- Ежедневные отчеты: рабочее время, производительность (структурированные данные).
• Беспилотники, AR/VR, ГИС, 3D-печать
- Геоданные: топографические карты (геометрические и структурированные данные).
- Данные в реальном времени: видео и фотографии (неструктурированные данные).
- Модели для 3D-печати: цифровые чертежи (геометрические данные).
• Дополнительные системы управления (4D BPM, 5D ERP1)
- Данные о времени и затратах: графики, сметы (структурированные данные).
- Управление изменениями: записи об изменениях в проекте (текстовые и структурированные данные).
- Отчетность о результатах деятельности: показатели успеха (структурированные данные).
• Интеграция данных и связь (CDE, RFID, AMS, RPM)
- Обмен данными: обмен документами, модели данных (структурированные и текстовые данные).
- RFID и данные отслеживания: логистика, управление активами (структурированные данные).
- Мониторинг и контроль: датчики на объектах (структурированные и неструктурированные данные).
Структурированные данные характеризуются простотой поиска и анализа, в то время как обработка полуструктурированных и неструктурированных данных требует более совершенных инструментов и методов для эффективного поиска и дополнительных усилий для их понимания и интерпретации.
В конечном итоге инженеры по работе с данными в каждой компании сталкиваются с широким спектром различных форматов документов, где каждый тип данных требует индивидуального подхода.

Различия в объемах данных
С
егодня большинство компаний сталкиваются с непростой дилеммой: около 80% их ежедневных бизнес-процессов основаны на традиционных структурированных данных [15]. Однако 80 % новой информации, поступающей в системы и процессы компании, является неструктурированной [16].

Более того, объем неструктурированных данных в организациях увеличивается на 55-65% ежегодно [17]. 


   Рисунок 2.2-2. Ежегодный рост объема неструктурированных данных на 60% создает проблемы с интеграцией потоковой информации в бизнес-процессы
Игнорирование неструктурированных данных в процессах автоматизации может привести к значительным пробелам в информационном ландшафте компании.
В современном мире неконтролируемого и лавинообразного движения информации компаниям необходимо применять гибридный подход к управлению данными, включающий эффективные методы работы со всеми типами данных.
Ключ к эффективному управлению данными лежит в организации и классификации различных типов "Вавилона" данных включая неструктурированные, текстовые и геометрические форматы, в полуструктурированные или структурированные данные. 
Этот процесс преобразует хаотичное множество данных в организованные структуры для интеграции в системы, тем самым облегчая принятие решений на их основе. Для ИТ-специалистов и менеджеров по управлению данными основная задача заключается в том, чтобы справиться с этой сложностью и создать структурированные системы с общим языком запросов, на основе которых можно создавать индивидуальные решения, основанные на данных.

   Рисунок 2.2-3. Основная задача отделов управления данными - перевести «Вавилон» разнообразных форматов данных в структурированные системы 
Отчет Национального института стандартов и технологий (NIST, США) подчеркивает, что низкая совместимость данных между различными строительными платформами ведет к потере информации и значительным дополнительным затратам. В исследовании отмечается, что стандартизация форматов данных может сократить эти потери и повысить эффективность работы на всех этапах жизненного цикла объекта.


Этот процесс преобразования - не просто техническая задача; это критически важный шаг к тому, чтобы данные служили своей конечной цели - поддержке стратегических бизнес-решений. ИТ-специалисты и менеджеры по управлению данными должны просеивать и упорядочивать разноформатные данные, чтобы обеспечить их точность, доступность и значимость для организации. Их роль похожа на роль переводчика, который переводит различные диалекты и языки данных на язык общего знаменателя, понятный и используемый всей компанией.

ГЛАВА 2.3. 
Унификация и структурирование данных

REV Появление семантики и онтологии в строительстве
Стандартизация и унификация в строительстве заимствовали внедрение семантики и онтологии у концепции семантической паутины в конце 1990х. Эта концепция была адаптирована в контексте buildingSMART для стандарта IFC. Основная идея семантики заключается в том, что данные должны иметь смысл не только для человека, но и для машин, позволяя им "понимать" информацию, а не просто передавать её. Онтология, в свою очередь, создаёт чёткие определения терминов и их взаимосвязей, что обеспечивает единую основу для всех систем.
buildingSMART попытался масштабировать этот подход на всю строительную отрасль. В одном из ключевых документов о будущем формата IFC5 под названием "Future of the Industry Foundation Classes: towards IFC 5" семантический подход упоминается 32 раза, подчёркивая его значимость для дальнейшего развития стандарта.
Особенно в области Семантического веба много сил было вложено в преобразование, модулизацию и упрощение схемы (или онтологии; по типичной идиоме в этой области) IFC. Начиналось все с прямого преобразования схемы IFC EXPRESS и модификаций, которые привели к созданию более идиоматичной онтологии (Beetz et al. 2009), а также анализов, направленных на внедрение модульности (Terkaj and Pauwels 2017).
Цель buildingSMART  — создать единый универсальный стандарт для описания объектов и их взаимосвязей. Такой подход должен быть применим по всему строительному миру, обеспечивая унификацию данных и улучшая их интерпретацию различными системами. Покупка членства в buildingSMART даёт компаниям-участникам не просто возможность приобщиться к будущему, но и активно влиять на его формирование уже сегодня. 

Рис. 23. Цитата 1994 года председателя международного совета директоров BuildingSMART
Однако внедрение семантики и онтологий не всегда приводит к успеху. Реальность оказалась куда сложнее. В игровой индустрии попытки описать игровые объекты и взаимодействия через онтологии столкнулись с проблемами из-за высокой динамики изменений и креативной природы отрасли. В результате стандартные форматы данных (XML, JSON) и алгоритмы оказались более эффективными. Аналогичная ситуация наблюдалась на рынке недвижимости, где разнообразие локальных терминов и быстрые изменения сделали онтологии избыточно сложными. Простые базы данных и стандарты, такие как RETS, лучше справлялись с задачами обмена и обработки данных.
Не следует привлекать новые сущности без крайней на то необходимости
Бри́тва О́ккама 
Технические трудности, такие как сложность разметки и высокая трудоёмкость поддержки, а также низкая мотивация разработчиков, тормозили развитие этой идеи в других отраслях экономики. RDF (Resource Description Framework) не стал массовым стандартом, а онтологии оказались избыточно сложными и экономически неоправданными. В результате амбиции по созданию глобального семантического веба не оправдались. Некоторые идеи были адаптированы в корпоративных решениях, но изначальная цель создания единого всеобъемлющего графа так и не была достигнута.

Рис. 24. Сравнение реляционных и онтологических баз данных
Онтологии и семантические технологии обещали создать смысл из данных, но на практике они работают скорее как механизм унификации и стандартизации. Переход от таблиц к графам данных позволяет улучшить поиск и унифицировать модель данных, но не делает данные более осмысленными для машин. Вопрос не в том, нужно ли использовать семантические технологии, а в том, где они действительно приносят пользу.
Интерес к семантическим технологиям и онтологиям в строительстве поддерживается благодаря инициативам buildingSMART. Однако необходимость полной формальной логики и создание единой онтологии для всей отрасли остаётся спорным моментом. Опыт проектов CYC ("encyclopedia") и семантического веба показывает, что отказ от идеи единой универсальной онтологии в пользу локальных микротеорий, применимые только в рамках конкретной задачи, проекта или компании, может быть более продуктивным подходом.

REV Семантика и онтология: как заставить данные говорить?
Благодаря усилиям buildingSMART, семантика и онтологии стали не только ключевой идеей, лежащей в основе стандартизации, управляемой CAD-вендорами, но и фундаментом для таких проектов, как SCOPE, продвигаемый Züblin (Strabag), и направленный на освобождение строительной отрасли от зависимости CAD-систем.
Семантические технологии это унификация, стандартизация и модификация больших массивов разнородных данных, а также реализация сложного поиска. Однако семантика никак не связана с созданием нового смысла или знаний — в этом плане они ничем не превосходят другие технологии хранения и обработки данных.
Представление данных из реляционной базы данных в виде набора триплетов не добавляет осмысленности самим данным. Замена таблиц на граф может быть полезна для унификации модели данных, реализации сложного поиска и безопасной модификации бизнес-моделей. Однако это не делает данные более "умными" — компьютер не начинает лучше понимать их смысл.
Когда дело доходит до хранения «OWL-данных», эти данные хранятся с помощью RDF-триплетов (RDF — Resource Description Framework и OWL — Web Ontology Language). 

Рис. 25. Графовая модель данных: узлы (Nodes), связи (Edges) и тройки (Triples), иллюстрирующие отношения между строительными элементами
Теоретически, логический вывод ризонеров (программы для автоматического логического вывода) позволяет получать новые утверждения на основе онтологий. Например, если в строительной онтологии записано, что "фундамент — это опора для стены", а "стена — это опора для крыши", ризонер способен автоматически сделать вывод, что "фундамент — это опора для крыши". Этот механизм действительно полезен для оптимизации анализа данных, поскольку исключает необходимость явно прописывать каждую зависимость. Однако, это не создание новых знаний, а лишь автоматическое сопоставление уже известных фактов.
Логические связи в онтологии, если они нужны, можно организовать и без сложных семантических технологий, например, используя реляционные базы данных (SQL) или таблицы CSV и XLSX. В колончатых базах данных и форматах можно добавить колонку "опора крыши" и программно обеспечить добавление факта связи крыши с фундаментом при создании стены. Это достигается без применения RDF, OWL, графов или ризонеров.

Рис. 26. Сравнение графовой и табличной моделей представления одних и тех же логических связей
Решение buildingSMART и Strabag (Zublin) следовать концепции семантического веба, который в конце 1990х казался перспективным и популярным, повлияло на всю строительную отрасль. Однако, парадокс в том, что сама концепция семантического веба, изначально предложенная для интернета, не получила широкого применения даже в своей родной среде. В интернете, для которого и разрабатывались RDF и OWL, эти концепции сегодня практически не используются. Полноценного семантического веба в изначальной архитектуре так и не появилось, и его создание уже возможно не предвидится.
Идея создания интернета, где компьютеры будут понимать смысл контента, оказалась слишком сложной и экономически невыгодной. Именно поэтому корпорации, которые первоначально поддерживали семантический веб, оставили только полезные элементы технологии — такие как онтологии и SPARQL — и применили их для корпоративных целей, а не для интернета в целом. Если посмотреть в Google Trends, например за последние 20 лет, можно увидеть что перспектив там возможно уже не осталось.

Рис. 27. Интерес к теме семантического интернета согласно статистики Google запросов
Здесь возникает логичный вопрос: зачем вообще использовать триплеты, ризонеры и SPARQL в строительстве, если можно обрабатывать данные с помощью популярных структурированных запросов (SQL, Pandas, Apache)? В корпоративных приложениях SQL является стандартом для работы с базами данных. SPARQL, напротив, требует сложных графовых структур и специализированного программного обеспечения и по трендам в Google не привлекает к себе интереса разработчиков. 
Графовые базы данных и деревья классификаций могут быть полезны в отдельных случаях, но их применение не всегда оправдано для большинства повседневных задач. В итоге, создание графов знаний и использование технологий семантического веба имеет смысл только в тех случаях, когда требуется унифицировать данные из разных источников или реализовать сложные логические выводы. Для повседневных задач, таких как управление строительными данными, реляционные базы данных, CSV, SQL и Excel остаются более простыми, доступными и эффективными инструментами.
REV От графов к таблицам: трудозатраты в группировки и фильтрации
Любая онтология и отношение фундаментально описывает параметры элементов и сущностей проекта с помощью пар «ключ-значение».  Вопрос лишь в том, как передать эти параметры словарей ключ-значение и в какой форме. Различие заключается не в механизме хранения или структуре, а в глубине семантического понимания и способности устанавливать значимые связи между понятиями. Является ли экспресс-разметка и онтология IFC идеальным инструментом для этого - большой вопрос. 

Рис. 28. Информация о сущностях элементов хранится в форме ключ-значения в виде различных форм представления
В других отраслях экономики существуют те же самые элементы с параметрами, геометрическими формами и аналогичные проблемы передачи онтологии. Однако специалисты этих отраслей передают метаинформацию с использованием популярных форматов, таких как XML, DB, JSON, CSV, HD5 и XLSX. Возникает логичный вопрос: почему в строительной отрасли мы решили передавать метаинформацию с помощью технологий, разработанных ещё в 70-х годах для формата IGES-STEP в построчной EXPRESS разметке, которая была придумана ещё во времена перфокарт? Да, существуют конвертеры для преобразования данных из IFC в JSON, XML, CSV или XLSX. Однако возникает вопрос — зачем вообще использовать промежуточный этап с IFC? 
Гораздо логичнее выгружать данные из CAD-программ напрямую в JSON, XML или структурированные форматы CSV/XLSX с помощью SDK реверсинжениринга, которыми пользуются все CAD вендоры без исключения. В таком случае использование IFC как промежуточного этапа теряет смысл. И если разницы в полноте информации между графами и таблицами нет, то выбор будет сводиться только к выбору схемы данных и формата записи. 
Форма и схема данных должна подходить под кейс использования для решения тех или иных задач. 

Рис. 29. Графовая и табличная структура содержат идентичную информацию о элементах проекта
Семантический, графовый формат лишь упрощает создание новых связей, то есть позволяет добавлять в граф новые типы данных без каких-либо изменений в структуре хранилища. 
По сравнению с реляционными таблицами в графе нет никакой особой, дополнительной связанности данных — перевод данных двумерных баз данных в граф не увеличивает количество связей и не позволяет получить новую информация. 
Для получения данных в бизнес процессах мы должны стремится использовать те инструменты, которые помогают максимально быстро и просто получить результат.
Сегодня большинство крупных компаний используют отдельные модели данных для каждого приложения, а таких приложений у них сотни или даже тысячи. Эти модели сложны: каждая из них минимум в 10 раз сложнее, чем необходимо, а все вместе – в 100–1000 раз.
Сложность модели данных – это всё, что разработчики и пользователи должны изучить, чтобы освоить систему. В реляционных базах это таблицы и столбцы, в объектно-ориентированных системах – классы и их свойства, в XML или JSON – уникальные элементы и ключи.
Чем больше элементов в модели, тем больше кода нужно написать и протестировать. Это также усложняет работу пользователей, так как каждый элемент рано или поздно появляется в интерфейсе и требует понимания.

Среди различных широко используемых сегодня форматов открытые структурированные данные не только завоевали популярность, но и стали стандартом в области обработки данных.

REV Открытые структурированные данные
П
ереход от неуправляемого потока данных к их эффективной интеграции в бизнес-процессы начинается с преобразования данных из закрытых форматов в открытые. 
В научных исследованиях принцип обмена открытыми данными ускоряет открытие и облегчает международное сотрудничество. 
В медицине обмен информацией между учреждениями приводит к повышению эффективности диагностики и лечения. В информационных технологиях приложения с открытым исходным кодом позволяют разработчикам по всему миру совместно совершенствовать программное обеспечение.
Одним из главных преимуществ открытых данных является их способность устранить зависимость разработчиков приложений от конкретных платформ для доступа к данным.
В вопросе выбора между открытыми и закрытыми данными эксперты, очевидно, отдают предпочтение открытой форме данных, равно как и структурированным данным в процессах автоматизации, обработки и хранения данных (рис. 2.2-4). Открытые и структурированные данные часто используются по умолчанию в большинстве систем из-за простоты их обработки и однозначной интерпретации, что делает их наиболее предпочтительным типом для коммуникации и совместной работы на уровне требований и бизнес-процессов.

   Рисунок 2.2-4. Открытые структурированные данные снижают зависимость от платформ и ускоряют инновации
В контексте строительной отрасли открытые структурированные данные обеспечивают плавные и скоординированные бизнес-процессы, в рамках которых команды могут сосредоточиться на оптимизации проектов, а не на борьбе с несовместимыми форматами данных, платформами и системами.
Хотя в строительной отрасли уже существует предложенное в ISO 19650 решение для управления проектными данными – общая среда данных (Common Data Environment, CDE), по сути, этот стандарт не предлагает ничего принципиально нового по сравнению с хранилищами данных (DWH - Data Warehouse), которые давно используются в других отраслях.
Финансовый сектор, ритейл, логистика и промышленность десятилетиями применяют централизованные системы управления данными, обеспечивающие агрегацию, валидацию и анализ информации. В строительстве CDE лишь копирует эти принципы, адаптируя их под специфику проектирования и жизненного цикла зданий.
Как и классические DWH, CDE объединяет данные из множества источников, обеспечивая единый доступ ко всей проектной информации. В нем также контролируется релевантность данных, фиксируются изменения, а пользователи работают с единой проверенной информацией. Более того, CDE, как и современные DWH-инфраструктуры, все чаще строится на облачных технологиях и интегрируется с аналитическими инструментами.
Добавим к CDE гранулированные данные, о которых начали говорить CAD-вендоры еще в 2013 году (ссылка), и в итоге CDE с гранулированными данными будет мало чем отличаться от DWH на структурированных данных. Этот переход еще больше стирает границы между хранилищами данных в строительстве и других отраслях, подчеркивая, что индустрия просто догоняет давно сложившиеся подходы.
Подробнее про гранулированные данные, DWH и другие системы хранения мы рассматриваем в следующих главах.
Сделай настолько просто, насколько это возможно, но не проще.
 Альберт Эйнштейн физик-теоретик

Большинство пользовательских интерфейсов (80–90%) в современных приложениях можно сгенерировать автоматически на основе модели, без необходимости писать отдельный код для каждого из них. Достаточно создать или использовать инфраструктурный слой, который сможет интерпретировать эти модели. Как только эта основа настроена, новые интерфейсы можно развертывать без дополнительного программирования.
Разумеется, существуют ключевые интерфейсы с высокой ценностью и активным использованием, которые могут потребовать ручной доработки. Однако стремиться к полной автоматизации не обязательно — разумнее сосредоточиться на достижении 90%. Такой подход позволяет не только сократить объем кода, но и уменьшить число дефектов, а также снизить будущие расходы на поддержку системы.


Для преобразования данных в структурированный формат существует широкий спектр инструментов, среди которых одним из самых популярных является библиотека языка Python - Pandas. Благодаря своей гибкости и широкой функциональности Pandas стала незаменимым инструментом для специалистов по анализу данных, автоматизации и аналитике, облегчая процесс превращения сырых данных в ценную информацию. В следующих главах мы рассмотрим практические примеры, использующие библиотеку Pandas вместе с инструментом ChatGPT, и подробно разберем их функциональные возможности.

ГЛАВА 2.3 
PANDAS DATAFRAME И LLM CHATGPT
Колончатые базы данных и структуированные форматы 

Pandas: незаменимый инструмент для работы с данными
P
andas - это библиотека Python с открытым исходным кодом, предоставляющая высокопроизводительные, простые в использовании структуры данных и средства анализа данных. Библиотека Pandas, занимает особое место в инструментарии для работы с данными, став одной из самых популярных и востребованных в этой области [18]. Язык запросов в библиотеке Pandas по своей функциональности похож на язык запросов SQL, который мы рассматривали в главе "Реляционные базы данных и язык запросов SQL".
В мире аналитики и управления структурированными данными Pandas выделяется своей простотой, скоростью и мощностью, предоставляя пользователям широкий спектр инструментов для эффективного анализа и обработки информации.
Оба инструмента - SQL и Pandas - предлагают мощные возможности для работы с данными, включая выборку, фильтрацию (рис. 2.3-2), сортировку и группировку данных. 

   Рисунок 2.3-2. Pandas, в отличие от SQL, обладает гибкостью в работе с различными форматами данных, не ограничиваясь базами данных
Pandas часто предпочитают использовать в научных исследованиях, автоматизации процессов, создании конвейеров и манипулировании данными на Python, в то время как SQL является стандартом управления базами данных и часто используется в корпоративных средах для работы с большими объемами данных.
Библиотека Pandas языка программирования Python позволяет выполнять не только базовые операции, такие как чтение и запись таблиц, но и более сложные задачи, включая объединение данных, группировку данных и проведение сложных аналитических расчетов. 
Pandas можно сравнить со швейцарским ножом для аналитиков и инженеров данных. По состоянию на январь 2024 года количество загрузок библиотеки Pandas составляет около 6,2 миллиона в день [18].
Используя Pandas, вы можете управлять и анализировать наборы данных, намного превосходящие возможности Excel. В то время как Excel, как правило, способен обрабатывать до 1 миллиона строк данных, Pandas может без труда работать с наборами данных, содержащими десятки миллионов строк [19]. Эта возможность позволяет пользователям выполнять сложный анализ данных и визуализацию на больших наборах данных, обеспечивая глубокое понимание и облегчая принятие решений на основе данных. Кроме того, Pandas имеет сильную поддержку сообществ: сотни миллионов [20] разработчиков и аналитиков по всему миру (Kaggle.com, Google Collab, Microsoft Azure Notebooks, Amazon SageMaker) ежедневно используют его онлайн или офлайн, предоставляя большое количество готовых решений для любых бизнес-задач.

DataFrame: универсальный формат табличных данных
D
ataFrame в библиотеке Pandas - это название двумерной таблицы данных с гибкой структурой данных. DataFrame организован как таблица, в которой каждый столбец содержит данные одного типа (например, числа, строки, даты), а каждая строка представляет собой отдельный набор данных, или запись.
DataFrame — это способ организации данных в таблицу, очень похожую на ту, которую вы можете увидеть в Excel. В этой таблице строки представляют собой отдельные записи или объекты, а столбцы - различные характеристики или атрибуты этих объектов.

В примере с таблицей, содержащей информацию о строительном проекте, строки рассматриваются как представление сущностей - элементов проекта, а столбцы атрибутов отражают категории, параметры, позиции или координаты элементов ограничительного поля.

   Рисунок 2.3-3. Строительный проект в виде DataFrame — это двумерная таблица с элементами в строках и атрибутами в столбцах

Обработка данных - это то, чем занимается, наверное, треть всех мировых вычислений в каждой компании. Обработка данных и данные большинства компаний находятся в DataFrames в табличном формате.  
Генеральный директор Nvidia Дженсен Хуанг
18 августа 2024 г. SIGGRAPH 2024









Перечислим некоторые ключевые особенности и функциональность DataFrame в Pandas:
● Столбцы: в DataFrame данные организованы в столбцы, каждый из которых имеет уникальное имя. Столбцы-атрибуты могут содержать данные различных типов, подобно столбцам в базах данных или столбцам в таблицах.
● Pandas Series - — это одномерная структура данных в Pandas, похожая на список или колонку в таблице, где каждому значению соответствует свой индекс
● Строки: в DataFrame могут быть проиндексированы уникальными значениями, известными как индекс Series (колонки) или DataFrame. Этот индекс позволяет быстро изменять и корректировать данные в определенных строках.
● Индекс: по умолчанию при создании DataFrame Pandas присваивает каждой строке индекс от 0 до N-1 (где N - количество всех строк в DataFrame). Однако индекс можно изменить, чтобы включить в него особые обозначения, такие как даты или уникальные характеристики.
● Индексирование строк в DataFrame означает, что каждой строке присваивается уникальное имя или метка, которая называется индексом DataFrame.
● Типы данных: DataFrame поддерживает различные типы данных, включая: `int`, `float`, `bool`, `datetime64` и `obect` для текстовых данных. Каждый столбец DataFrame имеет свой собственный тип данных, который определяет, какие операции можно выполнять над его содержимым.
● Операции с данными: DataFrame поддерживает широкий спектр операций для обработки данных, включая агрегирование (`groupby`), слияние (`merge` и `join`), конкатенацию (`concat`), разделение-применение-комбинирование и многие другие методы преобразования данных.
● Манипулирование размерами: DataFrame позволяет добавлять и удалять столбцы и строки, что делает его динамической структурой, которая может быть изменена в соответствии с потребностями анализа данных.
● Визуализация данных: используя встроенные методы визуализации или взаимодействуя с популярными библиотеками визуализации данных, такими как Matplotlib или Seaborn, DataFrame можно легко преобразовать в графики и диаграммы, чтобы представить данные в графическом виде.
● Ввод и вывод данных: Pandas предоставляет функции для чтения импорта и экспорта данных в различные форматы файлов, такие как CSV, Excel, JSON, HTML и SQL, что делает DataFrame центральным узлом для сбора и распространения данных.

В Pandas Series насчитывается более 400 атрибутов и методов, что делает работу с данными невероятно гибкой. Можно напрямую применять функции к столбцу, выполнять математические операции, фильтровать данные, заменять значения, работать с датами, строками и многим другим. Кроме того, Series поддерживает векторизированные операции, что значительно ускоряет обработку больших наборов данных по сравнению с циклическими вычислениями. Например, можно легко умножить все значения на число, заменить пропущенные данные или применить сложные трансформации без написания сложных циклов.
Это лишь основные функции и возможности DataFrame, но уже они делают его незаменимым инструментом для импорта, организации, анализа, проверки, обработки и экспорта разноформатных и разноструктурных данных (рис. 2.3-4). В следующих главах мы подробно рассмотрим каждый из этих аспектов данных, а в главе "Современная обработка данных в строительстве" мы расскажем о других форматах, таких как Parquet, Apache Orc, JSON, Feather, HDF5 и хранилищах данных.


 Рисунок 2.3-4. DataFrame - оптимальный выбор манипулирования данными с высокой производительностью и расширенной поддержкой типов данных
С ростом числа больших языковых моделей (LLM) фокус смещается на создание нового поколения LLM, основанного на технологиях обработки больших данных. Эти решения открывают ключевые возможности для масштабной аналитики, интеллектуального поиска, выявления инсайтов, многоэтапного обучения моделей и других продвинутых задач.
Формируется замкнутый цикл взаимодействия данных и искусственного интеллекта, что закладывает основу для агентных платформ нового поколения, где LLM интегрируется с большими данными. Этот технологический сдвиг уже активно меняет такие отрасли, как научные исследования, финансы, промышленность и здравоохранение, расширяя границы возможностей AI.
Библиотека Pandas и формат DataFrame, благодаря своей популярности и простоте использования, стали основными инструментами для обработки и автоматизации данных в LLM чатах и в частности в ChatGPT (версий 2023-2024 года). ChatGPT считает использование Pandas и Python часто используемым по умолчанию при обработке запросов, связанных с проверкой, анализом и обработкой данных.

LLM и ChatGPT для автоматизации процессов обработки данных
C
hatGPT и другие инструменты, основанные на использовании больших языковых моделей (a large language model - LLM), значительно упрощают сбор, анализ и автоматизацию данных. Эти инструменты позволяют пользователям формулировать запросы к данным, не прибегая к услугам программистов или самостоятельному изучению языков программирования и различных фреймворков.
ChatGPT, разработанный компанией OpenAI, — это искусственный интеллект, который обрабатывает естественный язык и использует обширные данные из Интернета для ответа на запросы.
Раньше для визуализации, обработки и анализа данных требовалось знание языка программирования (Python, R, Scala, SQL) и специализированных библиотек (таких как Pandas, Polars или DuckDB). Однако к 2023 году этот процесс значительно упростился благодаря способности ChatGPT обрабатывать текстовые запросы и предоставлять точные результаты без необходимости ручного кодирования. Такая возможность текстового взаимодействия упростила создание кода и сделала обработку данных более доступной для широкой аудитории, что стало значительным прорывом в удобстве использования.


   Рисунок 2.3-5. ChatGPT предоставляет возможность пользователям получать результаты без необходимости владеть навыками программирования
Как в определенный момент пользователям уже не нужно понимать, как работает интернет, чтобы пользоваться им или даже создавать интернет-магазины, онлайн-приложения или страницы (CMS WordPress, Joomla, Drupal), так и специалисты и инженеры строительных компаний без глубоких знаний программирования теперь используют такие инструменты, как ChatGPT (OpenAI) и LLaMA (Meta AI), для автоматизации логики процессов и замены функций отдельных специалистов или целых отделов.
LLM-модели, такие как ChatGPT и LLaMA, позволяют специалистам без глубоких знаний программирования внести свой вклад в автоматизацию и улучшение бизнес-процессов компании.

   Рисунок 2.3-6. ChatGPT заменяет необходимость знания языков программирования и заменяет обработку данных через библиотеку Pandas текстовыми запросами
Большое количество комманд сегодня работают над тес чтобы сделать LLM Команда Meta (подразделения Фейсбук) на своём сайте при публиковании новой модели LlaMa 3.1 сделало первым и главным кейсом использование данных именно работу со структуированными датафреймами в формате CSV и использованию внутри чата библиотеки Pandas.
LLM без передачи данных во вне и OpenSource
Многие компании, особенно в финансовой сфере, государственных учреждениях и строительстве, ограничивают использование облачных сервисов искусственного интеллекта из-за требований безопасности. Однако это не означает, что AI недоступен для бизнеса. Вместо использования внешних облачных решений можно развернуть собственную локальную большую языковую модель (LLM), которая будет работать внутри корпоративной сети без подключения к интернету.
Преимущества собственной LLM
✅ Полный контроль над данными — все данные остаются внутри компании, ничего не передается во внешние сервисы.
✅ Работает автономно — даже при отсутствии доступа к интернету.
✅ Гибкость применения — генерация текстов, анализ данных, создание скриптов на Python, помощь в проектировании и управлении проектами.
✅ Адаптация под бизнес — можно обучить модель на внутренней документации компании, чтобы она понимала специфику вашей работы.

Какие модели можно использовать?
На рынке представлен широкий выбор бесплатных и открытых LLM, которые можно развернуть на собственном оборудовании. Ниже мы рассмотрим основные популярные OpenSource LLM решения, которые вы можете запускать локально и бесплатно без подключения к интернет:


Как запустить свою LLM за 5 минут?
Если у вас есть современный компьютер или сервер, вы можете развернуть LLM буквально за несколько минут. Рассмотрим два простых способа:
Способ 1: Через Ollama (самый простой)
Ollama — это удобный инструмент для быстрого развертывания LLM на вашем устройстве.
1️⃣ Скачайте Ollama с официального сайта: ollama.com .
2️⃣ Откройте командную строку (терминал) и выполните следующую команду для загрузки модели Mistral 7B:
bash
Copy
1
ollama pull mistral
3️⃣ Запустите модель и задайте вопрос:
bash
Copy
1
ollama run mistral "Как рассчитать объем бетона в стене?"

Способ 2: Через LM Studio (графический интерфейс)
LM Studio предоставляет интуитивный графический интерфейс для работы с LLM.
1️⃣ Скачайте LM Studio с официального сайта: lmstudio.ai .
2️⃣ Установите программу и выберите нужную модель (например, Mistral).
3️⃣ Скачайте модель и начните работу через встроенный чат-интерфейс.
💡 На Windows и Mac все работает без сложных настроек.

Можно ли обучить AI на своих данных?
Да! Для того чтобы модель лучше понимала специфику вашего бизнеса, вы можете провести дообучение на ваших данных.
Пример использования:
У вас есть PDF-документы, Excel-файлы и Revit-модели. Вы можете загрузить их в LLM и получить AI-помощника, который знает все о вашей компании.
Как это сделать?
1️⃣ Соберите данные – файлы, таблицы, отчеты.
2️⃣ Используйте инструменты вроде LlamaIndex или LangChain , чтобы загрузить их в модель.
3️⃣ Запускайте запросы – AI будет отвечать, учитывая вашу документацию.
Пример кода для загрузки PDF-файлов с помощью LlamaIndex:
python
Copy
1
2
3
4
5
from llama_index import SimpleDirectoryReader

# Укажите путь к папке с PDF-файлами
reader = SimpleDirectoryReader("папка_с_PDF")
documents = reader.load_data()
После этого AI сможет работать с вашими файлами и предоставлять ответы на основе загруженной информации.

Расширенные возможности для строительства
LLM может быть полезна для решения следующих задач в строительной отрасли:
Автоматизация документации
Создание технических спецификаций, чертежей и отчетов.
Проектирование
Генерация предварительных расчетов и рекомендаций по материалам.
Управление проектами
Анализ прогресса, прогнозирование сроков и выявление рисков.
Обучение сотрудников
Создание учебных материалов и тестов на основе корпоративных стандартов.
Контроль качества
Анализ данных с датчиков и камер для выявления дефектов.

Заключение: AI внутри компании – это просто!
Если вашей компании запрещено использовать облачные сервисы типа ChatGPT, это не значит, что нужно отказываться от преимуществ искусственного интеллекта. Развернув локальную LLM, вы получите:
✅ Безопасность – все данные остаются внутри компании.
✅ Гибкость – модель можно адаптировать под любые задачи бизнеса.
✅ Экономию – нет необходимости платить за подписки на облачные сервисы.
🔥 Попробуйте запустить LLM уже сегодня и убедитесь, что AI может эффективно работать внутри вашей компании!

RAG


Выбор IDE: Погружение в ИИ и LLM через Практику
Погружаясь в мир искусственного интеллекта (ИИ) и больших языковых моделей (LLM), важно выбрать правильную среду разработки (IDE). Каждый инструмент имеет свои особенности, и выбор зависит от ваших целей и уровня подготовки.
IDE (Интегрированная Среда Разработки) — это универсальный строительный комбинат на вашем компьютере для автоматизации процессов и обработки данных. Вместо того чтобы хранить отдельно пилу, молоток, дрель и другие инструменты, у вас есть одно устройство, которое может всё — резать, крепить, сверлить и даже проверять качество материалов. IDE для программистов: это единое пространство, где можно писать код (создавать чертежи), тестировать его работу (собирание модели здания), находить ошибки (как контроль прочность конструкций в строительстве) и запускать готовый проект (сдача дома в эксплуатацию).
PyCharm — это мощная профессиональная IDE для Python. Она отлично подходит для серьезных проектов благодаря большому количеству встроенных функций. Однако базовая поддержка .ipynb-файлов доступна только в платной версии, а новичкам может показаться интерфейс слишком сложным.
Файл с расширением .ipynb (Jupyter Notebook) — это интерактивный документ, который объединяет Python-код, текстовые пояснения, визуализации и результаты выполнения программы в одном месте, позволяя создавать удобные для восприятия отчеты и проводить исследования без разделения на отдельные файлы.
VS Code — более легковесный вариант, который можно настроить под себя с помощью плагинов. Он предлагает бесплатную поддержку .ipynb-файлов и интеграцию с GitHub Copilot. Это отличный выбор для тех, кто хочет гибкость и возможность адаптировать среду под свои нужды.
Jupyter Notebook —  идеальный вариант для экспериментов и обучения. Этот инструмент позволяет писать код, добавлять пояснения и создавать визуализации в одном документе. Большинство примеров работы с ИИ можно найти именно в формате .ipynb. Но для управления зависимостями лучше использовать Anaconda Navigator.

   Рисунок 2.3-7. Jupyter Notebook один из самых удобных и простых инструментов по созданию Pipeline процессов
Google Collab — облачная версия Jupyter Notebook с бесплатным доступом к GPU/TPU. Это отличное решение для тех, кто хочет сразу начать экспериментировать с моделями без установки дополнительного программного обеспечения. Также здесь есть интеграция с Google Gemini и другими сервисами.
Выбор IDE зависит от ваших задач. Если вы хотите быстро начать работать с ИИ, попробуйте Jupyter Notebook или Google Colab. Для серьезных проектов лучше использовать PyCharm или VS Code. Главное — не бойтесь начать экспериментировать.

   Рисунок 2.3-8. Jupyter Notebook один из самых удобных и простых инструментов по созданию Pipeline процессов
Все представленные инструменты позволяют эффективно создавать Pipelines – последовательности шагов для обработки и анализа данных. Благодаря модульной структуре, каждый этап процесса (от загрузки данных до получения результатов) можно организовать как отдельный блок, легко модифицировать и повторно использовать. Это особенно важно для менеджеров и инженеров, так как позволяет формализовать логику принятия решений, документировать процессы и создавать воспроизводимые рабочие потоки, где каждый шаг ясно описан и связан с предыдущим. Подробнее о Pipelines и выстраивании блоков логики для автоматизации процессов мы поговорим в главе «ETL и автоматизация процессов».

От индустриальной революции к революции данных: параллели и перспективы
В истории человечества каждый технологический скачок приносил фундаментальные изменения в экономику и общество. Сегодня мы наблюдаем новую волну трансформации, сравнимую по масштабу с промышленной революцией XIX века. Однако если тогда основным драйвером изменений были механические силы и энергетические технологии, то сейчас – это данные и искусственный интеллект.
"I truly believe the entire application stack is going to disappear. All of that business logic is going to be compressed into the agent."
Искусственный интеллект и агенты изменят саму суть приложений, сделав традиционные программные стеки ненужными. Вся логика работы с данными будет сосредоточена в ИИ-агентах, а не в жестко закодированных бизнес-правилах.
В мире, ориентированном на данные, у нас не будет приложений, устанавливающих нормы архитектуры, потому что у нас не будет приложений в том виде, в котором мы их сейчас представляем. 
Как мы уже говорили ранее и более подробно расскажем в третьей части этой трилогии, в этой архитектуре будет очень мало кода приложений. Будут небольшие "апплеты", сравнимые с приложениями в магазине приложений или Google Play, но не будет монолитных приложений, как мы их знаем.


Переход от паровых машин к электрическим двигателям занял более 40 лет, но принес невероятное увеличение производительности за счет децентрализации мощностей. Аналогично, переход от традиционных методов управления бизнесом к data-driven подходам требует времени, но обещает значительно более высокие результаты через системное внедрение новых приложений и систем.
Сегодняшняя революция в области AI и LLM (Large Language Models) можно сравнить с тем, как когда-то тракторы заменили ручной труд на полях. Теперь вместо человеко-часов рутинной работы с информацией мы можем использовать алгоритмы, которые способны обрабатывать огромные объемы данных и выявлять скрытые закономерности. Как фермер сажает семена и собирает урожай, так и современный бизнес может "посевать" данные и получать ценные инсights для принятия решений.

Картинка тракторист и куча землепашцев AI против программирования
Однако важно понимать, что создание truly data-driven организации – это не быстрый процесс. Это долгосрочное стратегическое направление, подобное выращиванию леса. Каждое "дерево" в этом лесу – это отдельный процесс, компетенция или инструмент, который требует времени для роста и развития. И как в случае с настоящим лесом, успех зависит не только от качества посадочного материала (технологий), но и от почвы (корпоративной культуры), климата (деловой среды) и ухода (системного подхода).
Эта революция отличается от предыдущих тем, что время на адаптацию значительно сокращено – вместо десятилетий у нас может быть всего несколько лет. Поэтому компании должны осознать важность комплексного подхода: нельзя просто купить новый инструмент или внедрить одну технологию и ожидать мгновенных результатов. Необходимо формировать целую экосистему, где данные становятся основным активом, а аналитическое мышление – частью корпоративной культуры.
Now that isn't to say there won’t be software companies in the future, it’s just going to look drastically different. Now that's not necessary. You just tell the agent what you want. And it will either know how to accomplish it or write tools to go accomplish it on your behalf.
Больше не нужно программировать сложные процессы — достаточно сформулировать задачу, и агент сам создаст необходимые инструменты. → Будущее разработки ПО меняется: компании больше не будут работать по привычным SaaS-моделям.


Подобно тому, как электрификация породила новые отрасли промышленности, AI и LLM открывают совершенно новые горизонты для бизнеса. Но этот переход требует не только технологических инвестиций, но и глубокой трансформации мышления, процессов и организационных структур. И те компании, которые поймут это и начнут действовать уже сегодня, будут лидерами завтрашнего дня.





После того как мы познакомились с основными типами данных и инструментами для их обработки, в следующей главе мы готовы перейти к первому этапу работы с данными: открытию закрытых форматов и преобразованию информации из различных форматов в структурированные формы.






ГЛАВА 2.4 
ПРЕОБРАЗОВАНИЕ ДАННЫХ В СТРУКТУРИРОВАННУЮ ФОРМУ


REV Преобразование неструктурированных данных в структурированные
В традиционном подходе каждая новая система требует преобразования данных. Любой, кто сталкивался с внедрением программного обеспечения, знает, насколько это трудоемкий процесс: данные из старой системы необходимо переименовать, переструктурировать и очистить, чтобы они соответствовали новой модели. Это не добавляет ценности самим данным — просто старый формат не совпадает с новым.
В Data-Centric подходе преобразование данных больше не будет регулярной необходимостью. Единожды приведя данные к единой структуре, компании смогут использовать их без постоянных переделок. Новые приложения будут адаптироваться под существующую модель, а не заставлять пользователей переделывать данные под каждую новую систему.
Разумеется, иногда все же потребуется изменять представление данных — например, для ускорения работы или удобства анализа. Однако это уже не потребует изменения самого приложения.
Современные системы нового поколения строятся не вокруг жесткой структуры данных, а вокруг их смысла и значения. В отличие от структуры, которая может меняться от системы к системе, смысл бизнес-данных остается неизменным гораздо дольше. Именно поэтому ключ к эффективной работе с данными — не их постоянное преобразование, а изначальное создание структурированной, универсальной модели.



В
 строительных проектах неструктурированные данные в основном представляют собой техническую документацию, отчеты о проделанной работе, планы, чертежи и схемы, содержащие такую важную информацию, как спецификации, графики и протоколы согласования. Разнообразие форматов и структур этих данных усложняет их организацию, анализ и интеграцию в другие системы и приложения.
Процесс преобразования в структурированные или полуструктурированные форматы может варьироваться в зависимости от типа входных данных и желаемых результатов обработки.
Преобразование данных из неструктурированной в структурированную форму — это и искусство, и наука. Этот процесс часто занимает значительную часть работы инженера по обработке данных и аналитика, c целью получить чистый, упорядоченный набор данных, отражающий всю сложность данных.

   Рисунок 2.4-1. Преобразование отсканированного документа в структурированную форму


Преобразование неструктурированных данных в структурированный формат — это пошаговый процесс, включающий следующие этапы:
1. Извлечение данных (Extract): на этом этапе загружается исходный документ или изображение, содержащее неструктурированные данные. Это может быть PDF-документ, фотография, чертеж или схема.
2. Преобразование данных (Transform): далее следует этап преобразования неструктурированных данных в структурированный формат. Например, это может включать распознавание и интерпретацию текста с изображений с помощью оптического распознавания символов (OCR) или других методов обработки.
3. Загрузка и сохранение данных (Load): последний этап включает в себя сохранение обработанных данных в различных форматах, таких как CSV, XLSX, XML, JSON, для дальнейшей работы, где выбор формата зависит от конкретных требований и предпочтений.

Преобразование неструктурированных данных в структурированный формат, состоящее из операций Extract, Transform и Load, называется ETL, о котором мы подробнее поговорим в главе "ETL и Pipeline: Extract, Transform, Load". Давайте посмотрим на практике, как документы разных форматов преобразуются в структурированные.

Пример преобразования PDF-документа в таблицу
Ч
тобы показать процесс преобразования неструктурированных данных в структурированный формат, возьмем в качестве примера PDF-документ, содержащий таблицу, с целью преобразования таблицы из PDF-документа в формат таблицы Excel или CSV (рис. 2.4-2).
Автоматизация и языковые модели LLM, такие как ChatGPT, значительно упрощают работу специалистов с данными, снижая необходимость глубокого изучения языков программирования и позволяя решать многие задачи с помощью текстовых запросов.


   Рисунок 2.4-2. В отличие от PDF, форматы CSV и XLSX широко распространены и легко интегрируются в различные системы управления данными
Поэтому, вместо того чтобы искать решение в Интернете, мы попросим ChatGPT предоставить код, необходимый для преобразования PDF-документа в табличный формат.
❏ Отправьте текстовый запрос в ChatGPT:
Напиши, пожалуйста, код для извлечения текста из PDF-файла, в котором есть таблица. Код должен принимать в качестве аргумента путь к файлу и возвращать извлеченную таблицу в виде DataFrame. ⏎
















➤ Ответ ChatGPT:

   Рисунок 2.4-3. Код извлекает текст из PDF-файла 
Этот код можно запустить в одной из популярных IDE (интегрированная среда разработки) в оффлайн режиме: PyCharm, Visual Studio Code (VS Code), Jupyter Notebook, Spyder, Atom, Sublime Text, Eclipse с плагином PyDev, Thonny, Wing IDE, IntelliJ IDEA с плагином Python, JupyterLab или популярных онлайн-инструментах: Kaggle.com, Google Collab, Microsoft Azure Notebooks, Amazon SageMaker





❏ На этапе "Преобразование" мы используем популярную библиотеку Pandas, чтобы считать извлеченный текст в таблицу DataFrame и, наконец, сохранить DataFrame в табличный файл CSV:
Мне нужен код, который будет преобразовывать результирующую таблицу из PDF-файла в DataFrame. Также добавьте код для сохранения DataFrame в CSV-файл. ⏎

➤ Ответ ChatGPT:

   Рисунок 2.4-4. Преобразование извлеченного текста в DataFrame
 и сохранение таблицы в CSV-файл
Используя обычные текстовые запросы в ChatGPT и десяток строк Python и библиотеки Pandas, мы преобразовали PDF-документ в табличный формат CSV, который, в отличие от PDF-документа, широко распространен и легко интегрируется в различные системы управления данными. Мы можем применять этот код (скопировав его из ChatGPT) к десяткам и тысячам новых PDF-документов одновременно, тем самым автоматизируя процесс преобразования потока неструктурированных документов в структурированный табличный формат. 
Документы PDF не всегда содержат текст, чаще всего это отсканированные документы, которые необходимо обработать как изображения. Хотя изображения по своей природе не структурированы, разработка и применение библиотек распознавания позволяют извлекать, обрабатывать и анализировать их содержимое, что дает нам возможность в полной мере использовать эти данные в бизнес-процессах.

Преобразование изображения в структурированную форму
П
ри управлении данными изображения представляют собой одну из наиболее распространенных форм неструктурированных данных. Изображения содержат много сложной информации, поскольку их содержание, цвета, текстуры разнообразны, а для извлечения полезной информации требуется специальная обработка.
Сложность использования изображений в качестве источника данных заключается в отсутствии структуры. Изображения не передают смысл прямым, легко поддающимся количественной оценке способом, который компьютер может сразу понять или обработать, как это делает электронная таблица или таблица базы данных. Чтобы преобразовать неструктурированные данные изображений в структурированную форму, необходимо использовать программные библиотеки, способные интерпретировать содержащуюся в них визуальную информацию.

   Рисунок 2.4-5. Преобразование отсканированных документов и 
изображений в структурированные форматы возможно с 
помощью специальных OCR инструментов 
Одной из основных технологий, используемых при работе с изображениями, является оптическое распознавание символов, или OCR (Optical character recognition), - процесс, который преобразует различные типы документов, например отсканированные бумаги, PDF-файлы или изображения, в редактируемые и доступные для поиска данные. 
OCR достаточно универсален, чтобы быть интегрированным в различные рабочие процессы, предлагая мощный инструмент для разработчиков и позволяя внедрить возможности распознавания в приложения по работе с данными.
Давайте попросим ChatGPT написать пример кода для получения данных из отсканированной или сфотографированной таблицы в структурированном виде.
❏ Отправьте текстовый запрос в ChatGPT:
Напиши код, позволяющий преобразовать JPEG-изображение, содержащее таблицу, в таблицу DataFrame. ⏎


























➤ Ответ ChatGPT:

   Рисунок 2.4-6. Преобразование текста, извлеченного из таблицы изображений или фотографий, в структурированное табличное представление 
Код, написанный ChatGPT, использует библиотеку pytesseract (Tesseract для Python) для преобразования изображения в текст с помощью OCR (оптического распознавания символов) и библиотеку pandas для преобразования этого текста в структурированную форму, т. е. DataFrame.
Tesseract - один из ведущих OCR-движков с открытым исходным кодом, изначально разработанный компанией HP, а теперь поддерживаемый Google. Известный своей точностью и способностью распознавать более 100 языков, Tesseract широко используется для задач OCR. 


Процесс преобразования обычно включает предварительную обработку для улучшения качества изображения, после чего применяются различные алгоритмы для обнаружения образов, выделения признаков или распознавания объектов. В результате неструктурированная визуальная информация преобразуется в структурированные данные.

Преобразование текстовых данных в структурированную форму
П
реобразование текстовой информации в структурированный формат - задача, требующая тщательного анализа для создания таксономии и категоризации данных из текста.
Таксономия — это система классификации, используемая для группировки и организации объектов. Она помогает организовать информацию, разделяя ее на категории и подкатегории по определенным признакам или характеристикам. В конкретном контексте обработки текстов, таксономия используется для систематической организации элементов текста в соответствии с их контекстуальными связями и значениями.

   Рисунок 2.4-7. Выделение ключевой информации из текста о необходимости корректировки сроков и интеграции изменений в систему управления проектом


Чтобы смоделировать процесс извлечения ключевой информации из текстовых данных, необходимо выполнить следующие шаги:
1. Извлечение данных (Extract): необходимо проанализировать текстовые данные, чтобы извлечь информацию о задержках и изменениях в графике проекта.
2. Категоризация и классификация (Transofrm): Мы распределяем полученную информацию по категориям, например, причины задержек и изменений в расписании.
3. Интеграция (Load): В конце мы подготавливаем структурированные данные для интеграции во внешние системы управления данными.

Предположим, у нас есть текстовые данные в виде записанного диалога с рис. 2.4-7 выше, и мы хотим извлечь смысл текста в структурированную форму. Выполним извлечение на основе ожидаемых ключевых слов, создадим DataFrame для имитации извлечения данных и конечный DataFrame, который будет содержать столбцы для даты, события (например, причина задержки) и действия (например, изменение расписания).
Приведем код для решения задачи с использованием текстового запроса в языковой модели ChatGPT, как и в предыдущих примерах.
❏ Отправьте текстовый запрос в ChatGPT:
У меня есть разговор между менеджером: "Здравствуйте, мы отстаем от графика из-за дождя" и инженером: "Да, нам нужно скорректировать сроки на неделю". Мне нужен сценарий, который анализирует предоставленные текстовые данные, извлекает из них причины задержек и необходимые корректировки сроков, а затем генерирует DataFrame из этих данных. Затем DataFrame должен быть сохранен в CSV-файл. ⏎









➤ Ответ ChatGPT:


   Рисунок 2.4-8. Выделение ключевой информации из текста о необходимости корректировки сроков в виде таблицы
В этом примере текстовые данные, содержащие переписку между менеджером проекта и инженером, анализируются для выявления и извлечения конкретной информации, которая может повлиять на управление проектом. С помощью регулярных выражений (подробнее про регулярные выражение мы поговорим в главе «Структурированные требования и регулярные выражения RegEx») автоматически определяются причины задержек проекта и необходимые корректировки временного графика. 
Написанная ChatGPT функция извлекает из строк либо причину задержки, либо корректировку времени, основываясь на шаблонах. Она выделяет слово после "из-за" как причину задержки или слово после "по" как корректировку времени. 
Если в строке упоминается задержка из-за погоды, то в качестве причины определяется "дождь"; если в строке упоминается корректировка графика на определенный период, то этот период извлекается в качестве корректировки времени. Отсутствие любого из этих слов в строке приводит к значению "Нет" для соответствующего атрибута-столбца.

   Рисунок 2.4-9. Сводная таблица, полученная в виде DataFrame, содержащая информацию о причинах задержек и необходимых корректировках времени 
После извлечения данных из диалога нужная нам информация была преобразована в формат, удобный для анализа и обработки. Такая форма данных позволяет эффективно интегрировать извлеченную информацию в системы управления для дальнейшего анализа, планирования и принятия решений.

REV Перевод данных САПР (BIM) в структурированную форму
П
реобразование документов и изображений в структурированный формат может быть достигнуто с помощью относительно простых инструментов, основанных на категоризации. Категоризация элементов также является ключевой и важной частью работы с проектными данными из программ САПР (BIM). 

Однако структурирование и категоризация данных САПР (BIM) - более сложная задача, поскольку данные, экспортируемые из баз данных САПР (BIM), почти всегда представлены в закрытых форматах или форматах, сочетающих одновременно элементы геометрических данных (полуструктурированные) и элементы метаинформации (структурированные данные).
В этих специальных САПР (BIM) форматах информация о характеристиках и атрибутах элементов проекта собирается в иерархическую систему классификации (полуструктурированные данные), где сущности с соответствующими свойствами располагаются, подобно плодам фруктового дерева, в самых последних узлах ветвей классификации данных.

   Рисунок 2.4-10. Вид данных из баз данных САПР (BIM) представляется пользователю в виде деревьев классификации

Для извлечения данных из классификации САПР (BIM) деревьев в можно использовать метафору топора, нажимая на кнопки и имитируя процесс подъема к нужной ветке. Альтернативный вариант - использование бензопилы API - предполагает более прямой, программный подход к получению доступа и срубанию нужной ветки, преобразовывая ее в итоге в структурированную таблицу для использования в других системах.
Для извлечения таблиц данных из САПР (BIM) проектов можно использовать различные инструменты такие как Dynamo, pyRevit, Pandamo (Pandas + Dynamo), Forge, ACC для Revit®, или решения с открытым исходным кодом, такие как IfcOpenShall или IFC.js для формата IFC. Такие инструменты позволяют разделить данные, хранящиеся в формате САПР (BIM), на геометрическую информацию и метаинформацию, а также атрибутивную информацию элементов конструкции. 
Нативные форматы баз данных САПР (BIM) закрыты и защищены, и качественный доступ к данным в таких базах предоставляется только через специализированные программы от поставщиков САПР (BIM) или через дополнительные уровни API (рис. 2.4-11), обеспечивающие ограниченный доступ к программам баз данных САПР (BIM).

   Рисунок 2.4-11. Специалисты по системам автоматизированного проектирования (BIM) имеют доступ к данным только через API-соединения
С развитием технологий реверс-инжиниринга и появлением наборов для разработки программного обеспечения (SDK) доступность и преобразование данных из закрытых форматов программ САПР (BIM) стали намного проще. 
Инструменты обратного инжиниринга позволяют легитимно преобразовывать данные из закрытых проприетарных форматов в структурированные, разбивая информацию из смешанного формата САПР (BIM) на необходимые пользователю типы данных и форматы, облегчая их обработку и анализ. 
Это позволяет специалистам перейти от обработки моделей САПР (BIM) в смешанном формате, что предполагает использование специализированного программного обеспечения, к подходу, ориентированному на данные. В последнем случае основной упор делается на использование открытых данных и открытых инструментов.

   Рисунок 2.4-12. Минимизация зависимостей и использование открытых данных позволяет перейти к дата-центричному подходу
С 2002 года для формата DWG (AutoCAD®), с 2008 года для формата DGN (MicroStation®) и с 2018 года для RVT (Revit® BOM-BIM) стало возможным удобно и эффективно преобразовывать изначально закрытые данные в структурированные форматы с помощью инструментов реинжиниринга. 
Сегодня практически все крупные САПР (BIM) и крупные инжиниринговые компании в мире используют SDK-инструменты обратного инжиниринга для извлечения данных из закрытых форматов САПР (BIM) других поставщиков САПР (BIM) [21].
Рисунок 2.4-13. Использование инструментов обратного проектирования: Преобразование базы данных любой САПР (BIM) программы в структурированный формат
Преобразование данных из закрытых, проприетарных форматов в более общедоступные или разделение смешанных форматов САПР (BIM) на геометрические и метаинформационные атрибутивные данные упрощает процесс работы с ними, делая их более доступными для анализа, манипулирования и интеграции с другими системами. Подробнее о процессе преобразования и коде для автоматизации получения данных САПР (BIM) мы расскажем в главе "Процесс проверки данных трубопровода-ETL с помощью ChatGPT".
В современной работе с данными САПР (BIM) мы достигли того уровня, когда для доступа к данным не нужно запрашивать разрешение у поставщиков САПР (BIM).

   Рисунок 2.4-14. Современные инструменты SDK позволяют легально конвертировать данные из проприетарных форматов баз данных САПР (BIM)
Изучив различные типы данных и инструменты для их преобразования из разнообразных форматов в структурированную форму, мы можем перейти к одному из самых важных и сложных этапов работы с данными - моделированию данных и проверке их качества.

Вендоры CAD переходят к структурированным данным
В 2024 году в сфере проектирования и строительства происходит значительный технологический сдвиг в области использования и обработки данных. Если вы считаете, что понимание основ BIM (openBIM и closedBIM) будет достаточно для работы с данными в строительстве в ближайшие годы, то вас вскоре может ждать сюрприз. Вместо свободного доступа к проектным данным, производители CAD-систем, сосредотачиваются на продвижении очередных новых концепций. Устаревающие подходы, такие как BIM (2002 год) и openBIM (2012 год), постепенно уступают место современным технологическим решениям, которые ожидают нас в ближайшем будущем:
• Переход на использование гранулированных данных, которые позволяет эффективно управлять информацией и осуществить переход к аналитике данных
• Появление USD формата и внедрение подхода Entity-component-system (ECS) для гибкой организации данных 
• Активное использование искусственного интеллекта в обработки данных, автоматизации процессов и аналитике данных
• Развитие интероперабельности - улучшенного взаимодействия между разными программами, системами и базами данных
Чтобы понять текущие тренды и делать обоснованные прогнозы, мы должны найти исторические паттерны и провести анализ основных фактов, которые привели к решению CAD вендоров о необходимости введения новых концептов и новых форматов для всей строительной отрасли.
Тренды в индустрии строительных данных, как и последние тридцать лет, продолжают формироваться под влиянием ключевых игроков рынка — CAD-вендоров, которые активно работают над укреплением своих позиций в мире данных и ищут форматы, которые позволят привлечь больше пользователей к собственным платформам.
На фоне появления платформ для анализа проектных данных от CAD вендоров интерес к формату IFC и концепции openBIM постепенно снижается, уступая место более популярным и простым формам информации, таким как формат USD (Universal Scene Description). Суть изменений в том, что индустрия движется от сложных специализированных форматов к более универсальным и простым решениям. Новый формат USD словно снег на голову обрушивается на строительную отрасль, знаменуя эпохальную смену парадигмы, благословлённую Autodesk. 
BuildingSMART, организация, которая ранее фокусировалась на развитии формата IFC как языку моделирования и формату обмена данными (в соответствии с ISO 10303 и ISO 16739) и концепции openBIM, пересматривает свои стратегические цели в связи с появлением альянса AOUSD и растущей популярностью формата USD. До 2022 года формат USD не фигурировал в планах организации по разработке новых версий IFC формата, но текущие тенденции заставляют buildingSMART адаптировать свою стратегию. 
Крупнейшие разработчики программного обеспечения для проектирования переходят к новым форматам данных, способным заменить устаревшие стандарты. В 2023 году ведущие вендоры САПР совместно с технологическими гигантами сформировали альянс для продвижения формата USD (Universal Scene Description) в строительной отрасли. Этот шаг направлен на унификацию данных и улучшение совместимости между различными платформами. Альянс также поддержали организации, занимающиеся стандартизацией данных в строительстве, что подтверждает стратегическую значимость этого перехода.
На протяжении последних десятилетий основным форматом для обмена данными в строительстве был IFC (Industry Foundation Classes). Этот параметрический формат создавался для обеспечения интероперабельности между различными BIM-системами. Однако его сложная структура, трудности в обработке данных и несовместимость между разными программными решениями привели к многочисленным проблемам с его внедрением. В результате многие разработчики начали искать альтернативные подходы, включая USD, glTF, CPIXML, DAE и другие форматы, обеспечивающие более гибкую и удобную работу с данными.
Ведущий разработчик САПР долгое время заявлял о своей приверженности IFC, однако так и не смог обеспечить его полноценную поддержку в своих ключевых продуктах. За более чем 20 лет этот формат не получил нативной реализации в его флагманском программном обеспечении, что вынудило компанию использовать сторонние инструменты. С 2019 года крупнейший вендор САПР перешёл на внешний SDK для работы с IFC, что фактически означало утрату контроля над этим стандартом.
Сертификация и интеграция IFC требуют значительных ресурсов, а процесс экспорта и импорта данных остаётся сложным и нестабильным. Вендоры вынуждены ежегодно инвестировать десятки и даже сотни тысяч евро в поддержку IFC, что делает его менее привлекательным по сравнению с альтернативными решениями. В результате разработчики всё чаще обращаются к USD — формату, изначально созданному для индустрии 3D-графики, но обладающему высокой совместимостью с различными программными платформами.
В отличие от IFC, USD предлагает более простую, плоскую структуру данных, что облегчает обработку информации и ускоряет её интеграцию в цифровые процессы. Новый формат позволяет хранить геометрию в виде меш-сетей, а свойства объектов — в JSON, что делает его более удобным для автоматизированных процессов и работы в облачных экосистемах. Крупнейший вендор САПР уже использует схожий формат SVF, но он остаётся закрытым. В этом контексте USD может стать его открытым аналогом, подобно тому, как в своё время DXF стал открытой версией DWG.
С 2023 года ведущие разработчики САПР начали активно внедрять USD в свои программные продукты, заявляя о планах по его полной интеграции в экосистему проектирования. Руководители крупнейших компаний отмечают, что переход на USD позволит упростить обмен данными, обеспечит лучшую совместимость между платформами и создаст единую среду для работы с 3D-моделями и атрибутными данными.
В большинстве существующих BIM-систем доступ к данным ограничен и осуществляется через API, которые требуют подписки и постоянного обновления. Это создаёт препятствия для пользователей, желающих работать с открытыми данными. В отличие от этого, USD, glTF и CPIXML предлагают более гибкие и удобные механизмы хранения и передачи информации.
Организации, занимающиеся стандартизацией данных, уже начали обсуждение возможной интеграции USD в будущие версии IFC 5. Это может привести к постепенному изменению структуры IFC в сторону более упрощённого формата, либо к его полной замене USD в качестве основного стандарта обмена данными в строительстве.
На данный момент сложность и громоздкость IFC остаются его главным недостатком. В отличие от него, USD изначально создавался для управления большими массивами данных в 3D-графике, что делает его более адаптированным к современным цифровым процессам. Он уже активно используется в индустрии визуализации, поддерживается такими инструментами, как Blender, Unreal Engine, Unity, и становится стандартом для обмена 3D-моделями.
Переход крупнейших разработчиков к USD и аналогичным форматам отражает глобальную тенденцию к упрощению данных и повышению их доступности. В ближайшие годы можно ожидать постепенного ухода от сложных параметрических стандартов в пользу более лёгких и структурированных решений. Это приведёт к трансформации способов хранения, обработки и обмена данными в строительной отрасли, что ускорит внедрение автоматизированных процессов и цифровых технологий.
REV Что за данные хранятся в CAD






REV Где рождается БИМ или любая CAD (BIM) программа — это компилятор данных, визуализирующий геометрию через геометрическое ядро
Каждая CAD (BIM) программа либо использует собственное геометрическое ядро, либо опирается на стороннее проприетарное решение, что существенно усложняет обмен данными между различными платформами. 
Любая CAD (BIM) программа является компилятором данных о геометрии, которая отображается при помощи геометрического ядра.
На рынке доминируют такие геометрические ядра, как Siemens Parasolid, Dassault Systèmes CGM, PTC ProEngineer, ADSK ShapeManager и АСКОН C3D. Единственными бесплатными геометрическими ядрами с открытым исходным кодом являются OpenCascade и библиотека CGAL под лицензией GPL.

Рис. 8. Архитектура процесса работы CAD/BIM-систем: от кодовых баз до визуализации
Проблем с построением геометрии по параметрам не возникает, если речь идет о простых геометрических элементах — таких как линии или плоскости. Однако при работе со сложными или составными элементами ситуация меняется. Даже при одинаковых входных параметрах разные геометрические ядра могут давать разные результаты из-за особенностей их работы и алгоритмов обработки. В итоге геометрические сущности проект, сохранённые в виде параметрической геометрии будет отображаться в разных CAD (BIM) продуктах по разному.

Рис. 9. Разные входные параметрические модели дают разные результаты при использовании разных геометрических ядер
Полная кроссплатформенная совместимость на уровне параметрической геометрии остаётся недостижимой для большинства CAD-вендоров. Это связано с отсутствием стандартизации алгоритмов, используемых в геометрических ядрах систем, которые часто не принадлежат CAD-вендорам (а больше MCAD вендорам), а также с необходимостью создания открытых спецификаций обмена и разработки универсальных конвертеров. В настоящее время подобными задачами занимаются лишь несколько инициатив, включая OpenCascade, Open Design Alliance и CADExchanger. Исторически, инициативы по конвертации и унификации разноформатных данных подвергались активному давлению со стороны CAD-вендоров. Однако многие из этих конфликтов завершались судебными разбирательствами, в которых решения выносились не в пользу вендоров.
В формате IFC используются различные способы представления геометрии, такие как CSG и Swept Solids, однако BREP стал также лидирующим стандартом для передачи геометрии элементов в IFC формате, так как такой формат поддерживается при экспорте из CAD (BIM) программ и позволяет потенциально (реализовано лишь в экспериментальных продуктах) редактировать элементы при обратном импорте IFC в CAD программы.
В большинстве случаев, когда геометрия в IFC задана параметрически (BREP), получить свойства, такие как объём или площадь сущностей проекта, становится невозможно имея только файл IFC, потому что для работы с геометрией и его визуализацией в таком случае потребуется геометрическое ядро, которое изначально отсутствует. 
Для поддержки IFC в любой программы фактически необходимо создать ещё одну идеальную IFC CAD внутри уже существующего решения cо своим геометрическим ядром и своей логикой работы с геометрией.

Рис. 11. Возможно ли стандартизировать геометрические ядра и SDK которыми пользуются CAD вендоры?
И если с примитивными элементами в IFC-BREP формате может не возникать проблем, то помимо проблем с разными движками геометрических ядер существует достаточно элементов, которые имеют свои особенности для правильного отображения. Эта проблема подробно рассмотрена в международном исследовании “Reference study of IFC software support”, опубликованным 2019 года. Цитата:
Одни и те же стандартизированные наборы данных дают противоречивые результаты, мало обнаруживаемых общих закономерностей, и серьезные проблемы найдены в поддержке стандарта (IFC - примечание автора), вероятно, из-за той самой высокой сложности стандартной модели данных. Отчасти здесь виноваты сами стандарты, поскольку они часто оставляют некоторые детали неопределенными, с высокой степенью свободы и различными возможными интерпретациями. Они допускают высокую сложность в организации и хранении объектов, что не способствует эффективному универсальному пониманию, уникальным реализациям и согласованному моделированию данных
Правильное понимание “определённых положений” доступно платным членам buildingSMART и часто в кулуарных дискуссиях. Как следствие, тот, кто хочет получить доступ к важным знаниям об определенных особенностях IFC, будет пытаться кооперироваться с крупными компаниями, либо доходить до этого своими исследованиями. Из интервью разработчика CAD-программы Renga: 
Ты натыкаешься на вопрос об импорте и экспорте данных через формат IFC и спрашиваешь у коллег-вендоров: “А почему так в файле IFC передаётся информация про параметрическую передачу помещений? В открытой спецификации от buildingSMART ничего про это не сказано”. Ответ от "более знающих” европейских вендоров: “Да, не сказано, но допустимо"

Рис. 11. Разное отобржение одних и тех же геометрических элементов в разных программах CAD (BIM)
Все особенности отображения и генерации параметров IFC в ядре геометрии могут быть реализованы только большими командами разработчиков. Поэтому нынешняя практика особенностей и сложности формата IFC, выгодна прежде всего CAD вендорам и имеет много общего со стратегией Microsoft «adopt, extend, destroy», когда растущая сложность стандарта фактически создает барьеры для небольших игроков рынка. Стратегия Microsoft заключалась в адаптации открытых стандартов, добавлении собственных расширений и функций, чтобы создать зависимость пользователей от своих продуктов, а затем вытеснить конкурентов. Microsoft долгое время навязывала собственные стандарты (например, Internet Explorer), что замедляло внедрение более прогрессивных и универсальных технологий, таких как CSS, HTML5, или независимых браузеров.
В итоге сегодня полноценная реализация онтологии IFC под силу только крупным поставщикам CAD, которые могут вложить значительные ресурсы в поддержку всех сущностей и их маппинга с их внутренним геометрическим ядром. Крупные вендоры также имеют возможность согласовывать между собой технические детали особенностей, которые могут быть недоступны даже самому активному участнику buildingSMART. 
Подробнее о сложностях с которыми сталкиваются команды разработчиков, работающие с IFC форматов в исследовании “Reference study of IFC software support”

Рис. 12. Международное исследование кроссплатформенности IFC формата
Для небольших независимых команд и проектов с открытым исходным кодом, стремящихся поддерживать развитие интероперабельных форматов, отсутствие собственного геометрического ядра превращается в серьёзную проблему. Без него практически невозможно учесть всё многообразие тонкостей и нюансов, связанных с межплатформенным обменом данными.
На текущий момент единственным широко используемым open-source ядром, лежащим в основе популярных openBIM-инструментов — таких как IfcOpenShell, BlenderBIM-Bonsai, IFC.js и FreeCAD — остаётся OpenCascade. Однако и у него есть свои ограничения. Организация BuildingSMART не имеет непосредственных инструментов влияния на развитие OpenCascade (OCC) и его лицензирование. Исторически команда разработчиков OCC была сосредоточена в Нижнем Новгороде, но в последние годы часть специалистов OCC переехала в Португалию, а большая и оставшаяся часть команды сконцентрировалась на развитии ответвления проекта OpenCascade (OCC) под маркой нового китайского open-source геометрического ядра OGG. 
Зачем строителям геометрия? Когда линии превращаются в деньги
Геометрия, помимо визуализации, дополняет существующие списки параметров элементов ключевыми объёмными характеристиками, такими как площадь и объём, которые автоматически рассчитываются на основе формы объекта-cущности проекта. Эти параметры играют важнейшую роль, так как служат основой для последующих вычислений, расчётов и анализа.
Автоматический расчёт геометрии становится связующим звеном между абстрактными данными в виде параметров задачи и их физической реализацией.
Геометрия исторически была основой инженерной коммуникации, обеспечивая возможность расчёта длин, площадей и объёмов. От первых чертежей на папирусе до современных цифровых форматов, чертежи всегда служили ключевым инструментом для передачи информации об объёмах материалов и работ между инженерами, прорабами и сметчиками. На протяжении тысячелетий, вплоть до 1980-х годов, сметчики вручную собирали количественные и объёмные данные, опираясь исключительно на визуальные представления, используя линейки и транспортиры как основные инструменты измерения.

Рис. 13. Основные цели геометрических данных в строительных бизнес процессах
С появлением компьютеров ручная и трудоемкая задача по расчётом объемных характеристик теперь решается путем полной автоматизации благодаря появлению объемного моделирования в современных инструментах CAD (BIM), которое позволяет автоматически получать объемные атрибуты любого элемента, без необходимости вычислять эти значения вручную с калькулятором. 
Работая в CAD-программах создание геометрических элементов для расчётов происходит через пользовательский интерфейс CAD-BIM программ. Для преобразования точек и линий в объемные тела используется геометрическое ядро. Геометрическое ядро выполняет ключевую задачу — преобразование геометрии в объемные модели, из которых, после аппроксимации автоматически рассчитываются объемы элемента.

Рис. 14. Путь визуализации геометрической формы вне CAD (BIM) систем
Как и тысячи лет назад при строительстве пирамид, где для измерений использовались локоть и кубит, так и сегодня в CAD-программах точность интерпретации геометрии играет ключевую роль: от неё зависят точность расчётов бюджета проекта, корректное определение стоимости и сроков выполнения работ из которых состоит любой строительный проект.
Точность расчётов — это ключевой фактор выживания в строительной отрасли. В условиях жёсткой конкуренции доступ к качественным данным об объёмах становится решающим условием для успешной реализации проектов и поддержания конкурентоспособности.
Если точность расчётов играет ключевую роль в определении ресурсов, материалов и временных параметров проекта, то важно разобраться, как именно осуществляется этот расчёт.
7. Основы расчётов в строительстве или от линий до объёмов: как площадь и объём становятся числами 
На практике для вычисления площадей и объемов геометрических поверхностей, заданных аналитически или через NURBS в BREP, часто используется триангуляция, которая преобразует сложные поверхности в сетку треугольников. 
NURBS (Non-Uniform Rational B-Splines) это математический способ описания кривых и поверхностей, тогда как BREP — это структура для описания полной трёхмерной геометрии объекта, включая его границы, которые могут быть определены с использованием NURBS.
Даже если поверхность задана аналитически или через NURBS, её чаще всего аппроксимируют тесселяцией, так как точные вычисления через интегралы или сложные аналитические методы на практике реализуются редко из-за их сложности и больших вычислительных затрат. 
Суть тесселяции заключается в разбиении сложных поверхностей на более простые элементы — треугольники или полигоны. Этот подход используется для расчётов поверхностей и объёмов, визуализации на экране, для экспорта в форматы вроде MESH ( "сетка"), и системы анализа столкновений и коллизий. В играх тесселяция используется для создания реалистичных ландшафтов, а в системах CAD/CAE — для вычислений и визуализации. В природе примером тесселяции являются пчелиные соты.

Рис. 15. BREP и полигональное представление сферы
BREP (NURBS), применяемая в CAD (в том числе BIM-системах), не является фундаментальной моделью геометрии. Этот метод был создан как удобный инструмент для представления окружностей и рациональных сплайнов. Однако у него есть ограничения — например, невозможность точно описать синусоиду, которая лежит в основе винтовых линий и поверхностей. В результате BREP (NURBS) остаётся лишь способом аппроксимации, но не фундаментальным средством описания геометрии.
Треугольные сетки (triangle mesh) и тесселяция параметрических фигур напротив отличаются простотой, эффективным использованием памяти и способностью обрабатывать большие объёмы данных. Эти преимущества позволяют обходиться без сложных и дорогих геометрических ядер, и заложенных в них сотен миллионов строк кода, при расчётах геометрических форм.

Рис. 16. Примеры тесселяции цилиндра и куба
При этом в строительной отрасли, не имеет принципиального значения, каким образом определяются объёмные характеристики — за счёт параметрических моделей во внутренних форматах CAD или IFC, либо с использованием упрощённых геометрических представлений в форматах USD, glTF, DAE или OBJ.
Геометрия, заданная в виде полигонов или BREP (NURBS), — это способы приближённого описания непрерывной формы. Подобно тому, как интегралы Френеля не имеют точного аналитического выражения, дискретизация геометрии через полигоны или NURBS всегда является аппроксимацией, такой же как и триангулярный MESH. 
И полигональнй MESH и параметрический BREP имеют свои преимущества и ограничения, но цель у них одна — эффективно и удобно описывать геометрию с учётом задач пользователя.В конечном счёте, точность геометрической модели зависит не только от метода её представления, но и от требований конкретной задачи.

Рис. 17. Различие объёмных характеристик у фигур с разным количеством полигонов
Параметрическая геометрия в формате BREP необходима в основном там, где важен минимальный размер данных и есть возможность использовать ресурсоёмкие и дорогие геометрические ядра для её обработки и отображения. Чаще всего это характерно для CAD-программ, которые применяют для этого геометрические ядра MCAD-вендоров.
В большинстве строительных задач потребность в параметрической геометрии и сложных геометрических ядрах возникает редко, если только её значимость не продвигается самими вендорами CAD или производителями геометрических ядер, которые и разрабатывают эти инструменты.
В итоге, внутри CAD (BIM) программ параметрическая геометрия (BREP, RVT, IFC, PLN) для расчётов всё равно преобразуется в MESH треугольники и полигоны через процесс тесселяции. За пределами среды CAD (BIM) в большинстве случаев, для визуализации, расчётов и поиска коллизий используется также триангулированная MESH геометрия (USD, SVF, glTF, CPIXML, DAE, NWC), что делает необходимость параметрической геометрии ещё менее очевидной.
Так какой формат следует выбрать в качестве стандарта для обмена данными и является ли IFC подходящим форматом для обмена - триангулярный IFC-MESH (gLTF, OBJ, DAE, SVF) или параметрический IFC-BREP (RVT, PLN, DGN)?
8. Зачем нам треугольники? Использование тесселяции в строительстве
В основе обменного формата, который будет использоваться как в отделах калькуляций, так и на стройплощадке - не должна подразумеваться конкретная CAD (BIM) программа. Геометрическая информация должна быть представлена в формате напрямую, без привязки к геометрическому ядру или архитектуре CAD. 
В строительной отрасли, в системах и базах данных использующих проектные данные зависимость от редактора CAD и геометрического ядра должна быть минимальной.
Параметрика геометрии из CAD программ может быть частью процесса, но лишь как исходные данные, а не основа обменного формата. Только так можно обеспечить универсальность и независимость геометрических описаний. Большинство параметрических геометрий, включая BREP и NURBS, для расчетов и визуализации преобразуются в треугольную сетку (тесселяцию). После тесселяции всё равно получается triangle MESH. Если в итоге разницы не видно, то зачем усложнять процесс? 
Параметрические форматы не фундаментальны и наоборот такие форматы как OBJ, STL, gLTF, SVF, CPIXML, USD и DAE, остаются фундаментальными, поскольку используют простую и универсальную структуру Triangle MESH. Она понятна и эффективна в архитектуре компьютерной графики, а также не требует дополнительных геометрических ядер с десятками миллионами строк кода для визуализации или расчётов элементов.

Рис. 18. Переход геометрии из параметрического формата в полигональное представление
Из за проблем с интерпретацией IFC и разности геометрических ядер все CAD вендоры, без исключения, используют SDK обратного инжениринга для передачи данных между решениями различных вендоров и никто не использует для целей интероперабельности сложный IFC или USD формат.
MESH формат USD, предлагаемый с 2023 года CAD вендорами в новом альянсе AOUSD, который обсуждался в прошлой статье (An Era of Change: IFC is a thing of the past or why Autodesk and other CAD vendors are willing to give up IFC for USD in 14 key facts), потенциально может стать новым стандартом для замены параметрической геометрии в проприетарных форматах. Он также может служить средством для описания BREP-геометрии в IFC, с чем до сих пор не справились сами CAD-вендоры. 

Но вместо того, чтобы использовать концепты, продвигаемые альянсами CAD вендоров, которыми они сами не пользуются- продуктивнее сосредоточиться на понимании преимуществ каждого подхода в конкретном контексте и выбирать тот или иной вид геометрии в зависимости от кейса использования.
Выбор между различными геометрическими представлениями - это компромисс между точностью, вычислительной эффективностью и практическими потребностями конкретной задачи. 

Рис. 19. Тесселированная BREP сфера с различным количеством полигонов
Сложность и использование геометрических ядер, которые навязывают строительной отрасли CAD-вендоры в обработке проектных данных, возможно, вовсе не нужна. Формат USD с MESH-геометрией может стать своего рода "ящиком Пандоры" для отрасли, открывая разработчикам подходы , альтернативные от IFC и BREP, к обмену данными. Оказалось, что есть и другие, более простые и открытые форматы, которые могут обеспечить качественное взаимодействие CAD (BIM) инженеров с десятками других специалистов.
Существующим примером подобного эффективного применения MESH-геометрии в бизнес процессах строительных компаний является одна из самых популярных строительных ERP-систем — ITWO/MTWO. Этот продукт, принадлежащий франко-немецкому объединению Schneider Electric и RIB Software, ещё в середине 2000-х продемонстрировал использование MESH формата с упрощённой схемой хранения метаинформации. Вместо IFC и USD форматов в ITWO/MTWO используется проприетарный, но открытый для чтения формат CPIXML.
За разработкой ERP-системы iTWO/MTWO стоит строительная корпорация Strabag, а точнее её дочерняя компания Züblin из Штутгарта. Именно Züblin была инициатором разработки iTWO, которая на тот момент позиционировалась не просто как ERP-система, а как интернациональная платформа для 4D-5D BIM — интеграции проектных данных с графиками и сметами.

Зачем строителям и заказчикам контролировать данные? 
Создание данных в строительстве — это непрерывный процесс генерации параметров и их преобразования в удобочитаемые форматы. Каждая сущность проекта — стена, окно или фундамент — это объект с набором атрибутов, таких как материал, тип, стоимость, объём и площадь. Эти данные нужно где-то хранить, обрабатывать и предоставлять конечным пользователям. 
Разработчики CAD (BIM) программ стремятся удержать пользователей в своей экосистеме и с каждым годом будут уводить всё больше процессов обработки данных на облачные хранилища партнёров Amazon, Microsoft Azure и Huawei. Основным маркетинговым преимуществом закрытых систем становится наличие качественно переноса геометрии из геометрического ядра CAD (BIM) решений в облачный MESH формат и возможности импорта/экспорта сторонних форматов других вендоров при помощи дорогих SDK для реверсинжениринга. 
Но зачем обычным инженерам, логистам, строителям, прорабам и сметчикам геометрические ядра и облачные технологии? Точности теселлированных форматов хватает для большинства строительных задач, а использование сложных геометрических ядер и SDK лишь усложняет процесс.

Рис. 34. Строительную отрасль ждёт неизбежный переход к открытым структуированным данным и открытым инструментам
Большинство современных графических движков работают именно с треугольными сетками, а не с BREP-геометрией. Ирония заключается в том, что все CAD-вендоры продолжают упорно продвигать сложные геометрические ядра, иногда им не принадлежащие, тогда как визуализация, симуляции и анимация постепенно переезжает в популярные и бесплатные инструменты для некоммерческого использования - Blender, Unity, Unreal Engine и Omniverse.
Если отказаться от параметрической геометрии при обмене и обработке данных в пользу MESH-геометрии, зависимость от CAD-программ и геометрических ядер значительно сократится. Это позволит сделать работу с данными более прозрачной и ускорит развитие уже популярных форматов, таких как OBJ, gLTF, DAE и USD. Осознавая эту тенденцию, CAD-вендоры стремятся удержать пользователей внутри своих экосистем. Для этого они продвигают "удобные" форматы интероперабельности, которые формально позиционируются как открытые. Однако на практике для их экспорта требуется подписка на CAD (BIM) программы, а для обработки — знания API и навыки по маппингу особенностей сложных геометрических ядер.
Сегодня в мире проектирования и строительства сложность доступа к данным привела к чрезмерной инженерии в управлении проектами.  Средние и крупные строительные и проектировачные компании вынуждены либо поддерживать тесные отношения с поставщиками CAD (BIM) решений для доступа к данным через API и такие продукты, как Forge и ACC, либо обходят ограничения поставщиков CAD, используя дорогие SDK-конвертеры для реверс-инжиниринга.
Доступ к собственным проектным данным не должен требовать специального ключа, абонентской платы на облачное решение или волшебного заклинания в виде запроса API.
Доступ к информации — это право, а не привилегия.
Тим Бернерс-Ли, изобретатель World Wide Web
Доступ к открытым к данным откроет для строительного бизнеса следующий ящик пандоры, который неизбежно приведёт к трансформация всей строительной отрасли. 




ГЛАВА 2.5 
МОДЕЛИРОВАНИЕ ДАННЫХ И ПОЯВЛЕНИЕ СТАНДАРТОВ

Скорость принятия решений 
В средних компаниях существуют десятки, а в крупных - тысячи систем или баз данных (рис. 1.2-2), которые должны постоянно наполняться данными и при этом уметь работать друг с другом. Все новые данные, полученные в результате обработки поступающей информации, создаются в системах для решения конкретных бизнес-запросов. 
И если раньше решения в компании принимал главный руководитель или менеджер на основе собственного опыта, который вручную собирал все данные для анализа, то в современном мире быстрого потока данных работа смещается в сторону автоматизированной аналитики.
Простое "традиционно-ручное" обсуждение бизнес-процессов на уровне руководителей будет смещаться и уже смещается в сторону операционной аналитики, которая требует быстрых ответов на бизнес-запросы.
Эпоха, когда бухгалтеры и сметчики могли позволить себе тратить много времени на составление отчетов, таблиц количества и смет, уходит в прошлое. 

   Рисунок 2.5-1. В строительной отрасли принятие решений занимает несколько дней, в отличие от других отраслей, где на это уходят часы или минуты 
Современные компании требуют быстрых ответов на свои аналитические вопросы, ожидая результатов в течение нескольких минут. Заглядывая в будущее, можно сказать, что вряд ли какая-либо крупная компания будет мириться с длительными процессами и временем ответа в часы или дни, которые сегодня приняты в строительной отрасли.
Считайте то, что поддается подсчету, измеряйте то, что поддается измерению, а то, что не поддается измерению, сделайте измеримым.
-Галилео Галилей

В современной строительной отрасли отсутствие стандартов качества и автоматизации привело к тому, что обработка и анализ данных происходят гораздо медленнее, чем в других отраслях. 
Одной из основных проблем, препятствующих обработке и интеграции данных, остается качество и стандартизация как самих данных, так и процессов.
Что отличает строительную отрасль от других секторов экономики, так это устаревшие подходы и принципы, которые повсеместно распространены в компаниях, работающих в строительном секторе. 
Без стандартизированных, качественных и согласованных данных эффективное взаимодействие между различными системами невозможно. Отсутствие согласованности приводит к сбоям в работе, задержкам и увеличению расходов. 

Стандартизация и интеграция данных о строительстве
Р
абота с данными в современных компаниях, требует четкой стратегии стандартизации и проверки данных. Такой подход гарантирует, что в процессах будут циркулировать только высококачественные данные, что ускорит их обработку и будет способствовать быстрому и качественному принятию решений.
В классической ситуации компания ежедневно или еженедельно получает сотни электронных писем, PDF-документов, проектных файлов САПР (BIM), данных с датчиков IOT которые необходимо интегрировать в бизнес-процессы компании. Лес систем должен получать питательные вещества в виде разноформатных данных, чтобы добиться нужных компании результатов.
Поскольку данные имеют разную структуру и содержание, часто кажется, что с такой задачей, как потоковая обработка и интеграция поступающих данных, просто физически невозможно справиться без привлечения большого количества специалистов и менеджеров.


   Рисунок 2.5-2. Обеспечение здоровой жизнедеятельности экосистемы компании требует быстрого и качественного снабжения ресурсами всех ее систем
Чтобы эффективно справиться с потоком данных, не обязательно нанимать целую армию менеджеров, в первую очередь необходимо разработать строгие требования к данным и использовать соответствующие инструменты для их проверки, унификации и обработки.
Качество данных описывается через требования к данным конкретной системы. Для работы с данными необходимо четко понимать, какие данные должны получать специалисты и какие требования предъявляет компания к входящим данным для использования в своих системах. 
Требования к данным описывают критерии качества, структуры и полноты получаемой и обрабатываемой информации. 
К ним относятся, например, точность технических данных в PDF-документе или соответствие отраслевым стандартам. Элементы-сущности из форматов САПР (BIM) требуют проверки на соответствие определенным техническим атрибутам, в то время как например проверка отсканированных изображений требует правильной даты и атрибутов общей суммы контракта.




   Рисунок 2.5-3. Проверка и обеспечение качества данных - самый дорогостоящий и сложный этап подготовки данных к интеграции 
в другие системы
Успешное управление данными в строительной компании требует комплексного подхода, включающего разработку требований к качеству данных и использование правильных инструментов для их проверки.

Появление требований к данным
И
з-за постоянно растущего количества систем в компаниях по отделам перемещаются менеджеры, отвечающие за различные системы, которые, не успевая за растущим объемом информации, просят специалистов создавать данные таким образом, чтобы эти данные можно было использовать в других системах и приложениях. Это требует от инженеров и специалистов, занимающихся созданием данных, адаптировать их под множество платформ, хотя они часто не знают, как именно их данные будут применяться в будущем.


Инженеры и специалисты, создающие данные, часто не знают и не понимают, где созданные ими данные будут использоваться в дальнейшем. 
Поэтому главная задача управляющих менеджеров компаний, работающих в строительной отрасли, - сделать этот процесс прозрачным и понятным для всех участников.

   Рисунок 2.5-4. Бизнес основан на взаимодействии различных ролей, каждая из которых требует определенных атрибутов, критически важных для их выполнения
Чтобы разработать точные требования к данным для строительного проекта, необходимо начать со всестороннего понимания процессов и приложений. Строительные проекты сильно различаются по сложности, часто включают в себя приложения и системы, каждая из которых требует точной актуальной информации.

   Рисунок 2.5-5. Качество данных зависит от качества требований, которые создаются для конкретных случаев использования данных
Под задачи бизнеса необходимо или создавать новые таблицы и базы данных или использовать уже существующие в компании по новым правилам. Чтобы эффективно написать требования к данным в существующих таблицах и базах данных, необходимо сначала понять специфику процессов и приложений, для которых они собираются и используются. Этот критически важный процесс сбора бизнес-требований для создания и настройки баз данных и таблиц известен как моделирование данных.

Моделирование данных: концептуальная, логическая и физическая модель
Ч
тобы решить проблемы доступа и повысить эффективность управления данными, таблицы и базы данных создаются в соответствии с требованиями бизнеса с помощью методов моделирования данных. Моделирование данных — это фундамент, который компания должна заложить, прежде чем приступать к обработке данных и автоматизации процессов.
Модель данных служит концептуальным инструментом для формулирования и обмена бизнес-требованиями. Она отображает характеристики данных, бизнес-правила, которые ими управляют, и организацию данных в таблицах и базе данных.
В процессе моделирования данных, похожем на строительство дома, компания нанимает архитектора данных для определения бизнес-требований к будущей базе данных. Затем архитектор создает модель данных, после чего та же компания нанимает строителей, то есть администраторов и разработчиков баз данных, для реализации проекта с учетом бизнес-требований.
Таким образом, каждая строительная компания, помимо возведения зданий, должна овладеть искусством "строительства" баз данных (таблиц) и научиться виртуозно создавать связи между ними, словно соединяя кирпичики в надежную и крепкую стену знаний и данных компании.
Ключевые понятия в моделировании данных включают:
• Сущности: они представляют собой элементы в бизнес-контексте, для которых собираются данные. На уровне создания модели проекта в программном обеспечении САПР (BIM) сущности могут быть отдельными элементами проекта, в то время как на уровне сметы или расчета сущности могут быть группами элементов, собранных по типам, категориям или другим атрибутам.
• Атрибуты: атрибуты служат для упорядочивания и определения структуры данных, охватывая конкретные детали, которые необходимо хранить о сущностях. Сюда может входить информация о размерах элемента-сущности, его свойствах, логистических параметрах, ценах на сборку — все это характеристики сущности.

• Отношения: связи между сущностями показывают, как одна сущность связана с другой в модели данных. Эти связи можно классифицировать как "один к одному", "многие к одному" или "многие ко многим".
• ER-диаграммы: диаграммы "сущность-связь" (ER) визуализируют сущности и их взаимосвязи. Эти диаграммы могут представлять концептуальную, логическую или физическую модель данных, каждая из которых служит для различных этапов моделирования данных.
При проектировании баз данных и табличных отношений в целом понимание уровней абстракции данных необходимо для эффективного построения архитектуры системы. 


   Рисунок XXX. 


Процесс проектирования обычно делится на три основные модели, каждая из которых служит отдельным целям и имеет свой уровень детализации при представлении данных и их структуры. Вот краткий обзор каждой из них:
• Концептуальная модель данных: эта модель описывает основные сущности и их взаимосвязи, не вдаваясь в подробности атрибутов. Обычно она используется на начальных этапах планирования.

   Рисунок 2.5-6. Концептуальная диаграмма описывает содержание системы: высокоуровневое представление сущностей и отношений,
 без технических деталей
• Логическая модель данных: основываясь на концептуальной модели, логическая модель данных включает в себя подробное описание сущностей, атрибутов, ключей и отношений, отображая бизнес-информацию и правила.

   Рисунок 2.5-7. Логическая модель данных подробно описывает типы данных, отношения и ключи, но без системной реализации
• Физическая модель данных: эта модель описывает необходимые структуры для реализации базы данных, включая таблицы, столбцы и отношения. Она фокусируется на производительности базы данных, стратегиях индексирования, физическом хранении для оптимизации физического развертывания баз данных. 

   Рисунок 2.5-8. Физическая модель данных определяет, как будет реализована система, включая таблицы и специфические детали базы данных
Физическая модель часто существенно отличается от логической. В среднем распределение времени на моделирование выглядит так: около 50% уходит на концептуальную модель, 10% — на логическую и 40% — на физическую.
Такой баланс объясняется тем, что концептуальный этап закладывает основу структуры данных, а логическая модель лишь уточняет связи и атрибуты. Наибольшие ресурсы требуются на физическую модель, так как именно на этом этапе данные внедряются в конкретные платформы и инструменты. Правильность такого распределения зависит от проекта.
Описание процессов на концептуальном уровне часто приводит к разночтениям, бюрократизации и субъективной интерпретации данных. Напротив, переход к управлению на уровне структурированных данных и их атрибутов позволяет добиться четкого и однозначного понимания. Такой подход устраняет зависимость от человеческого фактора в трактовке процессов и обеспечивает единообразие в интерпретации информации.
Центр передового опыта (COE) по моделированию данных
Современные строительные проекты генерируют огромные объемы данных, требующие эффективной системы структурирования, хранения и использования. Моделирование данных играет ключевую роль в этом процессе, обеспечивая создание стандартизированных структур, позволяющих унифицировать подход к управлению информацией.
Центр передового опыта (COE) по моделированию данных направлен на формирование единого подхода к работе с данными в рамках всего жизненного цикла проекта. Его основная задача – интеграция процессов моделирования в систему управления данными, что позволяет синхронизировать работу различных специалистов, включая проектировщиков, аналитиков, инженеров и управленцев.
Основные аспекты модели управления данными
1. Стандартизация процессов и управление жизненным циклом моделей
COE разрабатывает и внедряет методологии, позволяющие унифицировать создание и управление моделями данных. Это включает формирование структурных шаблонов, методов контроля качества и систем управления версиями, обеспечивающих непрерывность данных на всех этапах работы.
2. Управление ролями и распределение ответственности
В рамках COE определяются ключевые роли в процессе моделирования данных. Каждый участник проекта получает четко определенные функции и зоны ответственности, что способствует слаженной работе команд и снижает риски несоответствия данных.
3. Контроль качества и аудит
Эффективное управление строительными данными требует постоянного мониторинга их качества. COE внедряет механизмы проверки, анализа и обратной связи, позволяющие своевременно выявлять и исправлять несоответствия, а также повышать надежность моделей данных.
4. Управление метаданными и архитектурой информации
Единая система именования и метаданных повышает прозрачность данных и снижает вероятность дублирования информации. COE разрабатывает рекомендации по структурированию данных и применению согласованных стандартов, что облегчает интеграцию информационных потоков в рамках организации.
Оценка эффективности и адаптация методологии
Эффективность работы COE оценивается по множеству критериев, включая уровень внедрения стандартов, удовлетворенность участников процессов и влияние на производительность управления данными. Постоянный анализ и адаптация методик позволяют организации поддерживать актуальность подходов к моделированию данных и своевременно реагировать на изменения в отрасли.
Эффективное моделирование данных требует четкого распределения обязанностей между различными специалистами, обеспечивающими согласованность, целостность и соответствие данных бизнес-целям.
• Стратегическое управление — определяет политику, стандарты и принципы работы с данными.
• Архитектурное проектирование — формирует структуру и архитектуру моделей данных, связывая их с общими бизнес-процессами.
• Разработка моделей — отвечает за проектирование и создание моделей данных в соответствии с установленными требованиями.
• Инженерия данных — реализует интеграционные процессы, поддерживая корректную работу моделей в технической среде.
• Управление качеством данных — обеспечивает их точность, полноту и соответствие регламентам управления данными.
Управление моделями данных
Для работы с моделями данных важно определить единый жизненный цикл — от концепции до внедрения. Это включает:
• Формирование единого подхода к разработке и сопровождению моделей.
• Обеспечение соответствия требованиям бизнеса и архитектуры предприятия.
• Контроль версий и совместимость для сохранения преемственности данных при внесении изменений.
Технологическая поддержка
Для эффективного управления моделированием данных необходимо применение специализированных инструментов:
• Средства проектирования для унификации подходов к разработке моделей.
• Системы управления кодом для контроля версий и автоматизации изменений.
• Платформы документации для централизованного хранения и обмена моделями данных.
Коммуникация и сотрудничество
Важной частью управления моделями данных является прозрачность и согласованность процессов. Для этого COE обеспечивает:
• Публикацию правил и стандартов для единообразного использования моделей.
• Доступность диаграмм и схем для всех заинтересованных сторон.
• Создание культуры совместной работы, где специалисты разных направлений участвуют в развитии моделей данных.
Контроль качества и управление
Модели данных должны соответствовать требованиям бизнеса и техническим стандартам. Для этого вводятся механизмы:
• Стандартизации именования и метаданных для повышения качества данных.
• Регулярных аудитов и проверки качества моделей.
• Механизмов обратной связи для внесения улучшений и устранения несоответствий.
Оценка эффективности работы COE
Результаты внедрения методологии моделирования данных оцениваются по нескольким направлениям:
• Качество подготовки специалистов — анализ эффективности программ обучения.
• Степень внедрения стандартов — отслеживание уровня соблюдения требований.
• Производительность процессов — анализ влияния на скорость и точность принятия решений.




Структурированный рабочий процесс разработки модели данных и создания базы данных можно описать следующим образом:
1. Сбор бизнес-требований: этот начальный этап включает в себя сбор информации об операционных потребностях бизнеса и требованиях к данным.
2. Идентификация сущностей: на основе собранных требований на этом этапе определяются конкретные сущности - отдельные объекты, типы, категории, - о которых необходимо собрать данные.
3. Концептуальное и логическое моделирование данных: на этом этапе начинает вырисовываться структура модели данных. Она начинается с концептуальной модели, которая дает широкое представление о сущностях системы и их взаимосвязях, не вдаваясь в подробности. Затем эта модель перерастает в логическую модель данных, которая уточняет концептуальный план, детально определяя конкретные атрибуты, ключи и отношения между сущностями, устанавливая правила и рамки бизнес-данных.
4. Моделирование физических данных: этот этап, являющийся продолжением процесса моделирования данных, превращает логическую модель в подробную техническую схему, пригодную для реализации. В ней указываются точные таблицы, столбцы, типы данных и ограничения целостности, которые будут использоваться для создания базы данных, с учетом соображений производительности, таких как стратегии индексирования и варианты физического хранения.
5. Создание базы данных: кульминацией рабочего процесса является собственно создание базы данных, когда физическая модель реализуется в системе управления базами данных. База данных готова к хранению и организации бизнес-данных.

   Рисунок 2.5-9. Создание баз данных и систем управления данными для бизнес-процессов начинается с формирования требований

Создание базы данных с помощью ChatGPT
В
 этой главе мы создадим пример простой, но функциональной базы данных с минимальным количеством кода с помощью SQLite на примере языка программирования Python. Реляционные базы данных были подробно рассмотрены в главе "Структурированные реляционные базы данных и язык запросов SQL".
SQLite — это легкая, встраиваемая, кроссплатформенная база данных, поддерживающая основные функции SQL. Она имеет открытый исходный код, поскольку ее исходный код на языке C доступен без ограничений. SQLite широко используется в системах автоматизированного проектирования (BIM), ERP, EPM и присутствует практически в каждом смартфоне.
Давайте попросим ChatGPT создать для нас небольшую базу данных SQLlite на основе рисунка 2.5-8 для системы FEM (структурное воздействие) и CPM (график монтажа). 

❏ Отправьте текстовый запрос в ChatGPT:
Создай базы данных SQLlite для систем "Конструктивное воздействие" и "График установки" с рисунка во вложении (рис. 2.5-8 в качестве иллюстрации). ⏎














➤ Ответ ChatGPT:

   Рисунок 2.5-10. Сгенерированный код создает базы данных и таблицы из загруженного изображения, в которые мы теперь можем загружать данные
Этот код может быть выполнен в любой среде Python с поддержкой SQLite, которая обычно включена в стандартное окружение Python. Его можно запустить на локальной машине с Python или через онлайн-интерпретатор Python, способный запускать скрипты и создавать файлы. 
После запуска и выполнения этот код создаст на жестком диске файл - базу данных SQLite с именем construction.db, которая будет содержать таблицы "Structural Impact" и "Installation Schedule". После создания в эти таблицы можно будет вставлять данные, что позволит приступить к таким операциям, как ввод данных, запрос и обновление. Данные можно импортировать в базу данных SQLite из файлов CSV, электронных таблиц Excel, API, веб-скребка (парсера, веб-граббера) или экспортировать данные из других баз данных.
Наполнение базы данных данными — это не просто бесконтрольный процесс заполнения таблиц, а процесс, который в первую очередь должен зависеть от успешного прохождения проверок качества. Только после подтверждения качества исходных данных их можно записывать в таблицы и базы данных и использовать в бизнес-процессах.
В следующем примере мы рассмотрим сценарий, в котором технические специалисты, обслуживающие различные системы, таблицы и базы данных в компании, заполняют проект данными, чтобы выполнить просьбу клиента о добавлении нового окна в текущий проект.


ГЛАВА 2.6 
ТРЕБОВАНИЯ К КАЧЕСТВУ ДАННЫХ И ЕГО ОБЕСПЕЧЕНИЕ
Сбор и анализ требований: основные участники
А
нализ и сбор требований к процессу заполнения и хранения данных начинается с поиска всех заинтересованных сторон. Представим, что у компании есть проект, в котором клиент выдвигает новую просьбу - "добавить дополнительное окно на северной стороне здания". 
В небольшой процесс "запрос клиента на добавление нового окна в текущий проект" вовлечены архитектор, заказчик, специалист по САПР (BIM), менеджер по строительству, менеджер по логистике, ERP-аналитик, инженер по контролю качества, инженер по безопасности, менеджер по контролю и менеджер по недвижимости.
Даже в небольшом процессе могут участвовать десятки различных специалистов. Каждый участник процесса должен понимать требования специалистов, с которыми он связан на уровне данных.
На текстовом уровне (рис. 2.6-1) коммуникация между клиентом и специалистами происходит следующим образом:
➤ Заказчик: "Мы решили добавить дополнительное окно на северной стороне для лучшего освещения. Можно ли это реализовать?"
➤ Архитектор: "Конечно, я пересмотрю проект, чтобы включить новое окно, и вышлю обновленные планы САПР (BIM)".
➤ Специалист по САПР (BIM): "Получил новый проект. Я обновляю САПР (BIM) модель с дополнительным окном и после согласования с инженером FEM предоставляю точное расположение и размеры нового окна".
➤ Менеджер по строительству: "Получен новый проект. Мы корректируем сроки установки 4D и информируем всех соответствующих субподрядчиков".
➤ Инженер по объектам (CAFM): "Я введу данные 6D о новом окне в систему CAFM для будущего управления объектом и планирования технического обслуживания".

➤ Менеджер по логистике: "Мне нужны размеры и вес нового окна, чтобы организовать доставку окна на объект".
➤ ERP-аналитик: "Мне нужны таблицы объемов и точный тип окна для обновления бюджета 5D в нашей ERP-системе, чтобы отразить стоимость нового окна в общей смете проекта".
➤ Инженер по контролю качества: "Как только спецификации окон будут готовы, я удостоверюсь, что они соответствуют нашим стандартам качества и материалов".
➤ Инженер по безопасности: "Я буду оценивать аспекты безопасности нового окна, уделяя особое внимание соблюдению требований и эвакуации по схеме 8D".
➤ Менеджер по контролю: "Основываясь на точном объеме работ от ERP, мы обновим нашу временную шкалу 4D, чтобы отразить установку нового окна, и сохраним новые данные в системе управления контентом проекта".
➤ Рабочий (монтажник): "Нужны инструкции по установке, сборке и срокам выполнения работ. Кроме того, какие-нибудь особые правила безопасности, которые я должен соблюдать?"
➤ Управляющий недвижимостью: "После установки я буду документировать информацию о гарантии и обслуживании для долгосрочного управления".
➤ Менеджер активов: "Инженер по оборудованию, пожалуйста, отправьте окончательные данные для отслеживания активов и управления жизненным циклом. "
➤ Клиент: "Подождите, может, я тороплюсь, и окно не понадобится. Может, стоит сделать балкон".
Рисунок 2.6-1. Текстовый слой коммуникации между клиентом и исполнителем содержит разноформатные текстовые данные
В этом сценарии, в самом начале процесса добавления окна в проект, общение между различными специалистами, включая заказчика и архитектора, происходит в основном через текстовые данные, такие как электронные письма, диалоги, звонки и встречи.
В такой системе текстовых коммуникаций для строительного проекта очень важна система юридического подтверждения и регистрации всех операций по обмену данными и всех принятых решений. Это необходимо для того, чтобы обеспечить юридическую силу и возможность отслеживания каждого принятого решения, инструкции или изменения, что снижает риск возникновения недоразумений в будущем.
Отсутствие юридического контроля и подтверждения решений в соответствующих системах строительного проекта может привести к серьезным проблемам для всех его участников. Каждое решение, распоряжение или изменение, принятое без надлежащего документального оформления и подтверждения, может привести к спорам и судебным разбирательствам. 
Юридическое закрепление всех решений в текстовой коммуникации может быть обеспечено только большим количеством подписанных документов, которые лягут на плечи руководства, обязанного фиксировать все сделки. 
Отсутствие подтверждений транзакций не только задерживает проект, но и может привести к дополнительным финансовым потерям и ухудшению отношений между участниками проекта.


   Рисунок 2.6-2. Каждая система в ландшафте строительной компании служит источником юридически значимых документов в различных форматах
Текстовые коммуникации требуют от каждого специалиста либо ознакомления с полной перепиской, либо регулярного участия во всех встречах, чтобы понимать текущий статус проекта. 
Чтобы перейти от текстовой коммуникации и текстовых записей "операций по принятию решений" к системному уровню транзакций, необходимы методы преобразования текстовых взаимодействий в более структурированный и удобный для использования формат. Как и в моделировании данных (рис. 2.5-7), мы перешли от контекстуально-идейного уровня к концептуальному уровню, добавив системы и инструменты, используемые участниками, и связи между ними.





   Рисунок 2.6-3. Чтобы научиться управлять и автоматизировать процесс валидации, необходимо визуализировать и структурировать требования
Первый шаг в систематизации требований и отношений - визуализация всех связей и отношений с помощью наглядных блок-схем. Концептуальный уровень не только облегчает всем участникам процесса понимание всей технологической цепочки, но и наглядно показывает, зачем и для кого нужны данные на каждом этапе процесса.

REV Блок-схемы процессов и эффективность концептуальных схем
И
з-за быстрого роста количества оцифрованных документов, когда специалисты только фиксировали и хранили данные, требования к данным, процессам сбора и самим базам данных или таблицам формировались редко. 
Чтобы преодолеть разрыв между традиционными методами управления данными и современными цифровыми требованиями, необходимо признать эволюцию обработки данных от простого хранения до сложного анализа и автоматизации. 





Такая трансформация требует перехода к структурированному и концептуальному подходу к управлению данными. Сосредоточившись на создании концептуальных основ и визуальных представлений, таких как блок-схемы, организации смогут лучше понять особенности и тонкости собственных процессов.

Если есть необходимость в процессах не просто хранения данных, а их анализа или автоматизации, то необходимо начинать заниматься темой создания концептуально-визуального уровня требований.
В нашем примере каждый специалист может входить не только в небольшую команду, но и в более крупный отдел, включающий до десятка экспертов под управлением главного менеджера. Каждый отдел использует специализированную базу данных приложения (например ERP, CAD, MEP, CDE, ECM, CPM и др.), которая регулярно пополняется входящей информацией, необходимой для создания документов, регистрации юридического статуса решений и управления процессами.
Это похоже на работу древних менеджеров 4000 лет назад, когда для юридического подтверждения решений использовались глиняные таблички и папирусы. Отличие современных систем от их глиняных и бумажных предшественников заключается в том, что современные методы дополнительно включают процесс преобразования текстовой информации в цифровую форму для дальнейшей обработки в других системах и инструментах.
Создание визуализации процесса в виде концептуальных блок-схем поможет описать каждый шаг и взаимодействие между различными ролями, делая сложный рабочий процесс более понятным и простым.
Визуализация процессов обеспечивает прозрачность и доступность логики всего процесса для всех членов команды.







Тот же коммуникативный процесс по добавлению окна в проект, который был описан в виде текста и сообщений (рис. 2.6-1) в виде блок схемы выглядит следующим образом:

   Рисунок 2.6-4. На схеме участники проекта общаются как пользователи базы данных, их запросы связывают различные системы
К сожалению, часто, представляя процессы в виде блок-схем с приложением стандартных документов, специалисты и руководители ограничиваются "концептуальным уровнем" визуализации процессов, полагая, что участники проекта поймут их функции благодаря блок-схеме и самостоятельно справятся с требованиями и проверкой качества данных.
На концептуальном уровне специалистам сложно понять требования других систем и приложений в компании, используемых в различных отделах. Эта трудность возникает потому, что участники процесса часто не понимают, каковы их собственные требования к данным, и не могут определить по концептуальным блок-схемам, какие требования к данным нужны их коллегам, с которыми они взаимодействуют в рамках общего процесса.
В результате, даже если процесс уже детально описан на концептуальном уровне с помощью блок-схем, это не обязательно делает его более эффективным. Визуализация часто только облегчает работу менеджеров, которые, применив пошаговую систему отчетности, теперь могут удобнее запрашивать информацию у коллег и отслеживать процесс вручную с помощью блок-схем.
По мере продвижения к более сложным экосистемам данных внедрение концептуальных и визуальных инструментов становится критически важным для того, чтобы процессы обработки данных были не только эффективными, но и соответствовали стратегическим целям организации. Согласованность данных начинается с глубокого понимания сценариев использования, что закладывает основу для определения минимальных требований к сбору и анализу данных. 
Принятие минимализма в работе с данными естественным образом приводит к улучшению управления данными. Имея четкие рамки, основанные на минимальных требованиях, организации могут реализовать эффективные стратегии управления данными, которые обеспечивают качество, безопасность и соответствие данных на протяжении всего жизненного цикла.

   Рисунок 2.6-5. Работа по созданию информации должна начинаться с определения минимальных необходимых требований к получаемым данным
Чтобы полностью перевести этот процесс по добавлению окна (рис. 2.6-1) на уровень данных, нам нужно пойти на уровень глубже и перевести концептуальную визуализацию процесса на логический и физический уровень данных, требуемых атрибутов и их граничных значений.

Структурированные требования и регулярные выражения RegEx
Б
ольшая часть данных (80% [16]) в компаниях создается в неструктурированных форматах, что замедляет или делает невозможным их бесперебойный поток, поэтому мы преобразуем текстовые, неструктурированные и полуструктурированные данные в структурированную форму, чтобы повысить эффективность обработки данных.
Точно так же, как специалисты часто не знают, как перевести много форматные данные в структурированные форматы, специалисты также не знают, как структурировать свои требования и пожелания, оставляя их в текстовом формате на протяжении всего процесса. 
Точно так же, как мы уже преобразовали данные из неструктурированной текстовой формы в структурированную, в процессе работы над требованиями мы будем преобразовывать текстовые требования в структурированный формат "логического и физического уровня". 
В табличной форме мы опишем требования к каждой системе в виде атрибутов и их граничных значений.

   Рисунок 2.6-6. Преобразование текстовых требований в формат таблицы с описанием атрибутов сущностей упрощает понимание для других специалистов
В нашем примере рассмотрим требования к данным инженера по контролю качества, который использует систему управления качеством строительства (CQMS) для обеспечения соответствия стандартам и требованиям, предъявляемым к сущности проекта, в данном случае новому окну.
В качестве примера рассмотрим некоторые важные требования к атрибутам сущностей типа оконных систем в CQMS (рис. 2.6-7): энергоэффективность, акустические характеристики и гарантийный срок. Каждая категория включает в себя определенные стандарты и спецификации, которые необходимо учитывать при проектировании и установке оконных систем.

   Рисунок 2.6-7. Инженер по контролю качества проверяет оконные сущности на соответствие стандартам энергоэффективности, звукоизоляции и гарантии
Требования к данным, которые инженер по контролю качества задает в виде таблицы, имеют следующие граничные значения:
● Класс энергоэффективности окон варьируется от "A++", обозначающего наивысшую эффективность, до "B", считающегося минимально допустимым уровнем, и эти классы представлены списком ["A++", "A+", "A", "A", "B"].
● Акустическая изоляция окон, измеряемая в децибелах и показывающая их способность снижать уличный шум, определяется регулярным выражением \d{2}dB.
● Атрибут "Гарантийный срок" для сущности "Тип окна" начинается с пяти лет, устанавливая этот срок как минимально допустимый при выборе продукта; также указываются значения гарантийного срока, например ["5 лет", "10 лет" и т. д.].
В рамках установленных атрибутов классы ниже "B", такие как "C" или "D", не пройдут проверку на энергоэффективность окон при появлении новых данных. Акустическая изоляция окон в данных или документах, поступающих к инженеру по контролю качества, должна быть обозначена двузначным числом, за которым следует постфикс "дБ", например, "35 дБ" или "40 дБ", а значения вне этого формата, такие как "9 дБ" или "100 дБ", не будут приняты.






 Гарантийный срок должен начинаться минимум с "5 лет", а более короткие сроки, такие как "3 года" или "4 года", не будут соответствовать требованиям, которые инженер по качеству описал в формате таблицы.

Для проверки значений на соответствие граничным значениям из требований в процессе валидации мы используем или логические операции (например, больше, меньше для числовых значений) или регулярные выражения (для строковых и текстовых значений таких как в атрибуте "Акустические производительность") для проверки согласованности и целостности данных на основе заранее определенных правил.
Регулярные выражения (RegEx) используются в языках программирования, включая Python (Re), для поиска и изменения строк. Regex — это как детектив в мире строк, способный с точностью идентифицировать текстовые шаблоны в тексте.
В регулярных выражениях буквы описываются непосредственно с помощью соответствующих символов алфавита, а числа могут быть представлены с помощью специального символа \d, который соответствует любой цифре от 0 до 9. Квадратные скобки используются для обозначения диапазона букв или цифр, например, [a-z] для любой строчной буквы латинского алфавита или [0-9], что эквивалентно \d. Для нечисловых и небуквенных символов используются \D и \W соответственно.
Популярные варианты использования RegEx:
● Проверка адреса электронной почты: чтобы проверить, является ли строка действительным адресом электронной почты, можно использовать шаблон «^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$». 

● Извлечение даты: «\b\d{2}\d{2}\d{2}\d{2}\d{2}\d{2}\.\d{2}\.\d{4}\b» шаблон может использоваться для извлечения даты из текста в формате DD.MM.YYYYY.
● Проверка телефонных номеров: для проверки телефонных номеров в формате +49(000)000-0000, шаблон будет выглядеть как «\+\d{2}\(\d{3}\)\d{3}-\d{4}».

   Рисунок 2.6-8. Использование регулярных выражений для проверки адресов электронной почты и дат на соответствие определенным шаблонам
Переведя требования инженера по контролю качества в формат атрибутов и их граничных значений, мы превратили их из исходного текстового формата в организованную и структурированную таблицу, облегчив тем самым проверку и анализ поступающих данных в будущем. Наличие требований позволяет отбрасывать данные, не прошедшие проверку, а проверенные данные автоматически передавать в системы для дальнейшей обработки.
Теперь мы преобразуем все требования всех специалистов из нашего процесса установки нового окна в упорядоченный список в формате атрибутов и добавим эти списки с необходимыми атрибутами в нашу блок-схему для каждого специалиста.

   Рисунок 2.6-9. На логическом уровне процесса атрибуты, которые обрабатывает каждый специалист, добавляются к соответствующим блокам
Добавив все атрибуты в одну общую таблицу процесса, мы преобразуем информацию, представленную ранее в виде текста и диалога (рис. 2.6-1), в структурированную и систематизированную форму таблиц, связанных между собой с помощью блок-схемы (рис. 2.6-10.).

   Рисунок 2.6-10. Преобразование неструктурированного текста в структурированные таблицы помогает понять требования на физическом уровне

Требования к данным теперь четко структурированы, и следующим шагом будет создание данных, сбор данных и их подготовка к процессу проверки. 
Требования к каждой системе должны быть доведены до сведения специалистов, которые создают данные для этих конкретных систем. Только когда у вас есть требования, вы можете начать создавать данные на их основе, чтобы затем автоматизировать процесс проверки и передачи данных.
При соответствии данных установленным требованиям, они автоматически интегрируются в экосистему данных компании, направляясь непосредственно тем пользователям и системам, для которых были предназначены. Верификация данных на предмет наличия и соответствия атрибутов и их значений гарантирует, что информация соответствует необходимым стандартам качества и готова к применению в сценариях компании. Это особенно важно на этапах процесса, где вводится новый элемент проекта, требующий высокой актуальности и качества данных.

Сбор данных для проверки
Т
ребования к данным определены, и теперь, чтобы приступить к проверке, нам нужно собрать данные, которые мы хотим проверить, и зафиксировать текущее состояние информации в базах данных. Мы должны подготовить и преобразовать входящие данные из неструктурированных, слабоструктурированных, текстовых и геометрических форматах в структурированные, как мы делали это в главах выше, посвященных преобразованию различных типов данных. После преобразований любые данные, поступающие в процесс, выглядят как открытые структурированные таблицы.
Мы можем проверять каждый входящий документ отдельно, можно сделать единовременный снимок всех входящих (и уже существующих) данных или подключится к внешним или внутренним база данных. В нашем примере этот вымышленный снимок создается для базы данных САПР (BIM) в 23:00:00 пятницы, 29 марта 2024 года.


   Рисунок 2.6-11. Снимок таблицы проекта САПР (BIM), показывающий текущие сведения об атрибутах для новой сущности окна
На рисунке (рис. 2.6-11.) показана информационная таблица проекта архитектора, использующего программы САПР (BIM). В этой таблице-базе данных отображаются уникальные идентификаторы оконных и дверных систем (атрибут "ID"), типы (атрибут "TypeName"), размеры (атрибуты "Width" и "Length"), материалы (атрибут "Material"), энергетический рейтинг и акустические характеристики и другие атрибуты. Такая таблица, заполненная в программе САПР (BIM), собирается из различных отделов и документов, формируя информационную модель проекта. 
Благодаря инструментам реверсинжиниринга, рассмотренным в главе "Перевод данных САПР (BIM) в структурированную форму", эта информация из различных инструментов и редакторов САПР (BIM) может быть организована в отдельные таблицы или объединена в одну общую таблицу, объединяющую различные разделы проекта.

   Рисунок 2.6-12. Структурированные данные из различных систем представляют собой двумерную таблицу со столбцами, обозначающими атрибуты элементов
Проект базы данных САПР (BIM) в среднем состоит из десятков и сотен тысяч элементов (см. набор данных из главы "Пример больших данных на основе данных САПР (BIM)"). Эти элементы группируются в сущности по типам и категориям и варьируются от окон и дверей различных видов до бетонных плит и элементов стен. Уникальные идентификаторы (атрибуты native IDs) из программы САПР (BIM) или ее типа (атрибуты "Type Name", "Type" или "Family") для нового окна на северной стороне позволяют отслеживать одну и ту же сущность в разных системах. В нашем примере информация о новом окне должна быть записана во всех системах с одним и тем же цифровым или буквенным идентификатором объекта: "W-NEW".
В то время как имена и идентификаторы сущностей должны быть одинаковыми во всех системах, набор атрибутов-параметров и их значения различаются в разных системах. Архитекторы, инженеры-конструкторы, менеджеры по строительству, логисты и управляющие недвижимостью смотрят на одни и те же сущности и их атрибуты по-разному.
Для каждой роли в процессе предусмотрены базы данных с собственным пользовательским интерфейсом - от проектов САПР (BIM) и оценки воздействия на структуру до графиков монтажа, логистики доставки и хранения, а также управления недвижимостью.
Каждая система управляется профессиональной командой специалистов, где за суммой всех решений, принимаемых по введенным значениям в конце цепочки, стоит менеджер системы, который отвечает за юридическую обоснованность и качество введенных данных.

   Рисунок 2.6-13. Одна и та же сущность имеет одинаковый идентификатор в разных системах, но разные атрибуты, которые важны только в данной системе
После организованного сбора структурированных требований и данных на логическом и физическом уровне нам остается проверить данные, полученные из различных поступающих документов или из разных систем, на соответствие собранным требованиям.

Проверка данных и результаты проверки
Н
овые данные, поступающие в системы компании или уже собранные и записанные в виде документов, таблиц и баз данных от менеджера по недвижимости, архитектора, инженера-строителя, руководителя проекта и логиста, должны пройти процесс проверки, чтобы убедиться, что они соответствуют требованиям, которые мы ранее сформировали.



Для проверки новых данных, поступающих в систему - неструктурированных, текстовых или геометрических, - их необходимо преобразовать в слабоструктурированный или структурированный формат. В процессе проверки каждая уже преобразованная таблица поступающих или существующих данных должна быть проверена на соответствие полному списку требуемых атрибутов и их допустимых значений.
Преобразование различных типов данных: текста, изображений, PDF-документов и смешанных данных САПР (BIM) в структурированную форму было подробно рассмотрено в главе "Преобразование данных в структурированную форму".
В случае с базой данных САПР (BIM), которую мы разложили на полуструктурированный формат геометрии и структурированную атрибутивную таблицу элементов, мы ищем атрибуты и их граничные значения, которые, по мнению других экспертов, должны быть в базе данных САПР (BIM), прежде чем данные можно будет использовать вне системы САПР (BIM).


   Рисунок 2.6-14. Атрибутивная таблица сущностей САПР (BIM) проекта и таблица требований к атрибутам с граничными значениями для оконной сущности
Используя библиотеку Pandas, о которой мы рассказывали ранее в главе "Pandas: Незаменимый инструмент для анализа данных", мы проверим данные из табличного файла, извлеченного из файла Revit® САПР (BIM) (IFC, DWG, NWS, DGN), используя требования из другого табличного файла. 
Загрузим данные из файла raw_data.xlsx (САПР (BIM) проект), проверим их с помощью проверки и сохраним результат в новом файле checked_data.xlsx. Приведем код для решения этой задачи с помощью текстового запроса в языковой модели ChatGPT, который мы уже использовали в предыдущих примерах.
❏ Отправьте текстовый запрос в ChatGPT:
Напиши код для проверки таблицы из файла raw_data.xlsx и проверьте их с помощью правил проверки: значения столбцов 'Width' и 'Length' больше нуля, 'Energy Rating' входит в список ['A++', 'A+', 'A', 'B'], а 'Acoustic Performance' не меньше заданного минимума, с добавлением итогового столбца проверки, и сохраните итоговую таблицу в новый файл Excel checked_data.xlsx ⏎
➤ Ответ ChatGPT:
 
 Рисунок 2.6-15. Сгенерированный код ChatGPT, который проверяет преобразованный САПР (BIM) проект на соответствие требованиям к 
атрибутам в виде граничных значений

Этот код можно запустить в одной из популярных IDE: PyCharm, Visual Studio Code (VS Code), Jupyter Notebook, Spyder, Atom, Sublime Text, Eclipse с плагином PyDev, Thonny, Wing IDE, IntelliJ IDEA с плагином Python, JupyterLab или популярных онлайн-инструментах Kaggle.com, Google Collab, Microsoft Azure Notebooks, Amazon SageMaker.
Выполнение кода проверки покажет (рис. 2.6-16), что "элементы-сущности" W-OLD1, W-OLD2, D-122 (и другие элементы) из базы данных САПР (BIM) соответствуют требованиям к атрибутам: ширина и длина больше нуля, а класс энергоэффективности является одним из значений списка 'A++', 'A', 'B', 'C'.
Нужный нам и недавно добавленный элемент W-NEW, отвечающий за новое окно на северной стороне, не соответствует требованиям (Рис. 2.6-16 атрибут „Requrments Met“), поскольку его длина равна нулю и в нем не указан класс энергоэффективности (значение "0.0" считается неприемлемым).


   Рисунок 2.6-16. Проверка выявляет сущности, которые не прошли проверку, и показывает результаты в виде нового атрибута со значениями 'False' или 'True'
Аналогичным образом мы проверяем согласованность всех сущностей и необходимых атрибутов для каждой из систем, таблиц, баз данных во всех данных, которые мы получаем в процессе добавления окна в проект.
Для наглядности в итоговых таблицах мы будем отмечать зеленым цветом те атрибуты и их значения, которые готовы к использованию в других системах управления строительными проектами, а желтым (не критично) и красным (критично) - те атрибуты, которые не соответствуют требованиям, предъявляемым к сущности категории окна.

   Рисунок 2.6-17. Результат проверки позволяет определить, 
какие данные не соответствуют требованиям
В результате проверки мы получаем список доверенных и проверенных элементов сущности с их идентификаторами, которые были проверены на соответствие требованиям к атрибутам. Проверенные элементы обеспечивают уверенность в том, что эти элементы соответствуют заявленным стандартам и спецификациям для всех систем, участвующих в процессе добавления окон (подробнее об автоматизации проверки данных и создании автоматизированного процесса ETL мы поговорим в главе "Автоматизация ETL и проверки данных").
Прошедшие качественно проверку сущности редко оказываются в центре нашего внимания. В отличие от хорошей информации, которую нам не нужно никуда передавать дальше - информацию об элементах, которые не прошли проверку, необходимо передавать не только в виде таблиц, но и с помощью различных методов визуализации. Визуализация улучшает наше понимание общего состояния качества различных объектов проекта, позволяя быстро устранять и улучшать качество атрибутов или их значений.

Визуализация результатов проверки
В
арианты визуализации результатов проверки, помимо сводных таблиц, могут включать панели, диаграммы или PDF-документы, в которых элементы распределяются по группам, например, в зависимости от их статуса: зеленый цвет - для проверенных элементов, желтый - для элементов, требующих внимания, и красный - для элементов с неполными или неправильными значениями.
В процессе проверки мы последовательно анализируем данные (сущности) из каждой системы: от управления недвижимостью и данных САПР (BIM) до графиков монтажа и логистики. 
В нашем примере для визуализации результатов аудита мы автоматически создадим для каждого специалиста соответствующие PDF-документы с описанием результатов в зависимости от итогов проверки:
● Документ без комментариев: "Спасибо за совместную работу".
● Документ с комментарием: " В этом документе перечислены элементы, их атрибуты и значения, которые не прошли проверку на соответствие".

   Рисунок 2.6-18. Валидация и автоматическое создание отчетных документов ускоряют процесс поиска и устранения недостатков данных
Благодаря автоматизированному процессу проверки - как только обнаруживается ошибка или пробел в данных, мы мгновенно отправляем уведомление в виде сообщения в чате, электронной почты или PDF-документа лицу, ответственному за соответствующие сущности и их атрибуты, со списком элементов и описаний атрибутов, которые не прошли проверку.

   Рисунок 2.6-19. Автоматически отчеты по результатам проверок облегчают понимание ошибок и ускоряют работу по заполнению проектных данных
Например, если в систему управления недвижимостью поступает документ, в котором неверно заполнен атрибут "Гарантийный срок", менеджер по недвижимости получает оповещение со списком атрибутов, которые необходимо проверить и исправить. 
Аналогичным образом, любые недочеты в графике установки или данных о логистике приводят к автоматическому формированию отчета и отправке электронного письма с результатами проверки соответствующему специалисту.
Помимо PDF-документов и графиков с результатами, возможно создание интерактивных 3D-моделей с выделением элементов с недостающими атрибутами, что позволяет пользователям визуально использовать 3D-геометрии элементов для фильтрации и оценки качества и полноты данных элементов в проекте.
Визуализация результатов проверок в виде автоматически генерируемых документов, графиков или приборных панелей значительно упрощает интерпретацию данных и способствует эффективному взаимодействию между участниками проекта.
Автоматизация процесса проверки данных имеет много общего с процедурами ETL. В главе "ETL и автоматизация проверки данных" мы подробно рассмотрим тему ETL и методов автоматизации проверки данных.
Изучив основные типы данных и систем, а также научившись добывать качественные данные для наполнения систем, мы переходим к ключевым аспектам строительства: оценке стоимости и времени проекта, включая оценку объемов, расчет стоимости и составление графиков.










ЧАСТЬ III 

РАСЧЁТЫ НА ОСНОВЕ ДАННЫХ И ДАННЫЕ В БИЗНЕС-ПРОЦЕССАХ
ГЛАВА 3.1 
РАСЧЕТЫ СТОИМОСТИ И СМЕТЫ СТРОИТЕЛЬНЫХ ПРОЕКТОВ
Основы строительства: оценки количества, стоимости и времени
С
реди различных бизнес-процессов, влияющих на выживание компании, работающей в строительной отрасли, одними из главных, как и тысячи лет назад, являются процессы качественного расчета количества групп элементов, определения стоимости проекта и времени.
Именно товарно-денежные отношения стали одной из главных причин появления письменности. Именно товарно-денежные отношения сформировали первые юридически значимые глиняные таблички с расчетами за материалы и труд при возведении первых строительных проектов тысячи лет назад.
Если на протяжении десятков тысяч лет процессы оценки оставались неизменными, а расчет объема проекта выполнялся вручную, то с появлением ERP и CAD-инструментов традиционный мир оценки становится автоматизированным.

   Рисунок 3.1-1. Из множества различных систем наибольшее внимание привлекают инструменты, отвечающие за показатели объема, 
стоимости и времени

Основной интерес строительного бизнеса сосредоточен на данных о сроках и стоимости работ по проекту, за которыми стоят объемы материалов и работ. 
Исторические данные о стоимости и времени выполнения процессов собираются в ходе строительства прошлых проектов на протяжении всей жизни строительной компании и вносятся в базы данных различных систем (ERP, BPM, EPM и т. д.). Наличие и качество этих данных является основным конкурентным преимуществом любой строительной организации.
Отделы смет и калькуляции создаются в компаниях для повышения квалификации компании в области расчета объемов, стоимости и сроков реализации новых проектов на основе исторических данных компании, чтобы уменьшить количество ошибок и погрешностей в расчетах и увеличить прибыль компании. 

Методы расчета сметной стоимости проектов. Ресурсный метод
В
 мире строительства и проектного планирования используется несколько методов для расчета ресурсов и сметной стоимости проектов. К наиболее распространенным методам относятся:
• Ресурсный метод: оценка сметной стоимости проекта на основе подробного анализа всех необходимых ресурсов, таких как материалы, оборудование и труд. Этот метод требует детального перечня всех задач и ресурсов, необходимых для выполнения каждой задачи, с последующим расчетом их стоимости.
• Параметрический метод: использует статистические модели для оценки стоимости на основе параметров проекта. Это может включать анализ стоимости на единицу измерения, такую как площадь застройки или объем работы, и адаптацию этих стоимостей к конкретным условиям проекта.
• Метод единичных показателей (метод единичной стоимости): рассчитывает сметную стоимость проекта, исходя из стоимости за единицу измерения (например, за квадратный метр или кубический метр). Это обеспечивает быстрое и удобное сравнение и анализ стоимости различных проектов или их частей.

• Экспертные оценки (метод Дельфи): основан на мнениях экспертов, которые используют свой опыт и знания для оценки стоимости проекта. Этот метод часто применяется в ситуациях, когда недостаточно данных для использования более формализованных методов.
Параметрический и экспертный метод оценки относится к моделям машинного обучения для подсчётов стоимости и времени проектов. Об этом подробно мы поговорим в главе «Пример использования машинного обучения для нахождения стоимости и сроков проекта».
Одним же из самых популярных в мире строительства был и остаётся ресурсный метод оценки сметной стоимости проекта, который одновременно помогает рассчитывать временные оценки продолжительности отдельных работ и в целом проекта (подробнее в главе «Графики строительства и данные 4D-проекта»).
Чтобы понять ресурсный метод составления смет, калькуляций и графиков в строительстве, проведем параллель с составлением сметы и расчетом стоимости ужина в ресторане. Чтобы определить общую стоимость вечера в ресторане, менеджеру необходимо составить список продуктов и рассчитать время приготовления каждого блюда, а затем умножить полученные затраты на количество гостей. Точно так же в строительстве мы составляем постатейные сметы для каждой категории элементов проекта (объектов), в результате чего общая стоимость проекта получается путем суммирования затрат по всем категориям объектов в итоговой смете. 
Работа по составлению смет и графиков в ресурсном методе начинается с описания всех ингредиентов и объектов, имеющихся в распоряжении компании.
На самом первом этапе расчета стоимости всего проекта, в виде калькуляций и графиков, необходимо предварительно собрать в виде таблицы все предметы, материалы, работы и ресурсы, которыми компания оперирует при выполнении своих строительных проектов.
Информация обо всех элементах, которые могут быть использованы в строительных проектах, собирается в "Базе данных строительных ресурсов и материалов" компании, и эта база данных (или таблица) является ключевым источником для всех последующих расчетов стоимости и времени.


База данных строительных ресурсов
Б
аза данных или таблица строительных ресурсов и материалов - включает в себя подробную информацию о каждом элементе сущности - изделии, материале или услуге, включая его название, описание, единицу измерения и стоимость единицы, зафиксированные в структурированном виде. В этой таблице можно найти все: от разнообразия видов топлива и материалов, используемых в проектах, до подробных списков специалистов различных категорий с описанием почасовой оплаты.
"База данных ресурсов" сродни каталогу товаров интернет-магазина, в котором каждый товар имеет подробное описание своих атрибутов. Это облегчает сметчикам выбор нужных ресурсов, необходимых для расчета конкретных строительных процессов.
"Базу данных ресурсов можно также представить как список всех ингредиентов в поваренной книге ресторана. Каждый строительный материал, оборудование и услуга подобны ингредиентам, используемым в рецептах. "База ресурсов" — это подробный список всех ингредиентов - строительных материалов и услуг, включая их стоимость за единицу: штуку, метр, метр, час, литр и т. д.

   Рисунок 3.1-2. Таблица ресурсов — это список ингредиентов, описывающий материал и услугу с указанием стоимости единицы
Новые элементы сущности могут быть добавлены в таблицу "Базы данных строительных ресурсов" двумя способами: вручную (рис. 3.1-3) или автоматически, путем интеграции с системами управления запасами компании или базами данных поставщиков.

   Рисунок 3.1-3. База данных ресурсов заполняется вручную 
или собирает данные из других баз данных
Типичная строительная компания среднего размера использует базу данных, содержащую тысячи и десятки тысяч таких элементов-сущностей. 
Чтобы не отставать от меняющихся рыночных условий, таких как инфляция, атрибут "стоимость единицы продукции" для каждого продукта (товара или услуги) в системе регулярно обновляется вручную или путем автоматической загрузки фактических цен из других систем.  
Обновления могут происходить ежемесячно, ежеквартально или ежегодно, чтобы обеспечить актуальность и точность расчетов и оценок, поскольку эти минимальные сущности служат основой для сметчиков, которые готовят расчеты и оценки на их основе.

Статьи калькуляции и состав работ
Н
аполнив "Базу данных строительных ресурсов" сущностями, можно приступать к созданию калькуляций, которые рассчитываются для каждого процесса или работы на строительной площадке за определенные единицы измерения: например, за один кубометр бетона, один квадратный метр гипсокартонной стены, за метр бордюра или за установку одного окна.
Например, для возведения кирпичной стены площадью 1 м² (рис. 3.1-4) требуется примерно 65 кирпичей (сущность "Силикатный кирпич"), стоимостью $1 за штуку (атрибут "Стоимость за штуку"), что в сумме составляет $65. Также нам необходимо использовать строительную технику (сущность "Погрузчик JCB 3CX") в течение 10 минут, которая будет размещать кирпичи рядом с рабочей зоной. Поскольку аренда техники стоит 150 долларов в час, 6 минут ее использования обойдутся примерно в 15 долларов. Кроме того, потребуется 2 часа работы подрядчика по укладке кирпича, почасовая ставка которого составляет 30 долларов, а общая сумма - 60 долларов.

Рисунок 3.1-4. Расчеты затрат содержат подробный перечень строительных материалов и услуг, необходимых для выполнения работ
Состав рецептов-калькуляций формируется на основе опыта, накопленного компанией, за плечами которой выполнение больших объемов работ, например по возведению квадратных метров гипсокартонных конструкций или больших объемов работ по установке бордюрного камня или окон.
Как в рецепте описываются необходимые ингредиенты и их количество для приготовления блюда, так и в сметной ведомости приводится подробный перечень всех строительных материалов и услуг, необходимых для выполнения конкретной работы.
Работы, выполняемые многократно - предоставляют рабочим, бригадирам и сметчикам данные о примерном представлении работы в ресурсах, материалах, литрах дизельного топлива и трудочасах на единицу измерения. 
Эти объемные и количественные атрибуты объектов вводятся в сметные системы в виде таблиц, описывающих каждую отдельную задачу и работу, состоящую из минимальных объектов ресурсной базы.

   Рисунок 3.1-5. Для каждой работы атрибут объема сущности умножается на его количество с добавлением процента прибыли
Чтобы получить общую стоимость каждого объекта калькуляции, атрибут стоимости умножается на его количество и фактор ставки. Коэффициент может учитывать различные факторы, такие как сложность работы, риски, ожидаемые накладные расходы и прибыль.
Сметчик, выступая в роли аналитика, переводит слова прораба в повторяющиеся сметы и описывает строительные процессы через ресурсные сущности в виде таблицы.


Таким образом, общая цена всей единицы работы (квадратного метра, кубического метра или штуки), состоящей из ресурсов, отражает как прямые затраты на материалы и рабочую силу, так и дополнительные расходы и наценки компании (рис. 3.1-6). На этом уровне в таблицу калькуляций автоматически (например, по коду элемента или его идентификатору) подгружаются данные из базы ресурсов, которые в свою очередь подгружают описание, и актуальную стоимость за единицу. Сметчику на уровне калькуляций работ остаётся только описать работу или процесс через атрибут количество ресурсов (и дополнительный фактор).

   Рисунок 3.1-6. На этапе расчета стоимости работ (за метр, за квадратный метр) заполняются только атрибуты количества необходимых ресурсов
Созданные расчеты хранятся в виде таблиц - шаблонов типовых проектов, которые напрямую связаны с ресурсной базой. 
Если атрибут цены объекта (продукта, материала) изменяется в ресурсной базе (например, из-за индексации инфляции), этот атрибут описания или стоимости автоматически изменяется в таблице калькуляции стоимости работ, что позволяет сметчикам обновлять только ресурсную базу (рис. 3.1-3), а шаблоны калькуляции стоимости работ и сметы (рис. 3.1-6), могут оставаться неизменными с течением времени.
Шаблоны калькуляции затрат являются гибкими. Для каждого нового проекта создается копия стандартного шаблона калькуляции, что позволяет корректировать конкретные виды деятельности в соответствии с уникальными потребностями нового проекта без изменения исходного шаблона, а также производить индивидуальные расчеты в соответствии с требованиями клиента и находить способы повышения рентабельности. Такой подход позволяет найти баланс между максимизацией доходов, удовлетворением ожиданий клиентов и поддержанием репутации компании.
В некоторых странах подобные шаблоны смет, накопленные за десятилетия в национальном масштабе для стандартизации наценок и обеспечения прозрачности стоимости работ, превращаются в государственные стандарты (стандартизированные ресурсные базы смет), которым должны следовать все компании, работающие на строительном рынке того или иного региона в проектах с государственным участием.

Составление сметы расходов на проект
К
огда шаблоны расчетов отдельных работ и процессов готовы, на следующем этапе нужно умножить стоимость каждой работы на атрибут объема работы или процесса в новом проекте.
При расчете общей стоимости строительного проекта ключевым этапом является суммирование затрат по всем статьям калькуляции, умноженное на объем этих работ в проекте.
Чтобы создать общую стоимость проекта, в нашем упрощенном примере мы начнем с расчета стоимости строительства одного квадратного метра стены и умножения стоимости его расчета (например, работа "1м² стандартной установки стеновых элементов") на общее количество квадратных метров стен в проекте (например, атрибут "Объем" или "Количество" (рис. 3.1-7) сущности типа "Стеновые элементы" из САПР (BIM) проекта).
Аналогичным образом мы применяем этот метод ко всем категориям элементов проекта, перечисленным в смете, умножая стоимость каждого элемента на его объем в данном проекте, что позволяет нам сформировать полную смету всего проекта. 

Как и в случае с калькуляциями на это уровне мы подгружаем автоматически готовые обсчитанные позиции (из шаблона или новые, скопированные из шаблона и подредактированные, позиции), которые приносят с собой стоимость на единицу работы. Соответственно при любом изменение данных в ресурсной базе или калькуляционных таблицах – данные в смете будут автоматически актуализированы. Сметчику остаётся только внести количество данных работ в проекте в виде объёма или количества. 

   Рисунок 3.1-7. На этапе оценки мы определяем только объем 
работ или процесса в новом проекте
В контексте ресторана конечная стоимость мероприятия рассчитывается аналогичным образом и равна конечной стоимости всего ужина, где стоимость каждого блюда, умноженная на количество гостей, складывается в общую стоимость чека (рис. 3.1-8).
Как владелец ресторана умножает стоимость каждого блюда на количество порций, чтобы определить общую стоимость мероприятия, так и менеджер по строительству суммирует стоимость всех компонентов проекта, чтобы получить полную смету строительства.

Таким образом, для каждой работы в проекте определяется ее конечная стоимость, которая, умноженная на атрибутивный объем сущности, соответствующей этой работе, - дает стоимость групп работ, из которой получается конечная стоимость всего проекта. 
Итоговая стоимость проекта представляет собой финансовую картину проекта, позволяя разработчикам и инвесторам понять общий бюджет и финансовые ресурсы, необходимые для реализации проекта.
 
   Рисунок 3.1-8. Итоговая смета рассчитывается путем суммирования атрибута стоимости работ каждого элемента на атрибут его объема 
На протяжении тысячелетий традиционным методом вычисления объемов были ручные способы измерения объемных и количественных характеристик с помощью бумажных чертежей. С наступлением цифровой эры компании обнаружили, что эту же информацию теперь можно автоматически извлекать из геометрических данных, содержащихся в моделях САПР (BIM), что произвело революцию в тысячелетних способах работы с количественными данными, расчетами и вычислениями.


И если процессы составления ресурсных баз, расчетов и смет уже отработаны и полуавтоматизированы, то автоматическое получение качественной информации об объеме и количестве элементов для последнего этапа финальной сметы - остается узким местом в процессах всех расчетов стоимостных и временных атрибутов проекта.
Современные подходы к оценке и сметному делу предполагают автоматическое извлечение объемных и количественных атрибутов из САПР (BIM) моделей, которые включают в себя дополнительные слои информации, помимо геометрической. В дополнение к 3D геометрическим атрибутам в проектных моделях элементы проекта дополняются 4D временными атрибутами и 5D атрибутами, включая аспекты, связанные со стоимостью.


ГЛАВА 3.2 
QUANTITY TAKE-OFF И АВТОМАТИЧЕСКОЕ СОЗДАНИЕ СМЕТ И ГРАФИКОВ РАБОТ 

3D-интеграция: 5D стоимость и 4D время
В
 контексте использования 3D-геометрических атрибутов элементов проекта, информационные слои об атрибутах времени и стоимости элементов обозначаются аббревиатурами 4D и 5D. В слоях атрибутов сущностей 4D time и 5D cost  - геометрические данные из САПР (BIM) проектов используются в качестве источника значений атрибутов объемов сущностей.
• 4D — это информационный слой, который дополняет данные сущностей из 3D-модели проекта атрибутами о продолжительности строительных работ для определенных категорий элементов. 
• 5D расширяет геометрическую информацию 3D-модели атрибутами о стоимости элементов и добавляет аспект финансового планирования и управления затратами в общую информационную модель.

   Рисунок 3.2-1. Оценки стоимости и времени работ, являются одними из основных в информационном ландшафте строительных компаний
Данные о стоимости и 3D, 4D, 5D атрибутивные свойства сущностей, записанные в ERP-системах (или Excel-подобных инструментах), используются для автоматического расчета стоимости и бюджетного планирования.
Атрибуты 5D и получение объемов атрибутов из САПР (BIM) 
П
ри подготовке окончательной сметы строительного проекта, составление которой мы описывали в предыдущих главах (рис. 3.1-7), атрибуты объема для каждой категории элементов проектной организации либо собираются вручную, либо извлекаются из спецификаций атрибутов объема, предоставляемых программами САПР (BIM).
В традиционном ручном процессе прораб и сметчик проводят детальный анализ чертежей, представленных (последние тысячи лет) в виде линий на бумаге или в форматах PDF (PLT) или DWG (последние 30 лет). Опираясь на свой профессиональный опыт, прораб и сметчик рассчитывают атрибуты объемов работ и необходимых материалов. Этот метод требует значительных усилий и времени, а также особого внимания к деталям. Определение атрибутов объема работ таким способом может занять от нескольких дней до нескольких месяцев, в зависимости от масштаба проекта. Кроме того, поскольку все измерения и расчеты выполняются вручную, существует риск человеческой ошибки, которая может привести к неточным данным, что впоследствии скажется на ошибках в оценке времени и стоимости проекта, за которые будет нести ответственность вся компания.
В современной практике использование проектных моделей САПР (BIM) значительно облегчает процесс вычисления атрибутов объема. Это достигается за счет возможности автоматического расчета объема для группы элементов, когда геометрия каждой группы элементов представлена в САПР (BIM) в виде подробных таблиц с атрибутами объема. В таких случаях, при наличии САПР (BIM) модели проекта, сметный отдел обращается к специалистам САПР (BIM) с просьбой экспортировать (выгрузить) объемные и количественные атрибуты элементов проекта в табличной форме. 
Если при разработке 3D-модели САПР были учтены требования сметного отдела, а имена и идентификаторы групп элементов совпадают с идентификаторами сметных групп, данные об атрибутах объема из систем САПР могут быть автоматически введены в сметные системы.
Автоматическое получение объемных атрибутов в виде спецификаций из САПР (BIM) моделей позволяет мгновенно получать актуальные данные о стоимости работ и общей стоимости проекта, обеспечивая при этом высокую точность и эффективность расчетов.

   Рисунок 3.2-2. Атрибуты объемов из таблиц САПР (BIM) автоматически вводятся в смету позволяя автоматически рассчитать общую стоимость проекта
Автоматическое получение количества из проектов САПР (BIM) осуществляется с помощью инструментов QTO (Quantity Take-Off - количественный учет). QTO инструменты работают путем группировки всех объектов проекта по специальным идентификаторам элементов или параметрам атрибутов элементов, используя спецификации и таблицы, созданные в программе САПР (BIM).

QTO Quantity Take-Off: группировка данных по атрибутам
Р
асчет количества материалов (QTO) в строительстве - это процесс получения атрибутов количества и объема ресурсов, необходимых для реализации строительного проекта. Для каждой группы сущностей проекта необходимо выбрать индивидуальный атрибут объема - атрибут количества (например сущности окна), атрибут длины (метры - бордюрный камень), атрибут площади (квадратные метры - гипсокартонные работы) или атрибут объема (кубические метры – бетонные работы). 

Кроме того, у каждой группы сущностей есть свои коэффициенты перерасхода, которые помогают получить реальный объем, а не просто геометрически обоснованный объём. Все эти особенности каждой группы сучностей и учитываются в процессе QTO.
Процесс количественного учета (QTO) необходим для составления точных калькуляций и смет, предотвращающих пере- или недозаказ материалов.
В качестве примера рассмотрим распространенный случай, когда необходимо показать таблицу объемов по типам элементов для определенной категории. Сгруппируем все элементы проекта по типам из категории стен проекта Revit® или IFC и просуммируем атрибуты объема для каждого типа, чтобы представить результат в виде таблицы объемов QTO. Схематичное представление этого процесса показано на рисунке 3.2-3.

   Рисунок 3.2-3. Получение атрибутов объема и количества QTO из проекта напрямую связано с группировкой и фильтрацией элементов проекта
В примере этого типового проекта (рис. 3.2-3) все элементы категории стен сгруппированы по типам стен, например, "Lamelle 11.5", "MW 11.5" и "STB 20.0", и имеют четко определенные атрибуты объема, представленные в метрических кубах. Наша задача - научиться автоматически составлять таблицу атрибутов объема для всех типов в категории стен в любом проекте.

Прошли те времена, когда опытные прорабы и сметчики вооружались линейкой и транспортиром, тщательно измеряя каждую линию на бумаге или PDF-планах - традиция, которая не менялась прошедшие тысячелетия. С развитием 3D-моделирования, где геометрия каждого элемента теперь напрямую связана с автоматически рассчитываемым атрибутом объема, процесс QTO стал автоматизированным.
В нашем примере задача состоит в том, чтобы "выбрать категорию стен в проекте, сгруппировать все элементы по типу и представить информацию об атрибутах объема в табличном формате".

   Рисунок 3.2-4. САПР (BIM) автоматизирует перевод неструктурированной информации о геометрической форме в структурированный атрибут объема 
Из-за закрытого характера данных САПР (BIM) не каждый специалист сегодня может использовать прямой доступ к структурированным данным внутри САПР (BIM) программы (подробнее об этом в главе "Концепция BIM-BOM"). Поэтому многие вынуждены обращаться к инструментам, основанным на концепциях open-BIM и closedBIM, которые разрабатываются и продвигаются производителями САПР (BIM) программ [10].
Создание таблицы с объемными атрибутами из САПР (BIM) проектов с помощью популярных сегодня библиотек open-BIM, таких как IFC.js, потребует около 150 строк кода, а использование IfcOpenShell (open-BIM) или Dynamo-IronPython (closedBIM) позволит сократить код автоматизации до 40 строк (рис. 3.2-6). При работе со специализированными инструментами пользовательского интерфейса, такими как Solibr®, или при создании таблицы непосредственно в Revit® идентичные результаты табличных атрибутов достигаются за 17 нажатий кнопок (рис. 3.2-5).

   Рисунок 3.2-5. Специалисты САПР (BIM), используют от 40 до 150 строк кода 
для создания таблиц атрибутов
Сегодня на рынке представлено огромное количество различных инструментов, которые могут давать идентичные результаты (рис. 3.2-6). С помощью инструментов open-BIM и closedBIM, независимо от объема написанного кода или количества нажатий на кнопки, можно получить одну и ту же таблицу объемов для групп элементов из проекта САПР (BIM). 




   Рисунок 3.2-6. Разные инструменты дают одинаковые результаты в виде атрибутивных таблиц сущностей проекта, но с разными трудозатратами
При работе с проектными данными САПР (BIM) в концепциях open-BIM и closedBIM пользователи полагаются на специализированные инструменты и API, предоставляемые поставщиками САПР (BIM), что добавляет дополнительные уровни зависимостей и необходимости в чтении уникальных классификаций, ограничивая прямой доступ к данным. Это усложняет получение таких данных, как таблицы атрибутов. 
При использовании открытых структурированных данных из САПР (BIM) проектов, как упоминалось в главе "Преобразование САПР (BIM) данных в структурированную форму", процесс значительно упрощается (рис. 3.2-6 – noBIM). Такой подход (без использования маркетинговых концепций с аббревиатурой BIM) использует популярные инструменты из других отраслей, делая поиск информации более простым и удобным.

QTO группировка атрибутов структурированных данных САПР (BIM)
П
еревод неструктурированных данных в структурированную форму значительно повышает эффективность различных процессов: он увеличивает эффективность обработки данных и ускоряет процесс валидации, делая требования ясными и прозрачными, о чем мы уже говорили в предыдущих главах. Аналогичным образом, перевод данных САПР (BIM) в структурированную форму облегчает процесс группировки атрибутов и процесс QTO.
Таблица атрибутов объема QTO - это структурированная таблица, поэтому, используя структурированные данные САПР (BIM), мы имеем одну форму данных и, следовательно, можем группировать данные по одному или нескольким атрибутам с помощью всего одной строки кода, вместо того чтобы использовать десятки или сотни строк кода в open-BIM или closedBIM (рис. 3.2-6), которые работают с полуструктурированными смешанными форматами геометрии и атрибутивной информации или закрытыми собственными форматами САПР (BIM) через API-соединение.
❏ Пример группировки всего проекта по одному атрибуту. Текстовый запрос в ChatGPT:
У меня есть проект как DataFrame - отфильтруйте данные так, чтобы "Type" содержал значение "Type 1".
➤ Ответ ChatGPT:

   Рисунок 3.2-7. Одна строка кода, написанная с помощью ChatGPT, позволяет сгруппировать по атрибуту "Тип" и получить группу элементов 


И если раньше, чтобы начать писать такой простой код, нужно было погрузиться в изучение аналитики данных, то теперь логика процесса переводится в код через текстовые запросы с помощью современных языковых моделей LLM, таких как ChatGPT (подробнее о том, как ChatGPT помогает автоматизировать обработку данных, читайте в главе "ChatGPT и LLM для автоматизации данных").
Автоматизация и языковые модели LLM, такие как ChatGPT, могут полностью избавить специалистов, работающих с группировкой и обработкой данных САПР (BIM), от необходимости изучать языки программирования или инструменты BIM, предоставляя возможность решать задачи с помощью текстовых запросов.
Тот же запрос (рис. 3.2-6) с группировкой данных всего проекта из категории стен и получения объёмов типов этой категории выглядит в популярных инструментах по работе с данными как простой для понимания запрос (рис. 3.2-8):
• При помощи одной строки в Pandas: 
df[df['Category'].isin(['OST_Walls'])].groupby('Type')['Volume'].sum()
Расшифровка: возьми из df – DataFrame элементы атрибут «Категория» равен «OST_Walls», сгруппируй все полученные элементы по «Type» и суммируй для сгруппированных типов атрибут «Объём»

• При помощи ChatGPT (Pandas):
Суммируйте столбец 'Volume', сгруппированный по 'Type', но только для строк, где 'Category' - 'OST_Walls' или 'OST_Columns'.


   Рисунок 3.2-8. Благодаря использованию Pandas и ChatGPT автоматизация обработки данных теперь возможна с помощью текстовых запросов
Получение QTO с данными САПР (BIM) и появление таких инструментов, как ChatGPT, меняет традиционные подходы к получению атрибутивной информации из проектов, предлагая интегрированный и быстрый метод работы также для получения количественных и объемных атрибутов для отдельных объектов и их групп.
Теперь любой менеджер проекта или инженер может за несколько секунд найти, например, общий объем всех элементов категории стен из проекта с большим количеством элементов, написав или произнеся запрос в одном или нескольких предложениях.


   Рисунок 3.2-9. ChatGPT, работая со структурированными данными, 
понимает из контекста текстового запроса, о какой группировке 
и атрибутах спрашивает пользователь
В подобном текстовом запросе (рис. 3.2-9) агент ChatGPT обрабатывает текстовый запрос и суммирует значения атрибута объема всех сущностей элемента с определенным значением атрибута "Категория". В результате получается число, которое представляет собой суммарный атрибут объема в нужном измерении для одной конкретной категории (определенное значение «OST_Walls» для сущностей в атрибуте «Категория»).
Однако если смета рассматривается в целом, то для каждого вида работ должны быть получены отдельные атрибутивные количества или объемы, сгруппированные по одному или нескольким атрибутам. Как правило, сметчики и оценщики имеют индивидуальные правила группировки и расчета суммарного значения количеств и объемов для каждой группы позиций. Чтобы упростить генерацию значений для всех групп, запросы пишутся не в виде текстовых запросов, а в виде таблиц, описывающих правила группировки для групп объектов в проекте.

QTO расчеты по проекту с использованием правил из таблицы Excel
В
 процессе выполнения различных вычислений в строительных проектах возникает необходимость группировать элементы сущности проекта более чем по одному атрибуту.
Например, мы можем классифицировать сущности в категории "Окна" (сущности со значением "OST_Windows" или "IfcWindows" в атрибуте "Категория") на различные типы окон, выбрав только те, которые имеют текстовое значение "Тип 1" в атрибуте обозначающим тип (например, "Type Name" или "Type"), или отсортировать те же элементы по значению теплопроводности, указанной в одном из атрибутов. Аналогичным образом можно группировать объекты, относящиеся к разным типам стен и перекрытий, при этом критерии группировки могут включать любое количество атрибутов и их значений.

   Рисунок 3.2-10. Для каждой группы или категории сущностей существует своя формула группировки для поиска качественных количественных атрибутов
Процесс определения таких правил группировки аналогичен процессу создания требований к данным, описанному в главе "Создание требований и проверка качества данных". Такие правила группировки и вычисления обеспечивают точность и релевантность результатов для вычисления суммарных атрибутов количества или объема любой категории сущности с учетом всех необходимых условий.
Следующий пример кода фильтрует таблицу проектов таким образом, что результирующий набор данных содержит только те сущности, в которых атрибут-колонка «Category» содержит значения «OST_Windows» или «IfcWindows» и в то же время атрибут-колонка «Type» содержит значение «Type 1».

❏ Отправьте текстовый запрос в ChatGPT:
У меня есть DataFrame проекта - отфильтруйте данные так, чтобы в наборе данных остались только записи, у которых атрибут "Категория" содержит значения "OST_Windows" или "IfcWindows" и одновременно атрибут Type содержит значение "Type 1".
➤ Ответ ChatGPT:

   Рисунок 3.2-11. Одна строка кода, похожая на формулу Excel, позволяет сгруппировать все сущности проекта по нескольким признакам
Чтобы получить сущности проекта в форме DataFrame по категории окна только с определенным значением теплопроводности, мы можем использовать следующий запрос в ChatGPT:

❏ Отправьте текстовый запрос в ChatGPT:
У меня есть DataFrame проекта - отфильтруйте данные так, чтобы в наборе данных остались только записи с "Категорией", содержащей значения "OST_Windows" или "IfcWindows", и одновременно столбец ThermalConductivity должен иметь значение 0,5. ⏎
➤ Ответ ChatGPT:
Рисунок 3.2-12. ChatGPT использует Pandas по умолчанию из-за его популярности и распространенности в задачах обработки информации

В этом примере, как и в первом, мы используем логическое условие "&", чтобы объединить два критерия: значение теплопроводности и принадлежность к одной из двух категорий. Метод "isin" проверяет, содержится ли значение атрибута-столбца "Категория" в предоставленном списке.
Далее мы рассмотрим каждую категорию сущностей проекта, установив для каждой отдельное правило группировки и определив окончательную формулу расчета стоимости атрибута объема. Эта формула будет учитывать уникальные характеристики группы и включать такие корректировки, как дополнительные 10 % объема (перерасхода) материала или конкретное дополнительное количество материала. Сохраним правила группировки с формулами для каждой категории в виде структурированной таблицы.
   Рисунок 3.2-13. Таблица группировки атрибутов QTO устанавливает правила группировки элементов проекта, обеспечивая точное общее количество и объем для каждой категории
Собрав правила группировки атрибутов для каждой категории в файле Excel, мы теперь можем автоматически прогнать таблицу проекта через таблицу правил группировки и сгруппировать весь проект для выполнения всех необходимых расчетов с корректировкой атрибутов геометрического объема до привидения его к «реальному объёму».
В процессе автоматического создания объемных таблиц QTO наше приложение должно пройти по всем категориям таблицы правил группировки, взять атрибуты группировки, сгруппировать по ним все элементы проекта и агрегировать атрибут объема для этой группы, дополнительно умножив его на уточняющий фактор или коэффициент. 

Попросим ChatGPT написать для нас код для такого решения, где код должен будет загружать две таблицы - таблицу правил группировки и таблицу самого проекта, а затем применять правила группировки, группировать элементы в соответствии с заданными правилами, вычислять агрегированные значения и сохранять результаты в новый файл Excel.
❏ Отправьте текстовый запрос в ChatGPT:
Мне нужен код для чтения данных из 'basic_sample_project.xlsx', а затем из Grouping_rules_QTO.xlsx сгруппировать все данные по 'Parameter 1' и 'Parameter 2', агрегировать 'Aggregate Parameter', фильтровать по 'Expression2', выполнить вычисления из 'Formel1' и сохранить итоговую таблицу в 'QTQ_table2.xlsx'. ⏎
➤ Ответ ChatGPT:

   Рисунок 3.2-14. Сценарий Python с использованием библиотеки pandas обрабатывает проектные данные САПР (BIM), группируя их в соответствии с заданными в Excel правилами
Конечным результатом выполнения кода будет таблица групп-сущностей, которая содержит не просто обобщенные атрибуты объема из исходной САПР (BIM) модели - а новый атрибут реального объема, учитывающий все требования для корректного создания калькуляций и смет.

   Рисунок 3.2-15. Атрибут "После вычисления" добавляется в сводную таблицу после выполнения кода, который вычисляет реальный объем
Мы можем применить такой код к любому количеству уже существующих или вновь поступающих проектов (RVT, IFC, DWG, NWS, DGN и другие), будь то несколько проектов или сотни проектов в разных форматах.

   Рисунок 3.2-16. Процесс группировки строительных данных связывает данные BIM (CAD) с таблицами QTO через правила из электронной таблицы Excel


Настроенный и параметезированный процесс сбора объемных данных (рис. 3.2-16) позволяет полностью автоматизировать сбор данных о количественных атрибутах и объемах элементов проекта для дальнейшей работы с ними, включая оценку стоимости, расчет углеродного следа (тех значений CO2, которые строительный материал имеет в своих свойствах) и других аналитических задач.
Изучив различные типы данных и инструменты, позволяющие легко организовывать и группировать их по определенным признакам, мы теперь готовы интегрировать данные проекта с различными бизнес-сценариями компании. В таких сценариях, как расчет количества (QTO), задачи обычно включают умножение, проверку или группировку столбцов атрибутов табличных данных.

ГЛАВА 3.3
 4D, 6D-8D И РАСЧЕТ ВЫБРОСОВ УГЛЕКИСЛОГО ГАЗА CO2
Ввод данных о последовательности и расчёт оценки времени выполнения работ в строительном проекте
П
омимо уже рассмотренных случаев создания расчетов для смет, одним из ключевых случаев применения данных в строительстве является определение временных атрибутов для отдельных строительных работ или сроков проекта в целом. Для расчета сроков и календарного планирования работ нам снова придется обратиться ресурсному методу оценки и к базе данных расчетов, подробно описанной в разделе «Расчеты и сметы для строительных проектов».
В процессе расчета стоимости работ по ресурсному методу мы не просто указываем количество материальных ресурсов из «Базы данных строительных ресурсов», мы также включаем в расчеты затраты времени (рис. 3.3-1 позиции с заполненными значениями атрибута «Work order» - порядок работ), присваивая элементам, имеющим атрибуты времени - будь то строительная машина, рабочий или доставка материала - атрибуты «количества времени» и «стоимости времени».

   Рисунок 3.3-1. Расчеты работ в ресурсном методе оценок включают 
в себя временные затраты рабочего времени
Поэтому мы включаем в расчеты не только топливо и материалы, но и время и труд машинистов или вспомогательных рабочих на стройплощадке. В приведенном примере (рис. 3.3-1) таблица затрат представляет собой калькуляцию затрат на установку фундаментного блока с указанием составных частей работы, таких как подготовка, установка каркаса и заливка бетона, а также сопутствующих материалов и временной рабочей силы. Например, первая работа в калькуляции - "Подготовительные работы" - не имеет материальных затрат, но имеет временные затраты, выраженные в рабочих часах.
Чтобы спланировать последовательность работ в таблице калькуляции, атрибут "Порядок работ" - последовательность работ - добавляется вручную в дополнительный столбец для элементов с атрибутами, для которых в измерении объема есть значения времени (час, день), в дополнение к коду работы, описанию, количеству, единице измерения и затратам. Описанная с помощью цифры последовательность работ помогает установить порядок выполнения конкретной задачи на строительной площадке, который будет использоваться для составления расписания.
Графики строительства и данные 4D-проекта
Г
рафик строительства - это визуальное представление плана выполнения работ, которые должны быть выполнены в рамках проекта. Он создается на основе подробных расчетов (таких, как на рисунке 3.3-1), в которых каждая задача-работа расписана по времени и последовательности.
Чтобы определить даты для графика строительства на диаграмме Ганта, мы берем значения атрибута объема времени для каждого элемента из калькуляции фундаментных блоков и умножаем их на количество блоков (в данном случае количество бетонных фундаментных блоков). Этот расчет дает продолжительность каждой задачи. Затем мы наносим эти длительности на временную шкалу, начиная с даты начала проекта, чтобы построить график, и в результате получаем визуальное представление, показывающее, когда каждая задача должна начаться и закончиться.
График помогает руководителям проекта и рабочим четко понимать, когда и в какой последовательности должны выполняться различные этапы строительства, обеспечивая эффективное использование ресурсов и соблюдение сроков.
Представим календарный план работ по установке трех бетонных фундаментных блоков с использованием расчетов из таблицы выше, начиная с 1 мая 2024 года.
Используя таблицу затрат (рис. 3.3-1) из примера выше, попросим ChatGPT запланировать установку 3 элементов фундаментного блока на первое мая 2024 года. Чтобы отправить калькуляцию в ChatGPT, мы можем загрузить таблицу калькуляции в формате XLSX или просто вставить скриншот картинки калькуляции. ChatGPT самостоятельно найдет библиотеку для визуализации изображения таблицы и, умножив временные атрибуты работ из таблицы на их объем, сложит все данные в график.
❏ Отправьте текстовый запрос в ChatGPT:
Создайте план работ с использованием значений из таблицы для установки 3 фундаментных блоков с 01/05/2024 (скриншот рис. 3.3-1 как изображение). ⏎

➤ Ответ ChatGPT: 


Рисунок 3.3-2. Автоматически созданный концептуальный график показывает этапы строительства трех бетонных блоков
Полученный график разделен на горизонтальные столбики, где каждый столбик соответствует определенному этапу работы над блоком. 
Приведённая временная диаграмма (рис. 3.3-2) не учитывает никаких других специфических граничных условий, таких как соблюдение дней недели, рабочих часов/дня и т. д., а предназначена только для примера и концептуальной иллюстрации. Цветами выделены этапы (автоматически распознаваемые ChatGPT), такие как подготовка, земляные работы, опалубка, армирование и т. д.. Продолжительность каждого этапа отображается на графике длиной столбика соответствующего цвета.
График (рис. 3.3-2) не только помогает оценить, сколько времени займет каждый этап, но и показывает, как работа над одним блоком пересекается с работой над другим. Например, когда заканчивается заливка бетона для первого блока, начинается подготовка к установке второго блока. 
Используя одну калькуляцию затрат (рис. 3.3-3), мы можем, благодаря атрибутам объемов из 3D-геометрии, автоматически оценивать стоимость проекта через автоматизированные сметы и рассчитывать временные характеристики групп в виде таблиц или графиков для различных вариантов проекта.

   Рисунок 3.3-3. Автоматический расчет затрат, позволяет прогнозировать 
затраты и время для различных вариантов проекта

Современные ERP-системы используют подобные автоматизированные методы расчета времени, которые существенно сокращают процесс принятия решений. Это позволяет быстро и точно планировать рабочие графики и рассчитывать общее время, необходимое для выполнения проектных задач.
Расширенные атрибутивные слои 6D-8D: от энергоэффективности до обеспечения безопасности
6
D, 7D и 8D - это продвинутые атрибутивные слои информационного моделирования, каждый из которых вносит дополнительные слои атрибутов в комплексную информационную модель проекта, основой которой являются атрибуты 3D-модели с их количеством и объемом.

   Рисунок 3.3-4. Атрибуты 6D, 7D и 8D расширяют рассмотрение различных аспектов проекта, от энергоэффективности до безопасности
● В 6D в дополнение к 3D-геометрическим атрибутам элементов добавляется информация (атрибуты) об экологической устойчивости, которая помогает оценить и спланировать, как проект повлияет на окружающую среду, и учесть такие аспекты, как энергоэффективность и использование экологически чистых материалов.
● 7D дополняет сущности атрибутами управления объектом, чтобы можно было отслеживать, как объект используется и обслуживается после завершения строительства.
● 8D — это дополнительный атрибутивный слой, который описывает безопасное использование и эксплуатацию зданий. На этом этапе планируются и включаются в общую информационную модель меры безопасности.

В структурированной табличной форме слои от 4D до 8D представляют собой дополнительные атрибуты в виде столбцов с заполненными значениями, добавленные к уже заполненным атрибутам 3D-модели, таким как название, категория, тип и объемные характеристики.
Значения в атрибутивных слоях 6D, 7D и 8D содержат дополнительные данные, такие как процент переработки, углеродный след, гарантийный срок, цикл замены, дата установки, протоколы безопасности и т. д.

   Рисунок 3.3-5. 6D-8D добавляют атрибутивные слои к проектным данным, которые уже содержат геометрические и объемные атрибуты из 3D-модели
Для нашего нового окна элемент с идентификатором W-NEW (рис. 3.3-5) имеет следующие 3D-8D атрибуты:
3D-атрибуты - геометрическая информация:
● Имя типа - элемент "Окно"
● "Ширина" 120 см
● Мы также можем добавить точки BoundingBox элемента или его геометрию в отдельный атрибут

Атрибуты 6D - экологическая устойчивость:
● Показатель "перерабатываемости" составляет 90%
● "Углеродный след" - 1622 кг CO2

Атрибуты 7D - данные об управлении объектом:
● "Гарантийный срок" 8 лет
● "Цикл замены" 20 лет
● Требуется ежегодное "Техническое обслуживание"

Атрибуты 8D - обеспечение безопасного использования и эксплуатации зданий:
● Окно "Установлено" компанией "XYZ Windows"
● Соответствует стандарту ISO 45001 "Стандарт безопасности"
Многомерное моделирование объектов проекта на основе атрибутов позволяет получить полное представление об их жизненном цикле, эксплуатационных требованиях и многих других аспектах, необходимых при проектировании, строительстве и эксплуатации проекта.

Оценка CO2 и расчет выбросов углекислого газа в строительных проектах
Н
аряду с темой устойчивости строительных проектов на стадии 6D, в современном строительстве особое внимание уделяется экологической устойчивости проектов. Одним из ключевых аспектов является оценка и минимизация выбросов углекислого газа CO2, которые происходят на этапах жизненного цикла здания.
Оценка и расчет выбросов углерода строительных материалов — это процесс, в ходе которого общие выбросы углерода определяются путем умножения объемного атрибута элементов или группы элементов, используемых в проекте, на подходящий коэффициент выбросов углерода для данной категории.
Включение выбросов углерода в оценку строительных проектов в качестве компонента более широких критериев экологического, социального и управленческого характера (ESG) создает дополнительный слой в комплексной оценке проекта. 
Экологическое, социальное и управленческое управление (ESG – environ-mental, social and governance) — это широкий набор принципов, которые могут использоваться для оценки корпоративного управления, социального и экологического воздействия бизнеса как внутри компании, так и за ее пределами.
ESG, первоначально разработанный в начале 2000-х годов финансовыми фондами для предоставления инвесторам информации о широких критериях экологического, социального и управленческого характера, превратился в ключевой показатель для оценки как компаний, так и проектов, включая строительные. 
Для определения выбросов по типам или категориям элементов нам необходимо собрать коэффициенты выбросов CO2 в результате производства различных строительных материалов, таких как бетон, кирпич, переработанная сталь и алюминий.
В следующей таблице (рис. 3.3-6) использованы данные из баз данных UK ICE 2015 и US EPA 2006 [22] (Европейские нормы выбросов). Для каждого материала в этой таблице приведены два атрибута выбросов (в килограммах CO2 на килограмм продукта) и коэффициенты пересчета объема в вес (в килограммах на кубический метр).

   Рисунок 3.3-6. Количество углерода, выделяемого при производстве различных строительных материалов, согласно базе данных UK ICE и US EPA
Чтобы рассчитать общий объем выбросов CO2 по проекту, необходимо определить объем атрибутов каждой группы объектов. Это можно сделать с помощью инструментов количественного анализа (QTO), получив объемы атрибутов в кубических метрах, как подробно описано в разделе "Количественный анализ QTO: сопоставление и группировка данных". Затем эти объемы умножаются на коэффициенты атрибута "CO2 технологические выбросы" для каждой группы материалов.
Давайте автоматически извлечем таблицу объемов по типам элементов из САПР (BIM) проекта, сгруппировав все данные проекта, как описано в предыдущих главах. Для выполнения этой задачи обратимся к ChatGPT.


❏ Отправьте текстовый запрос в ChatGPT:
Пожалуйста, сгруппируй таблицу DataFrame из САПР (BIM) проекта по параметру столбца "Type Name" и покажите количество элементов в каждой группе, а также суммируйте параметр "Volume" для всех элементов в типе. ⏎
➤ Ответ ChatGPT:

   Рисунок 3.3-7. Сгенерированный код в ChatGPT кластеризовал для нас сущности проекта по типу с суммированным атрибутом „Volume“ 
Чтобы автоматизировать процесс расчета суммарных выбросов для всего проекта, достаточно настроить автоматическое сопоставление в той же таблице или вручную сопоставить типы элементов (рис. 3.3-7) и типы материалов (рис. 3.3-6) из таблицы коэффициентов выбросов.
Готовую таблицу с коэффициентами выбросов и формулами, а также код для получения объемов из форматов САПР (BIM) и автоматизации определения CO2 можно найти на GitHub по запросу "CO2_calculating-the-embodied-carbon" [23].

Таким образом, использование данных QTO и САПР (BIM) для оценки выбросов углекислого газа в строительстве позволяет автоматически (рис. 3.3-8) рассчитывать соответствующие выбросы углекислого газа для различных вариантов дизайна с использованием различных материалов, автоматически выбирая только те варианты, которые отвечают требованиям заказчика по выбросам CO2.

   Рисунок 3.3-8. Интеграция QTO и САПР (BIM) обеспечивает точность и автоматизацию при получении оценок конечных объемов выбросов CO 2
Оценка выбросов CO2 путем умножения коэффициентов на объемы сгруппированных элементов проекта - типичный пример задачи в процессе получения строительной компанией рейтинга ESG (сертификации LEED) для объекта. 
Аналогичным образом, определяя объемы групп элементов, мы можем выполнять расчеты для контроля и логистики материалов, мониторинга и управления качеством, моделирования и анализа энергопотребления и множества других задач для получения нового атрибутивного статуса как отдельных групп элементов, так и всего проекта в целом.

Если количество таких расчетных процессов в компании начинает расти, встает вопрос о необходимости автоматизации таких расчетов и имплементации логики расчётов в систему по управлению данными. 
Средние и крупные компании, работающие в строительной отрасли, передают такую автоматизацию на аутсорсинг компаниям, занимающимся разработкой ERP-систем. Такие компании используют единую комплексную систему, известную как строительная ERP-система (система планирования ресурсов предприятия), для управления множеством различных информационных слоев, включая расчеты материалов и ресурсов.


ГЛАВА 3.4 
СТРОИТЕЛЬНАЯ ERP СИСТЕМА
REV Строительные ERP-системы на примере расчетов и смет
E
RP системы объединяют различные атрибутивные (информационные) слои и потоки данных в единое целое, позволяя руководителям проектов синхронизировано управлять ресурсами, финансами, логистикой и другими аспектами проекта. Строительная ERP-система выступает в роли "мозга" строительных проектов, упрощая сложные процессы за счет автоматизации, обеспечивая прозрачность и контроль на протяжении всего строительного процесса.
Строительные ERP-системы (Enterprise Resource Planning) — это комплексные программные решения, предназначенные для управления и оптимизации различных аспектов строительного процесса. В основе строительных ERP-систем лежат модули для управления расчетами затрат и составления графиков работ, что делает их бесценным инструментом для эффективного планирования проектов и управления строительством.
ERP-модули позволяют пользователям вводить, обрабатывать и анализировать в структурированном виде данные, связанные с материальными затратами, трудозатратами, использованием оборудования, логистикой и другими видами строительной деятельности. На основе этой информации специалисты ERP-систем могут автоматически составлять подробные сметы и графики работ, предоставляя точные и актуальные данные для принятия решений.
Сердцем ERP-системы является модуль автоматизации процессов BlackBox/WhiteBox (чёрный ящик / белый ящик), который представляет собой главный нервный центр, отвечающий за создание и поддержание логики процессов - от оценки стоимости и времени до логистики, закупок и других расчетов. Модуль BlackBox/WhiteBox — это процесс автоматизации в ERP-системе, отвечающий за обработку и управление бизнес-логикой, которая может быть полностью скрыта (Black Box) или полностью открыта (White Box) для пользователей системы. 



BlackBox/WhiteBox позволяет специалистам, использующим ERP-систему, гибко управлять различными аспектами бизнеса, которые уже были предварительно сконфигурированы другими пользователями:
● BlackBox "Черный ящик" описывает систему автоматизации, процессы которой скрыты от пользователя, т. е. пользователи не видят внутреннюю работу системы и взаимодействуют только с ее интерфейсом. Они вводят данные и получают результаты, не зная, какие операции были выполнены внутри системы (например, какие атрибуты, факторы и коэффициенты были перемножены или просуммированы).
● WhiteBox "Белый ящик", напротив, относится к системам автоматизации, которые прозрачны для пользователя и позволяют понять и, при необходимости, изменить логику работы. Это может включать в себя настройку или модификацию бизнес-процессов, алгоритмов, расчетов и т. д.

Например, логика одного из процессов описывает, какие атрибуты сущностей с каким другим атрибутом (или просто числом) умножаются или суммируются и в какой новый атрибут записывается полученное значение. Администратор или опытный пользователь настраивает процесс (так же, как мы делали это выше с ChatGPT), а остальным пользователям в новых проектах остается только загрузить данные и правильно нажать на кнопки. В таком процессе логика может быть закрыта от пользователя в "Черном ящике" или оставаться в полуоткрытом варианте "Белого ящика". 
Сценарий 1: BlackBox (скрытая автоматизация)Задача: Руководителю проекта необходимо рассчитать стоимость строительства объекта, введя базовые данные о материалах, рабочей силе и логистике.
Как это работает:
Пользователь вводит ключевые параметры (площадь, тип материалов, местоположение).
ERP-система автоматически анализирует данные, используя предустановленные коэффициенты и формулы.
Итоговая стоимость проекта отображается в интерфейсе, но пользователю не видны алгоритмы вычислений (например, применяемые наценки, поправочные коэффициенты и расчеты транспортных затрат).
Преимущества:
Упрощение работы для рядовых пользователей.
Исключение ошибок при ручных расчетах.
Единообразие расчетов по проектам.
Сценарий 2: WhiteBox (прозрачная логика)Задача: Инженер-сметчик хочет внести изменения в расчетную модель, добавив новый коэффициент удорожания для работы в зимних условиях.
Как это работает:
Администратор ERP-системы открывает модуль WhiteBox.
Настраивает новую формулу, учитывающую сезонный коэффициент.
Применяет изменения, после чего новые расчеты учитывают влияние зимних условий.
Преимущества:
Гибкость в настройке расчетов.
Возможность адаптации системы под различные условия.
Прозрачность и контроль формул.

В предыдущих главах мы рассмотрели наиболее важные модули вычислений и расчетов, представленные в запросах ChatGPT. В ERP-системе такие запросы заключены в пользовательский интерфейс, доступ к которому осуществляется щелчками мыши.
В следующем примере (рис. 3.4-1) в ERP-системе BlackBox/WhiteBox администратор описал правила сопоставления атрибутов сущностей из смет, чтобы пользователь, вручную добавив атрибут количества или объема в этот модуль, автоматически получал готовые сметы и готовые графики работ. Все те же процессы расчетов и создания смет, которые мы обсуждали в предыдущих главах, переводятся в полуавтоматический конвейер с помощью ERP-системы.

   Рис. 3.4-1. Архитектура строительной ERP-системы, для получения смет и графиков работ при ручном заполнении атрибутов объема 
Подключение этого полу-автоматизированного процесса к объемным атрибутам из САПР (BIM) моделей превращает поток данных в синхронизированный механизм, способный автономно и мгновенно обновлять стоимость отдельных групп элементов или всего проекта в ответ на любые изменения в проекте на этапе проектирования.
Чтобы создать автоматизированный поток данных (рис. 3.4-2) между системами САПР (BIM) и ERP, необходимо структурированно определить основные процессы и требования к данным из баз данных САПР (BIM) моделей, о чем мы уже говорили в главе выше "Требования и обеспечение качества данных". Этот процесс в ERP делится на следующие этапы:
● Создание правил проверки (1), которые играют важную роль в обеспечении точности данных, поступающих в сердце ERP-системы. Правила проверки служат в качестве фильтров, которые проверяют сущности и их атрибуты. Подробнее о проверке и валидации данных мы говорили в главе "Создание требований и проверка качества данных".
● Затем происходит процесс верификации (2), который подтверждает, что все элементы-сущности проекта с их атрибутами и значениями были созданы правильно и готовы к следующим этапам обработки.
● Если возникают проблемы с неполными атрибутивными данными, создается отчет (3), и проект вместе с инструкциями по исправлению отправляется на доработку до готовности к следующей итерации.
● После того как данные проекта были подтверждены и проверены, они используются (4) для создания таблиц Quantity Take-Off (QTO), которые создают атрибуты количества для групп сущностей, материалов и ресурсов.
● Сгруппированные данные по правилам сопоставления или QTO автоматически интегрируются с расчетами (например, затрат и времени) (5).
● На последнем этапе ERP-система, перемножая атрибуты объема из QTO с атрибутами таблиц процессов (например, сметных статей) в BlackBox/WhiteBox, автоматически генерирует результаты расчетов (6) (например, сметы затрат и продолжительности) для каждой группы сущностей и для проекта в целом. 

   
   Рисунок 3.4-2. Архитектура строительной ERP-системы с САПР (BIM), от создания правил валидации (1) до расчета стоимости работ (5-6)
В ERP-системе процессы интегрируются с помощью программного обеспечения, которое включает в себя пользовательский интерфейс. За этим интерфейсом находится внутренняя часть, где структурированные таблицы обрабатывают данные, выполняя различные операции. В результате пользователь, благодаря заранее заданной и настроенной логике автоматизации в модулях BlackBox/WhiteBox, получает автоматически подготовленные документы, отвечающие его потребностям и требованиям. 
Аналогичным образом, процессы в ERP-системах, от начала до окончательного расчета (этапы 1-6 Рисунок 3.4-3), представляют собой цепь взаимосвязанных шагов, которые в конечном итоге обеспечивают прозрачность, эффективность и точность планирования и управления строительными проектами.
   

    Рисунок 3.4-3. ERP-система помогает менеджерам и пользователям перемещаться между таблицами специалистов, чтобы 
генерировать новые данные

Мультимодульность строительных ERP-систем
С
овременные строительные ERP-системы включают в себя не только модули расчета стоимости и сроков, но и, как правило, функции документооборота, отслеживания хода реализации проекта, управления контрактами, цепочками поставок и логистикой, а также интеграции с другими бизнес-системами и платформами. Это обеспечивает централизованное и последовательное управление всеми аспектами строительного проекта.
Интегрированные аналитические инструменты ERP позволяют пользователям автоматизировать создание информационных панелей для мониторинга ключевых показателей (KPI - key performance indicators) проекта. 
В будущем ERP-аналитика будет использоваться в сочетании с машинным обучением для повышения точности и оптимизации процесса расчета будущих атрибутов проекта. Данные и атрибуты, проанализированные и собранные из ERP-систем в Big Data, в будущем станут основой для создания прогнозных моделей, которые смогут точно предвидеть потенциальные задержки, риски превышения ресурсов и возможные изменения стоимости материалов.
Прогностическая мощь систем управления данными позволит строительным компаниям в будущем заранее принимать взвешенные решения, минимизировать риски и оптимизировать процессы, используя модели на основе искусственного интеллекта в качестве одного из независимых дополнительных мнений. 
Более подробно тема Больших Данных и аналитики будет рассмотрена в главе "Будущее: предсказания, прогнозы и машинное обучение".

   Рисунок 3.4-4. ERP-система интегрирована с аналитическими инструментами автоматизирует процесс принятия решений в компании
Спекуляции, прибыль, закрытость и отсутствие 
прозрачности ERP 
О
бсуждение ERP-систем в строительной отрасли не может обойти стороной использование ERP в спекуляциях. Непрозрачность данных, описание процессов через BlackBox, закрытость систем и отсутствие точных данных об объемах работ, выполненных клиентами и заказчиками, открывают возможности для спекуляций и сокрытия информации в лабиринтах ERP. 
Несмотря на кажущуюся простоту процессов внутри ERP-систем, в отличие от других отраслей, ERP системы в строительной отрасли зачастую являются закрытыми, а вместе с привязкой данных из закрытых САПР (BIM) систем такой продукт выглядит крайне неповоротливым и не гибким, в силу закрытости баз данных и функционала самой системы, который заранее преднастраивается разработчиком ERP-системы. 

С 2020-х годов инициативу в разработке подобных решений взяли на себя производители САПР (BIM) систем, в базах данных которых хранится важнейшая информация, используемая строительной ERP системой – автоматически генерируемы атрибуты количества и объемов сущностей проекта. И по аналогии с САПР (BIM) системой, вместо доступа к базам данных ERP системы специалисты не компании разработчика получают ограниченный функционал пользовательского интерфейса (подготовленный BlackBox) или ограниченный функционал через API-запросы.
Ограниченный доступ к функциям автоматизации и сложность полной автоматизации создания смет и графиков, а также повсеместная бюрократия в ERP-системах подталкивают строительные компании искать пути повышения эффективности и прибыли путем манипулирования коэффициентами и факторами, определяющими стоимость. 
В строительстве прибыль — это разница между общей стоимостью завершенного проекта (выручкой) и переменными затратами, которые включают в себя проектирование, материалы, рабочую силу и другие прямые расходы, связанные со строительством. А затраты напрямую зависят от скорости и точности расчетов, выполняемых внутри компании.

Ситуация усугубляется тем, что процесс расчета стоимости непрозрачен не только для клиентов, но и для сотрудников строительной компании, не входящих в состав сметных отделов. 
Такая непрозрачность способствует формированию в компании привилегированной группы, обладающей исключительными правами на изменение различных атрибутов объектов в ERP-системе, что прямо и косвенно влияет на весь строительный проект.
Сметчики часто выступают в роли "финансовых жонглеров", пытаясь увеличить прибыль за счет различных коэффициентов на этапе расчетов, в то же время стараясь сохранить стоимость работ или проекта привлекательной для клиентов и не подорвать репутацию компании.
В результате основной схемой повышения эффективности и рентабельности компаний, работающих в строительной отрасли, становится не автоматизация и ускорение процессов принятия решений, а спекуляция на ценах на материалы и работы. Завышение стоимости работ и материалов осуществляется с помощью "серого" учета в закрытых ERP-системах (5D, Excel, ERP, EPM, сметные программы и др.) путем завышения процентов над среднерыночными ценами на материалы или объемами работ.
В этом случае клиент получает или завышенные объемы или стоимости, которые обычно скрывается в манипуляциях с количествами и объемами работ и материалов на этапе калькуляций. А строительным субподрядчикам, с другой стороны, приходится бороться с заниженной генподрядчиком "стоимостью работ", что вынуждает конечных подрядчиков в целях экономии закупать некачественные строительные материалы. 
Спекулятивный процесс поиска прибыли из воздуха в конечном итоге вредит как клиенту, получающим недостоверные данные, так и исполнителям вынужденные искать всё новые и новые модели спекуляций.
Отделы подготовки смет, расчетов и бюджетирования, от которых зависит получение прибыли в строительной компании, теперь строго защищены от доступа неавторизованных специалистов даже внутри самой компании. А из-за закрытого характера данных, баз данных и систем, без возможности четко выразить эффективность процессов без спекуляций и затуманивания внутренних данных, компаниям становится практически невозможно поддерживать свою конкурентоспособность

   Рисунок 3.4-5. Коэффициенты спекуляции на уровне расчетов — это искусство жонглирования между качеством работы и репутацией компании
.Для того чтобы понять причины возникновения спекуляций, низкой эффективности и низкого уровня автоматизации компаний строительного сектора, необходимо рассмотреть подробные основные причины проблем, в основных аспектах работы на уровне процессов и данных.
ERP или всё же DWH и дата аналитика
В зрелой ИТ-среде замена унаследованной системы похожа на замену несущей колонны в уже построенном здании. Убрать старую колонну и поставить новую — это только половина задачи. Главное — сделать это так, чтобы здание не обрушилось, все перекрытия остались на месте, а коммуникации продолжали работать. Именно в этом и заключается сложность, ведь любое неверное движение может привести к катастрофическим последствиям.

В целом можно поставить под вопрос использования ERP тем более закрытого типа в процессах своих компаниях. Врядли кто то уже в ближайщем будущем будет готов хранить все свои процессы и данные в определённых проприентарных и закрытых системах.
Если вы используете сложную СУБД или ERP-систему с миллионами строк кода, каждая мелкая правка или переход на новую платформу становятся проблемой. Чем больше кода, тем больше неэффективности, а новые проекты только усугубляют ситуацию.
При этом многие внедренцы гордятся объемом написанного кода, хотя это скорее показатель сложности, а не эффективности. Код — это бремя. Старайтесь минимизировать его.
Новая информация прививается к исходным структурам. Часто это создает дополнительную сложность. Опытные разработчики понимают, что они это делают, и периодически откладывают задачи разработки для "рефакторинга" и реструктуризации своего решения, основываясь на новой информации, которая изменила бы способ организации вещей, если бы она пришла в другой последовательности. 
Независимо от того, решает ли человек периодически рефакторинг своего решения или нет, решение постепенно становится сложнее. Поскольку это происходит постепенно, у архитектора решения есть время, чтобы осознать и закрепить сложность в своем сознании.
У всех остальных не было столько же времени, чтобы усвоить эту сложность. Это создает монополию на понимание в голове создателя или, зачастую, того, кто посвятил решению много времени. Такие эксперты, хотя и полезны в краткосрочной перспективе, если вы пытаетесь взаимодействовать с решением, на самом деле являются частью проблемы. 


ГЛАВА 3.5 
ПРОБЛЕМЫ РАБОТЫ С ДАННЫМИ В СТРОИТЕЛЬНОЙ ОТРАСЛИ

Проблема закрытых и проприетарных данных
П
роблема закрытости логики и бизнес процессов компаний в строительной отрасли неразрывно связана с проблемой закрытых и проприетарных данных в ключевых системах компаний. 
В то время как большинство систем управления строительными данными работают на основе открытых стандартов, базы данных инструментов САПР (BIM) и связанные с ними связанные с ними ERP от САПР (BIM) вендоров по-прежнему остаются единственными изолированными островками проприетарных систем в ландшафте строительных данных.


   Рисунок 3.5-1. Закрытый и проприетарный характер данных САПР (BIM) создает барьеры для интеграции и доступа к данным
Данные о проекте, хранящиеся в закрытых базах данных САПР (BIM), в частности атрибуты объемов объекта и их геометрическое представление, накапливаются в течение недель, месяцев и даже лет. 
В конечном итоге эти данные преобразуются в сложные параметрические или закрытые форматы САПР (BIM). Более подробную информацию о концепции BOM-BIM и преобразовании данных САПР (BIM) в открытые и структурированные форматы можно найти в главах "Концепция BOM-BIM" и "Преобразование данных САПР (BIM) в структурированную форму".
ИТ-специалисты и ИТ-разработчики компаний, создающих приложения для доступа к данным, их обработки и автоматизации, сегодня сталкиваются с многочисленными зависимостями от поставщиков программного обеспечения (рис. 3.5-2). Эти зависимости в виде дополнительных уровней доступа требуют создания решений со специализированными API-соединениями и специальными инструментами и программным обеспечением. 
Большое количество зависимостей от закрытых решений приводит к тому, что вся архитектура кода и логика бизнес-процессов в компании превращается в спагетти из инструментов, зависящих от политики поставщика программного обеспечения по предоставлению качественного доступа к данным.
Такая зависимость создает ряд проблем, от ограниченной гибкости в разработке до потенциальных рисков для бизнес-процессов, если поставщик САПР (BIM) изменит условия доступа или лицензионную политику.

   Рисунок 3.5-2. Большое количество зависимостей создает препятствия для интеграции данных в экосистеме строительных компаний

В современных условиях ИТ-разработчикам и менеджерам по управлению данными приходится постоянно адаптироваться к меняющимся API, иногда даже перестраивать значительные части своих систем, чтобы соответствовать новым требованиям разработчиков критически важных, но закрытых инструментов. Это не только увеличивает нагрузку на разработчиков, но и увеличивает время и ресурсы, необходимые для внедрения или обновления систем.
В итоге, несмотря на потенциал автоматизации и оптимизации, который предоставляют современные технологии, ограничения и количество зависимостей, накладываемые закрытыми поставщиками решений, сильно ограничивают возможности компаний по использованию современных технологий в полной мере. 
Отсутствие доверия и прозрачности данных и систем приводит к риску человеческих ошибок и созданию ненужной многоуровневой бюрократии в основных бизнес-процессах строительных компаний.
Монополия или жесткий контроль над важнейшими форматами и протоколами данных характерны не только для строительной отрасли (рис. 3.5-3). Многие отрасли сталкивались, а некоторые и до сих пор сталкиваются с проблемами, связанными с закрытыми стандартами и форматами [10]. Устранение барьеров, связанных с ограниченным доступом к данным в других секторах экономики, привело к росту инноваций, конкуренции и производительности [28].

   Рисунок 3.5-3. Монопольное владение над ключевыми форматами и протоколами данных не является исключительной проблемой 
строительной отрасли
Несмотря на барьеры и маркетинговые стратегии крупных корпораций, строительная отрасль признает необходимость использования открытых данных для обеспечения эффективного и непрерывного обмена информацией между различными системами. 
Крупные игроки других отраслей экономики, а также теперь и строительной отрасли, и в особенности финансовые организации, контролирующие финансирование строительных проектов, все чаще требуют от разработчиков не только создавать решения с открытыми данными, но и предоставлять доступ к исходному коду решений переводя все решения компании на открытый исходный код. 
Использование решений с открытым исходным кодом обеспечивает заказчика уверенностью в том, что даже если внешние разработчики прекратят сотрудничество или покинут проект, это не повлияет на возможность дальнейшего развития инструментов и систем.


   Рисунок 3.5-4. В будущем компании строительной отрасли будут вынуждены сосредоточить свой бизнес на работе с открытыми данными
 и открытыми инструментами
Если компания не может полностью опираться на открытые данные и программное обеспечение с открытым исходным кодом, то возможным решением для работы с проприетарными системами и данными является использование методов реверс-инжиниринга. Эти легальные методы позволяют преобразовывать закрытые системы в более доступные и управляемые форматы, как подробно описано в разделе «Перевод данных САПР (BIM) в структурированную форму». 
Решения с открытым исходным кодом, работающие с открытыми данными, заставляют компании сосредоточиться на бизнес-процессах и их эффективности, а не на программном обеспечении и постоянных хлопотах по обновлению API-команд и поиску совместимости между большим количеством неоднородных данных из закрытых решений.
REV Существует ли BIM, openBIM, BIM 3 level, noBIM на самом деле или это маркетинговый трюк? 
Когда мы говорим о BIM, в голове невольно всплывают образы трёхмерных моделей, инструментов по обнаружению коллизий и просмоторщики моделей в ACC. Но если копнуть глубже, возникает вопрос: а что такое BIM на самом деле? Это набор данных, параметров и процессов или просто маркетинговый слоган? Чтобы ответить на этот вопрос, нужно выйти за рамки аббревиатур и концептов, которые продвигают CAD-вендоры, и взглянуть на суть работы с проектной информацией — данные и процессы. 

Любой бизнес процесс в строительстве не начинается с работы в CAD- (или BIM-) инструментах. В любом бизнес процессе мы сначала формируем параметры задачи и определяем требования к будущим элементам: задаём перечень сущностей, их начальные характеристики и граничные значения. Обычно это делается в виде нескольких колонок таблицы, базы данных или списков пар «ключ–значение» (1-2). 
И только на основании этих первоначальных параметров с помощью API автоматически или вручную создаются объекты в CAD/BIM-программах (3-4), после чего их вновь проверяют на соответствие исходным требованиям (5-6). Этот цикл — определение, создание, проверка и корректировка (2-6) — повторяется до тех пор, пока качество данных не достигнет нужного уровня для целевой системы - документов, таблиц или дашбордов (7).





Рис. 37. Цикл автоматизации процессов для бизнес процессов в строительной отрасли
Если рассматривать CAD (BIM) как способ передачи параметров, представляющих собой наборы ключей и значений, изначально сформированных вне CAD-среды (1-2), то становится очевидным, что мы работаем фактически с базой данных параметров (2-3, 5-6), которая дополняется различными инструментами и в какой то момент переходит из простых требований в набор элементов с параметрами, которые в CAD программе обрабатываются обычно в виде закрытой базы данных. Подходя к BIM сквозь призму такого определения, мы обнаруживаем принципы, схожие с теми, что применяются в аналитике данных, а также в ETL-процессах (извлечение, трансформация и загрузка данных). Возникает вопрос: в чём же уникальность BIM, если в других отраслях экономики не существует подобных подходов?
Последние 20 лет поставщики CAD позиционировали BIM как что-то большее, чем просто базу данных. Маркетингово BIM продаётся как параметрически инструмент, способный автоматизировать процессы проектирования, моделирования и управления жизненным циклом объектов строительства. Однако в реальности BIM стал больше инструментом удержания пользователей на платформе вендоров, нежели удобным методом управления данными и процессами.

Рис. 38. В строительстве современные форматы требуют сложных геометрических ядер, ежегодно обновляемого API и специальных лицензий на CAD-BIM-программы
Вендоры фактически изолировали качественные CAD (BIM) данные внутри своих платформ, скрывая их за проприетарными API, SDK и геометрическими ядрами. Это лишило пользователей возможности самостоятельно извлекать, анализировать и передавать данные в обход этих экосистем. 
Сегодня большинство процессов анализа данных в строительной отрасли аналогичны процессам из других отраслей экономики. Это типичные ETL-циклы (Extract, Transform, Load) и аналитика данных. В банковской сфере, например, данные извлекаются, преобразуются в понятные форматы и загружаются в BI-платформы для визуализации и анализа. В строительстве это были и будут те же самые действия — извлечение данных из баз данных CAD (BIM) программ (Extract), нормализация и структуирование, последующий анализ, трансформация (Transform) и выгрузка в другие системы и базы данных (Load).
Имея полный доступ к базе данных CAD и используя инструменты обратного инжиниринга, мы можем получить плоский набор сущностей с атрибутами и экспортировать их в любой удобный открытый формат, содержащий как геометрию, так и атрибуты проектных элементов, подобно тому как это реализовано в проекте SCOPE. Когда BIM-данные трансформируются в удобные для анализа форматы структурированные представления таблиц, баз данных, DWH, DL — разработчики перестают зависеть от специфических схем данных и закрытых экосистем.

Рис. 39. Сравнение процессов обработки данных: ручной подход CAD (BIM) без обработки и автоматизированный рабочий процесс с предобработкой данных
Так выглядит будущее строительной отрасли — сбор данных, их анализ, проверка и автоматизация процессов при помощи инструментов аналитики данных. 
Информация — это нефть 21 века, а аналитика — это двигатель внутреннего сгорания.
Возможно BIM (CAD) - это не конечная цель, а лишь этап эволюции. Когда специалисты в строительстве осознают, что они могут работать непосредственно с данными, минуя традиционные CAD-инструменты, «BIM» как термин растворится в потоках информации. Мы начнём говорить о гранулированных или структуированных данных строительного проекта, но это уже не будет тот BIM, который мы знаем сегодня.
17. Что будет дальше? Простые форматы и удобные инструменты
Ключевым направлением развития может стать переход к открытым и независимым решениям, свободным от проприетарных SDK и геометрических движков. Вместо попыток "допилить" формат IFC, который остается сложным для работы без специальных знаниях об особенностях формата и специализированного геометрического ядра, индустрии следует обратить внимание на уже существующие универсальные форматы, доказавшие свою эффективность: MESH, OBJ, gLTF, DAE, FBX или USD для геометрии, а также CSV, JSON, XML, XLSX, SQL, YAML для метаданных и параметров.
Будущее строительной отрасли связано с созданием простых и доступных инструментов, аналогичных тем, что появились в сфере 2D-графики в конце 2010х после двух десятилетий доминирования Photoshop. Появление плоских форматов JPEG, PNG и GIF, свободных от избыточной логики внутренних движков 2D-редакторов, привело к развитию тысяч совместимых решений для обработки изображений.
Аналогичным образом, стандартизация и упрощение 3D-форматов и метаинформации будут стимулировать появление множества удобных и независимых инструментов для работы со строительными проектами. Отказ от сложной логики "вендорских ядер" и переход к универсальным, открытым форматам создаст условия для более гибкой и эффективной работы, а также откроет доступ к данным для всех участников процесса строительства.

Рис. 40. Уровнь зрелости CAD/BIM: от неструктурированных данных до полностью структурированных данных и хранилищ.
В Open Source сообществе есть перспективные проекты, которые могут послужить примерами развития лёгких геометрических решателей: SolveSpace с потенциалом работы в браузере, Web-CAD.org на JavaScript, различне бесплатные CSG-редакторы. Особого внимания заслуживает платформа Unity, предоставляющая готовую базу для создания сложных инструментов с возможностью настройки рендеринга и добавления необходимого функционала. В моём примере 2021 года был переработан движок браузерной CAD программы Unity NoteCAD с собственным геометрическим решателем для максимального соответствия функциональности бесплатного онлайн SketchUp. Получился легкий бесплатный продукт с открытым исходным в кодом, с быстрым запуском на любом сервере.

Рис. 41. BimCADOnline пример open source онлайн решения c собственным геометрическим решателем
Главный принцип развития отрасли должен заключаться не в создании новых форматов, а в эффективном использовании и доработке уже существующих решений. Важно опираться на интернациональные сообщества, такие как OsArch и FreeCAD, а также поддерживать команды, занимающиеся разработкой открытых геометрических ядер.
Для тех, кому необходима работа с BREP-геометрией, ключевую роль могут сыграть геометрические ядра Open Source, такие как OCC и OGG . А для задач, где достаточно MESH-геометрии, перспективным решением станет использование CGAL, OpenMesh и MeshLib. Для получения и записи данных в различные CAD и MCAD форматы используйте SDK реверс-инжиниринга от таких компаний, как OpenDesignAliance, CADExchanger или HOOPS. Эти SDK были созданы с целью предоставить разработчикам равный доступ к данным и обеспечить всем желающим возможность разрабатывать решения в области CAD и MCAD на уровне ведущих CAD (BIM) разработчиков.

Рис. 42. OpenDWG. Альянс поставил своей целью уравнивать шансы всех производителей CAD-решений, вне зависимости от того, в каких отношениях с компанией Autodesk находятся эти разработчики
В сочетании с LLM-моделями такие инструменты значительно повысят эффективность процессов создания, преобразования и экспорта данных в целевые системы.
18. Появляение LLM и ChatGPT в процессах обработки проектных данных
В дополнение к развитию открытых форматов и универсальных инструментов, революционные изменения в отрасль обработки данных вносят Large Language Models (LLM), такие как LLaMA, ChatGPT, Gemini и Claude. Эти технологии кардинально меняют подход к работе с проектными данными и аналитикой этих данных, делая процесс обработки и автоматизации доступными для всех участников строительного процесса.
Если раньше доступ к информации осуществлялся исключительно через сложные API и SDK-интерфейсы, требующие специальных навыков программирования, то теперь появилась возможность взаимодействовать с данными на естественном языке. 
В течение нескольких лет неизбежно произойдёт демократизация доступа к данным. Простые инженеры, менеджеры и проектировщики смогут получать необходимую информацию из проектных данных в структуированных форматах, просто формулируя запросы на обычном языке. Например, достаточно будет спросить в чате: «Покажи в виде таблицы с группировкой по типам все стены с объемом более 10 кубических метров», — и LLM самостоятельно преобразует этот запрос в SQL- или Pandas-запрос, преобразовав структуированные данные проекта через группировку в нужный формат таблицы, графика или готового документа. 
С каждым днем все чаще в строительной отрасли можно будет услышать о гранулированных структурированных данных, DataFrame и колончатах базах данных. Унифицированные двухмерные DataFrame, сформированные из различных баз данных и форматов CAD (BIM), станут идеальным топливом для современных аналитических инструментов. А инструменты вроде Pandas и аналогичные библиотеки для работы с двумерными таблицами и столбчатыми базами данных идеально подходят для использования в LLM благодаря мощным возможностям обработки данных и эффективному индексированию. Такие данные не требуют понимания схем форматов и становятся идеальным источником для RAG, LLM и ChatGPT.
Существенно упростится сам процесс автоматизации – вместо изучения API закрытых продуктов и написания сложных скриптов на Python, C# или JavaScript для анализа или трансформации параметров, теперь достаточно будет сформулировать задачу в виде набора отдельных текстовых команд, которые будут складываться в нужный Pipeline или Workflow процесса для нужного языка программирования.

Рис. 43. Переход от программирования к созданию запросов в LLM для создания Pipeline процесса
Больше не будет необходимости ждать выпуска новых продуктов, форматов, плагинов или обновлений от вендорвов CAD (BIM) инструментов. Инженеры и строители получат возможность независимо работать с данными, используя простые, бесплатные и понятные инструменты, в работе с которыми помогут LLM чаты.
Современные инструменты дата аналитики, в сочетании с открытыми форматами данных создадут новую парадигму работы в строительной отрасли, где главным станет не владение определенным программным обеспечением и понимание его API, а умение эффективно формулировать-параметризировать задачи и быстро анализировать полученные данные. 
Вместо заключения
Ситуация с интероперабельностью и кроссплатформенностью в строительной отрасли наглядно демонстрирует глубинные проблемы, связанные с передачей и использованием данных между различными CAD (BIM) системами. Ярким примером этого является Autodesk, который активно продвигает открытый формат IFC, но сам не способен обеспечить его корректный экспорт из собственных продуктов и вынужден обращаться к SDK реверс-инжиниринга от OpenDesignAlliance — организации, которая изначально создавалась в 1998 году для противодействия монополии Autodesk над данными. Парадоксально, но эта ситуация вынуждает всех игроков отрасли использовать аналогичные SDK для извлечения и адаптации данных конкурентов CAD решения под свои платформы, что фактически подрывает идею кроссплатформености, ради которой создавался формат интероперабельности IFC.
Формат IFC, призванный стать универсальным мостом между различными CAD (BIM) системами, в реальности выполняет роль индикатора проблем совместимости между геометрическими ядрами различных CAD-платформ, подобно STEP формату, из которого он изначально появился. Несмотря на активное продвижение формата организацией buildingSMART, основные усилия направлены на стандартизацию геометрии (что требует единого геометрического ядра, которого до сих пор не существует), и на унификацию семантики и онтологий для строительной отрасли. Однако эти усилия повторяют нереализованные амбиции концепции семантического интернета, где ожидания значительно превзошли реальность.

Рис. 44. Геометрия и информация в строительных процессах: от сложных CAD и BIM систем до упрощенных данных для аналитики
Отраслевая специфика усугубляет эту проблему. Строительная отрасль, традиционно отстающая на 10-20 лет в освоении новых технологий от других отраслей экономики, рискует повторить этот путь. Если в сфере IT неудачи семантического веба были компенсированы появлением новых технологий (больших данных, IoT, машинного обучения, AR/VR), то строительная отрасль таких поводов не имеет.
Однако есть и единичные примеры альтернативных подходов. Компания Züblin со своим проектом SCOPE демонстрирует, как можно выйти за рамки классической логики CAD (BIM) систем. Вместо того чтобы пытаться подчинить IFC или полагаться на проприентарные геометрические ядра, они используют API и SDK реверсинжениринга для извлечения данных из различных CAD-программ, преобразуют их в нейтральные форматы, такие как OBJ или CPIXML на базе open source ядра OpenCascade, и далее применяют их в сотнях бизнес-процессов строительных и проектных компаний. Тем не менее, несмотря на прогрессивность идеи, подобные проекты остаются частью замкнутых экосистем, которые воспроизводят логику моновендорных решений. В итоге строительная индустрия снова оказывается в ловушке, где межплатформенные стандарты, подобные IFC, не справляются со своей миссией, а локальные инициативы лишь частично смягчают эту проблему.
И с большой степенью вероятности, CAD-вендорам вновь удастся сместить дискуссию о доступе к открытым данным в сторону "новых" концепций, форматов и альянсов, которые, подобно BIM и openBIM, будут служить прежде всего инструментом удержания пользователей в проприетарных экосистемах, что в очередной раз затормозит рост производительности, и без того непроизводительной отрасли, поскольку ресурсы будут направлены не на упрощение и оптимизацию процессов, а на поддержание контроля над экосистемами и привлечение пользователей к новому концепту.

Рис. 45. За послдение 30 лет CAD (BIM) технологии так и не смогли повысить производительность в строительной отрасли
Цель этого анализа не в критике существующих подходов, а в инициировании дискуссии по главному вопросу — как повысить производительность в строительной отрасли и возможно ли это в принципе. С глубоким уважением отношусь к разработчикам CAD (BIM) решений и компании Autodesk, а также к участникам и членам buildingSMART. Однако, возможно, пришло время отказаться от ожидания новых концепций от ПО вендоров и сосредоточиться на самостоятельном развитии. Освободившись от проблем с доступом к данным, отрасль сможет перейти к современным и удобным инструментам для работы и анализа данных. Это позволит двигаться в направлении, которое ещё в конце 1980-х указал Самуэль Гайзберг.
Традиционные CAD / CAM программное обеспечение нереально ограничивает внесение недорогих изменений в самый начальный этап процесса проектировани. Цель состоит в том, чтобы создать систему, которая была бы достаточно гибкой, чтобы побудить инженера легко рассматривать различные конструкции. А затраты на внесение изменений в проект должны быть как можно ближе к нулю. 
Это начало дискуссии о трансформации отрасли. Только решив вопросы доступа к данным, мы сможем двигаться дальше к изучению бизнес процессов и их автоматизации.

Открытые данные и форматы неизбежно станут стандартом в строительной отрасли — вопрос лишь времени. Этот переход будет ускорен, если мы все будем распространять информацию об открытых форматах, инструментах доступа к базам данных и SDK для реверс-инжиниринга. Помочь в этом процессе может каждый из вас. Если вы считаете полезной информацию, которую прочитали, пожалуйста, поделитесь ею с коллегами.
REV Миф о интероперабельности CAD
Сейчас в строительной отрасли наблюдается интересный феномен. Множество команд разработчиков направляют свои усилия на создание "мостов" между закрытыми САПР-системами (closedBIM) и открытыми BIM-решениями (openBIM), с верой в то, что это универсальный ключ к решению проблем с обменом данными в строительстве. 
Но достаточно вспомнить события двадцатилетней давности, когда разработчики, утомленные доминированием Adobe на рынке графических редакторов, пытались наладить бесшовную интеграцию между Photoshop и GIMP. Этот исторический пример может многое рассказать о подводных камнях подобного подхода.

Тогда, как и сейчас, усилия были направлены на создание связей между закрытыми и открытыми системами, стремясь обеспечить взаимодействие между проприетарными и открытыми программными решениями. Однако пользователи в действительности искали простые решения — плоские, открытые данные без излишней сложности слоёв и параметров программ. Им нужны были только необходимые плоские данные, готовые к использованию без дополнительных настроек.
Где любит живопись может проследить как менялся подход в написании картин. Сначала это были плохие копии, потом стали реалистичными портретами и как только был достигнут пик в реализме всё заменилось резко фотографией, которая сегодня уступает место LLM чатам которые строят изображения по тексту.


В результате в индустрии изображений почти никто не использует закрытые форматы вроде PSD или открытые XCF для приложений, социальных сетей вроде Facebook и Instagram или в качестве контента на сайтах. Вместо этого в большинстве случаев применяются плоские и открытые форматы JPEG, PNG и GIF, которые обеспечивают простоту использования и широкую совместимость.

Сегодня в строительной отрасли форматы USD,OBJ, glTF, DAE играют ту же роль при создании 3D-моделей, что и плоские изображения в сфере графики. Эти форматы упрощают и ускоряют работу, беря верх над вопросами совместимости. Популярные упрощённые форматы NWC, SVF и CP2 выполняют схожие функции, но они закрыты, в отличие от вышеупомянутых открытых стандартов.

Вендоры следуют историческим тенденциям других отраслей: большинству пользователей не нужны закрытые форматы вроде PSD или сложные файлы GIMP с логикой слоёв. Им требуются простые изображения объектов, которые можно использовать в строительном Instagram (CAFM), Facebook (ERP) и в тысячах других процессах, наполненных эксель таблицами и PDF документами. Аналогично в строительстве: закрытая логика Revit или сложные параметрические файлы IFC часто оказываются избыточными. Пользователям ищут упрощённые и плоские форматы, такие как USD, CPIXML, DXF, glTF, SQL, DAE и XLSX, которые содержат всю необходимую информацию об элементах, но при этом не обременены избыточной логикой построения геометрии BREP и внутренними классификациями конкретных CAD и BIM-продуктов.

Ситуация с форматами данных в CAD-индустрии приближается к развязке. Autodesk, ведущий разработчик в отрасли, уже похоже уже сделал выбор в пользу USD и альянса AOUSD. Простота и универсальность USD выглядит более привлекательно по сравнению со сложной параметрической структурой IFC.
Однако за дискуссиями о форматах данных теряется главный вопрос: какую реальную ценность несут эти десятки различных форматов, содержащих одну и ту же информацию в разной форме и для чего они действительно нужны?
Гранулированные данные, аналитика, машинное обучение и большие языковые модели
Работа с данными в строительстве подразумевает взаимодействие с большим объёмом информации из разных источников, которые рано или поздно нужно интегрировать между собой. 

Сегодня в мире проектирования и строительства сложность доступа к данным приводит к чрезмерной инженерии управления проектами. Средние и крупные компании на рынке BIM либо вынужденно поддерживают тесные отношения с поставщиками САПР для доступа к данным через API и такие продукты, как Forge и ACC, либо обходят ограничения поставщиков САПР, используя дорогие конвертеры SDK для реверс инжиниринга для получения открытых данных.
Благодаря доступу к открытым данным любой специалист строительной отрасли, взявший в руки LLM и Python, может перейти на альтернативные инструменты для количественных расчетов (QTO), проверки данных, создания документов, электронных таблиц и приборных панелей, отказавшись от традиционных CAD (BIM) решений. CAD-вендоры стараются отсрочить процесс беспрепятственного получения открытых данных и перехода к аналитике данных, создавая новые форматы, концепции и альянсы. 
Появление в 2023 году альянса AOUSD знаменует важный поворот в строительной отрасли. Мы наблюдаем формирование новой реальности в работе со строительными данными через несколько значимых изменений. Первое серьезное изменение касается восприятия CAD-данных. Участники рынка начинают понимать, что строительное проектирование — это только начало пути. Данные, созданные в CAD-системах, становятся основой для глубокого анализа и последующей эксплуатации объектов.
Параллельно с этим происходит революция в подходах ведущих разработчиков. Autodesk, один из лидеров отрасли, совершает неожиданный поворот в своей стратегии. Компания отходит от традиционного хранения данных в отдельных файлах, делая ставку на работу с нормализованными и структурированными данными c переходом в дата центричный подход.

Не менее важна и активизация облачных гигантов. Amazon и Huawei, видя потенциал рынка, ускоренно разрабатывают специализированные решения. Их цель — создать инструменты маркетплейсов для эффективной нормализации и структурирования строительных проектов, которые хранятся в их облачных системах и поступают из различных CAD-платформ.
К 2025 году ожидается значительное ускорение изменений в обработке данных. По словам CEO Nvidia, уже сейчас 30% вычислительных ресурсов используется для обработки структурированных данных - датафреймов. Meta готовится представить новую модель LLaMa, ключевой сценарий применения которой связан с работой с нормализованной колончатой информацией. Популярность инструментов для анализа данных, таких как Pandas, продолжает расти стремительными темпами и достигает 10 миллионов скачиваний в день. 
Все эти тенденции знаменуют начало новой эпохи, где работа с данными становится основой профессиональной деятельности. Индустрия готовится к новой эре — эре аналитики данных в строительстве. Ручное перемещение данных между таблицами уходит в прошлое, уступая место автоматизации, анализу потоков данных, аналитике и машинному обучению, которые становятся ключевыми инструментами принятия решений.

Выбор за вами: адаптироваться к этой новой реальности или остаться в мире устаревших концептов и закрытых экосистем.
С закрытыми форматами Revit и других CAD/BIM-систем произошло то же, что и с DWG 20 лет назад. Благодаря обратной инженерии SDK и конвертерам эти форматы стали доступны как разработчикам, так и пользователям. Почти все крупные компании в области CAD, MCAD и строительства тратят от 10 000 до 200 000 евро в год на доступ к данным через конвертеры и ни одна из ведущих компаний мира не работает с данными через API, плагины или форматы которые предлагают CAD вендоры - будь то IFC или USD.
Старые решения и закрытые платформы с API документацией  отходят в прошлое. Маркетинговый концепт BIM де факто представляет собой преобразование требований заказчика в реальность с помощью «волшебства» параметров и анализа данных. Если вы ещё не начали изучать аналитику, сейчас самое время это сделать. Не ждите, пока вендоры представят новый формат, новый курс обучения, сертификат или концепцию по дата аналитике. Начните работать с данными и анализом данных уже сегодня — это ключ к будущему строительной отрасли и не только строительной отрасли. Все инструменты которыми пользуются специалисты в других отраслях экономики бесплатно и открыты уже доступны для вас если вы сможете получать открытые данные.
Данные, которые создаются сегодня в строительной отрасли, станут ключевым ресурсом для принятия бизнес-решений в будущем. Они будут выступать в роли стратегического "топлива", питающего развитие и эффективность строительных компаний.

Заключение
Будущее строительной отрасли — в умении работать с данными, а не в выборе формата. Итоги за 2024 год:
• Форматы данных, такие как RVT, IFC, PLN, DB1, CP2, CPIXML, USD, SQLite, XLSX, PARQUET и другие, содержат одинаковую информацию об элементах проекта. Это значит, что знание конкретного формата больше не является преградой для работы с данными.
• Данные из этих форматов объединяются в одну открытую гранулированную структуру, содержащую геометрию MESH и свойства объектов. 
• Дата-аналитика - ключ к универсальности: используя открытые данные вы можете научиться работать с проектными данными независимо от используемого формата. Это не просто полезный навык, а ваш пропуск в будущее проектирования и строительства.
• Прощай API: работа с данными больше не зависит от навыков использования API. Учитесь работать с открытыми данными и начинайте собирать их уже сегодня!
Разработчики и пользователи стоят перед стратегическим выбором, который может определить будущее отрасли на годы вперед. Создание гибридного решения, сочетающего форматы IFC и USD, выглядит маловероятным - такая искусственная комбинация была бы слишком сложной и неэффективной. Вместо этого индустрии предстоит сделать четкий выбор: либо полностью перейти на современный формат USD, либо модернизировать проверенный временем IFC, интегрируя в него лучшие элементы USD. Это решение станет одним из ключевых факторов, определяющих направление развития всей строительной отрасли.
Текущие тенденции в строительной отрасли потенциально создадут условия для постепенного ухода от устаревающего формата IFC в пользу более универсального USD, что отражает уже сегодня стратегию крупнейших игроков рынка, таких как Autodesk, Trimble и Hexagon, стремящихся укрепить своё влияние через альянс AOUSD. Исторические лидеры, включая HOK, которые когда-то активно продвигали IFC вместе с Autodesk и альянсом IAI-buildingSMART, открыто продвигают USD, подчеркивая его простоту и универсальность. Массовое внедрение USD в продукты, совместимость с GLTF и активная интеграция в инструменты, такие как Blender и Unreal Engine, свидетельствуют о потенциале начала новой парадигмы работы с данными. Наряду с популярностью локальных решений, таких как европейский плоский USD — CPIXML, используемый в ITWO/MTWO может потенциально усилить позиции USD в Центральной Европе. 

На этом фоне USD потенциально может стать стандартом де-факто, обещая преодолеть множество текущих ограничений. А BuildingSMART уже адаптирует свою стратегию под USD, что лишь подтверждает неизбежность сдвига. USD будет завоевывать место в строительной отрасли благодаря своей простоте, гибкости и поддержке крупных технологических альянсов. Однако, за фасадом "открытых данных" может скрывается намерение лидеров рынка монополизировать управление проектными данными. Пользователи оказываются в положении, где выбор формата больше связан с корпоративными интересами, чем с реальными потребностями.
Эпоха перемен в строительной отрасли, на первый взгляд, представляется как технологический прорыв в виде перехода от устаревающего IFC к более современному USD. Однако на данный момент за этой трансформацией скорее кроется борьба крупных корпораций за управлении данными. Анализ 14 ключевых фактов позволяет увидеть, что основная цель этих изменений – не только удобство пользователей, но и удержание контроля над экосистемами и потоками данных.
Ключевой урок: будущее за открытыми, плоскими, унифицированными данными, доступными для аналитики. Однако, чтобы не стать пешками в игре больших вендоров, строительным и проектировочным компаниям стоит делать ставку на настоящую открытость и независимость уже сегодня.

Проблема неоднородности данных
Д
ля хранения и обработки проектных данных компаниям строительной отрасли приходится полагаться на различные закрытые системы ERP, САПР (BIM), EMP и т. д. или облачные корпорации. Корпорации предоставляют "контролируемый" доступ к качественным данным, используя проприетарные инструменты и форматы, которых не существует в других отраслях.
Собственная природа систем приводит к тому, что каждая программа имеет свой уникальный формат данных, который либо закрыт и недоступен извне - RVT, PLN, DWG, NDW, NWD, SKP, либо доступен в полуструктурированной (и часто смешанной) форме - JSON, XML, CPIXML, IFC, STEP и ifcXML, IfcJSON, IfcSQL, RDF, dotBIM, BIMJSON. 
Различные форматы данных, в которых хранятся одни и те же данные, не только отличаются по структуре, но и включают разные версии внутренней разметки, которые разработчикам необходимо учитывать для обеспечения совместимости приложений, работающих с этими форматами (подробнее об этом в главе "BIM-данные и концепция BOM-BIM"). 
Не предоставляя прямого доступа к базам данных, каждый поставщик программного обеспечения в строительной отрасли изобретает свой собственный уникальный инструмент, который специалист должен использовать для доступа, импорта и экспорта данных.
Как следствие, поставщики базовых САПР (BIM) и ERP-решений постоянно повышают цены на использование своих продуктов, а рядовые пользователи вынуждены платить "комиссию" на каждом этапе передачи данных [10]: за подключение, импорт, экспорт и работу с данными, которые пользователи создали сами. Стоимость доступа к данным в облачном хранилище из популярных САПР (BIM) продуктов в 2024 году достигнет 1 доллара за транзакцию [25], а подписки на ERP-продукты для средних компаний достигают пяти- и шестизначных сумм в год [26].

   Рисунок 3.5-5. Из-за изолированности и сложности данных в строительной отрасли скорость принятия решений в несколько раз ниже, чем в других отраслях
Суть современного строительного программного обеспечения заключается в том, что не автоматизация или повышение эффективности, а умение инженеров разбираться в конкретном узкоспециализированном программном обеспечении влияет на качество и стоимость строительного проекта, а также на прибыль и долгосрочное выживание компаний.
Отсутствие открытых данных в процессе создания головоломки из закрытых системных решений и, как следствие, отсутствие качественной коммуникации между отдельными специалистами привело строительную отрасль к статусу одного из самых неэффективных секторов экономики с точки зрения производительности.
За последние 20 лет применения САПР (BIM) проектирования, появления новых систем (ERP), строительных технологий и материалов, производительность всей строительной отрасли упала на 20% (рис. 3.5-6), в то время как общая производительность всех секторов экономики выросла на 70% (96% в обрабатывающей промышленности) [27].

   Рисунок 3.5-6. Непрозрачные данные и как следствие плохая коммуникация между специалистами привели строительную отрасль к одному из наименее эффективных секторов экономики
Из-за ограничений закрытых систем и различий в форматах данных, а также отсутствия эффективных инструментов для их унификации компании сталкиваются с накоплением значительных объемов данных разной степени структурированности. Эти данные не используются должным образом и попадают в архивы, где со временем остаются навсегда забытыми и неиспользуемыми (рис. 3.5-7).
Данные, полученные путем значительных усилий, из-за своей сложности становятся недоступными для дальнейшего использования. 

Рисунок 3.5-7. Трудноизвлекаемые данные собираются в хранилища [33]
, которые рискуют никогда не быть использованными 

Так будет продолжаться до тех пор, пока не появится специализированный инструмент или энтузиаст, готовый решить сложную задачу по восстановлению и использованию этих некогда потерянных данных.
Одна из основных причин, по которым компаниям не удаётся автоматизировать, стандартизировать и унифицировать потоки данных, заключается в разнообразии и динамичности задач, с которыми сталкиваются все участники строительного проекта.


Постоянное повышение сложности и динамичности бизнес-процессов
С
троительная отрасль сталкивается не только с необходимостью работать с разнообразными и закрытыми данными и системами, но и с растущей сложностью и динамичностью самих бизнес-процессов, которые постоянно меняются и обновляются в соответствии со специфическими требованиями разных стран, клиентов и проектов.
В каждой стране мира действуют свои правила и нормы, регулирующие строительную отрасль, делая каждый строительный проект уникальным собранием различных заинтересованных сторон, обладающих различным набором навыков и опыта. Непрерывный же поток новых технологий и инструментов создаёт необходимость в постоянной модификации и адаптации управленческих процессов. Эти изменения сложно быстро интегрировать в существующие системы управления данными из-за необходимости при каждом изменение правил игры ожидать обновлений от разработчиков для реализации новых функций.
Поэтому дополнительными проблемами для бизнеса в современном постоянно меняющемся мире становятся динамичность и уникальность внутренних процедур и необходимость постоянно автоматизировать и унифицировать большое количество отдельных бизнес-сценариев.
Внутри одной компании часто функционируют множество взаимосвязанных иерархических систем, которые координируются через сеть менеджеров (рис. 3.5-8).


 Даже в рамках одной системы может возникать необходимость в оптимизации или автоматизации потока входящих и исходящих данных из множества разнообразных источников.
   Рисунок 3.5-8. Компании состоят из взаимосвязанных систем, чье объединение формирует процессы, требующие автоматизации
Из-за непрозрачности внутренних процессов и огромного объема данных, с которыми часто не могут справиться руководители и управленческий персонал, на помощь приходят поставщики специализированных технологических решений, предлагающие индивидуальные инструменты для решения специализированных задач.
Рынок переполнен большим количеством стартапов и инструментов, которые активно конкурируют друг с другом, предлагая разнообразные продукты для удовлетворения конкретных потребностей клиентов. Однако в погоне за удовлетворением конкретных потребностей упускается возможность целостного подхода к проблеме накопления и управления большими объемами данных. Это приводит к тому, что индивидуальные решения зачастую ограничиваются узкими рамками, не учитывая широту и сложность проблемы в целом.
В компании с множеством систем количество процессов и сценариев использования растет пропорционально количеству систем и пользователей, достигая тысяч различных сценариев использования в масштабах одной компании среднего размера.




   Рисунок 3.5-9. Для каждого случая использования данных рынок решений предлагает приложения для оптимизации и автоматизации процессов
Каждая компания уникальна в силу разнообразия элементов и ресурсов, лежащих в основе ее систем, что затрудняет перенос систем с пользователями между компаниями из-за специфики "почвы" и уникальной управленческой сети "мицелия менеджеров", где практически каждый процесс системы, будучи перенесенным в новую систему или отдел, потребует доработки, чтобы соответствовать новой среде.
Перемещение строительной компании или даже одной системы из одной страны в другую еще сложнее, чем перемещение систем внутри компании. Таким образом, количество процессов, умноженное на количество компаний в стране, даст приблизительную оценку общего количества уникальных процессов в национальном масштабе.
В 2023 году в Англии (включая Уэльс, Шотландию и Северную Ирландию) и Германии будет зарегистрировано около полумиллиона строительных компаний [24]. 

Исходя из невозможности использования бизнес-кейсов разными компаниями, можно предположить, что в таких странах, как Германия и Англия, может существовать миллионы уникальных бизнес-кейсов использования строительных данных на уровне страны (рис. 3.5-10), которые постоянно используются и оптимизируются компаниями в строительной отрасли.
   Рисунок 3.5-10. Индивидуальность бизнеса и проектов создает большое количество уникальных и постоянно меняющихся бизнес-кейсов
Строительная отрасль очень разнообразна: у разных проектов разные требования, региональные особенности, законодательные нормы, бюджетные ограничения и т. д. Поэтому практически невозможно создать проприетарное универсальное приложение или систему, которая бы идеально подходила под все эти требования и особенности проектов.
Разработка специализированного проприетарного программного обеспечения и закрытых систем для решения уникальных бизнес-проблем является ключевой частью четвертой технологической революции, отмеченной оцифровкой данных. В эту эпоху акцент делается на создании новых инструментов, придавая меньшее значение самим данным.
На протяжении десятилетий ключевые технологические переходы в сфере информационных технологий происходили под руководством поставщиков программного обеспечения. Именно они направляли движение индустрии, определяя, какие решения внедрять, а какие – игнорировать.
Когда предприятия переходили от разрозненных систем к базам данных и интегрированным пакетам приложений, именно вендоры предлагали свои продукты, требуя платы за лицензии. Позднее, с приходом облачных технологий, бизнес-модель изменилась, но суть осталась прежней – теперь пользователям продавали подписки, превращая компании в постоянных клиентов сервисов.
Но что, если на горизонте появился бы переход, который не поддается монетизации в привычном формате? Что, если новая парадигма, подобная Data-Centric, подрывает саму основу, на которой стоят эти гиганты? В отличие от предыдущих трансформаций, эту никто не будет активно продвигать – слишком велик риск разрушения устоявшихся бизнес-моделей. Здесь нет очевидного продукта, который можно было бы продать. Нет подписки, которую можно было бы навязать.
Именно поэтому этот переход будет другим. Не стоит ждать, что поставщики возьмут на себя его продвижение – напротив, для многих из них он станет угрозой. Но для тех, кто поймет его суть и освоит принципы Data-Centric, откроются новые возможности, свободные от диктата традиционных ИТ-монополий.
Сегодня в мире существует множество миллиардов строк кода, хотя для работы требуется лишь небольшая часть из них. Возможно, программного кода создано в тысячу раз больше, чем действительно нужно. Однако за его разработку уже заплачено, и эти затраты невозвратны. Тем не менее, новое программное обеспечение продолжает появляться, зачастую с минимальной реальной ценностью.
Снижение сложности, прямое и косвенное, уменьшает количество кода, который необходимо создавать и поддерживать. 

Стоимость одной строки проверенного программного кода сегодня составляет от 10 до 100 долларов, что зависит от сложности проекта и требований к качеству 
. Основными факторами, влияющими на цену разработки, являются сложность логики программного обеспечения и выбранные технологии 

. Современные тренды, такие как использование low-code платформ и экосистем, позволяют значительно снизить расходы на создание и поддержку ПО, указывая на потенциал для дальнейшего снижения стоимости в будущем 
8
. Благодаря развитию автоматизированных инструментов и искусственного интеллекта, можно предположить, что цена производства программного кода может существенно уменьшиться в ближайшие годы.
 Сегодня несмотря на то, что в строительной отрасли еще широко используются проприетарные приложения, лидирующие компании отрасли начинают переходить от подходов и стандартов четвертой технологической революции к пятой, где в центре внимания находятся данные.

Четвертая промышленная революция (Индустрия 4.0) и пятая промышленная революция (Индустрия 5.0) в строительстве
Т
ехнологические и экономические уклады - это теоретические концепции, используемые для описания и анализа эволюции общества и экономики на разных этапах развития человечества. 
• Четвертая промышленная революция (4IR или Industry 4.0) связана с информационными технологиями, автоматизацией, цифровизацией и глобализацией. Создание проприетарных и закрытых приложений является частью этого уклада, предполагая разработку программного обеспечения, которое является ключевым аспектом информационных технологий.
• Пятая промышленная революция (5IR) сегодня находится на более ранней стадии концептуализации и развития, чем 4IR. Ее основные принципы включают повышение степени персонализации продуктов и услуг. 5IR — это движение к более адаптируемой, гибкой и персонализированной экономической деятельности с акцентом на персонализацию, консалтинг и сервис-ориентированные модели. Ключевым аспектом пятого экономического уклада является использование данных для принятия решений, что практически невозможно без применения открытых данных и открытых инструментов (рис. 3.5-11).

   Рисунок 3.5-11. 4-й экономический уклад фокусируется на закрытых решениях, в то время как 5-й переносит акцент на использование данных
   
   
В условиях четвертой экономической парадигмы, даже создав параметризованное приложение или автоматизированный конвейер, который эффективен для процессов в десяти или ста компаниях, вероятность его массового масштабирования в других организациях без дополнительных модификаций и доработок остается низкой.
Если рассматривать процессы разных компаний на обобщенном концептуальном уровне (рис. 2.5-6), то действительно, результаты их работы часто кажутся практически идентичными. Однако, разделяя процессы на логический и физический уровни (рис. 2.5-7, рисунок 2.5-8), становится очевидно, что даже стандартные процессы могут значительно различаться в разных компаниях из-за уникальных характеристик и способов реализации их подпроцессов.
Важно понимать, что успешная интеграция технологических решений в строительстве подразумевает глубоко персонализированный подход к каждому процессу, проекту и компании. Это означает, что даже после разработки универсальной структуры, инструмента или программы потребуется ее детальная адаптация и настройка под уникальные требования и условия каждой конкретной компании. 
Учитывая масштабы мировой строительной отрасли, можно предположить, что существуют миллиарды уникальных бизнес-кейсов, каждый из которых имеет свои особенности и требует индивидуального подхода.


   Рисунок 3.5-12. Индивидуальность бизнес-кейсов делает попытки создания масштабируемых закрытых платформ и инструментов неэффективными

Персонализация и консалтинг, соответствующие пятому экономическому укладу, позволят перейти к более индивидуальной и основанной на знаниях деятельности, где в различных сценариях и задачах ключевым фактором успеха станет способность компаний не только адаптировать использование открытых данных и открытых решений, но и эффективно анализировать огромные объемы данных для принятия обоснованных решений.
Экосистемы строительных компаний, вслед за остальной экономикой, начнут переходить в пятую экономическую парадигму, где услуги по аналитике и консалтингу будут приоритетнее закрытых решений с жесткими сценариями использования.
В эпоху цифровизации и больших данных строительные компании, вместо того чтобы извлекать выгоду из спекуляций в закрытых системах, получат новый источник повышения эффективности - аналитические инструменты и методологии, которые станут неотъемлемой частью стратегического планирования и оперативного управления в строительстве. 
Принятие решений на основе данных и аналитика станут важнейшими компонентами, которые позволят строительным компаниям не только повысить эффективность и оптимизировать процессы, но и предвидеть тенденции, минимизировать риски и внедрять инновации для решения проблем.











ЧАСТЬ IV 

ПРИНЯТИЕ РЕШЕНИЙ 
НА ОСНОВЕ ДАННЫХ, АНАЛИТИКА, АВТОМАТИЗАЦИЯ И МАШИННОЕ ОБУЧЕНИЕ



ГЛАВА 4.1 
АНАЛИТИКА ДАННЫХ И 
ПРИНЯТИЕ РЕШЕНИЙ НА ОСНОВЕ ДАННЫХ

Принятие решений на основе данных
П
роцесс принятия решений на основе данных начинается со сбора информации из плодородной почвы компании, которая возникает через паденье отдельных данных (соответствующие листьям деревьев систем) и целых систем на дно хранилищ компании. Со временем эти данные, подобно листьям и веткам, преобразуются в ценный материал. Они организуются и подготавливаются к будущему использованию, при котором мицелий инженеров по данным и аналитиков превращает опавшие данные и системы в ценный компост. Эти подготовленные и правильно разложенные данные становятся ценным ресурсом для анализа и принятия обоснованных решений в компании.
Анализ данных, подобно распространению мицелия, проникает сквозь гумус прошлых решений, направляя менеджеров к ценным знаниям. Эти знания, подобно питательным веществам из разложившегося дерева, питают новые решения в компании, приводя к эффективным изменениям и росту, подобно новым побегам и росткам, появляющимся из богатой и здоровой почвы.
Руководители и менеджеры, принимающие решения, не всегда обладают достаточным опытом работы с разнородными данными и системами, но при этом им необходимо принимать решения на их основе.

   Рисунок 4.1-1. Анализ данных и аналитика - основной инструмент для повышения скорости принятия решений в компании

Сегодня, в период взрывного роста объема данных, процессом извлечения и анализа данных из гумуса прошлых проектов занимаются в основном крупные и продвинутые компании, которые занимаются сбором данных на протяжении последних десятилетий.
Даже в тех компаниях, где сегодня работают инженеры и аналитики данных, работа по извлечению и подготовке данных для аналитики напоминает чрезвычайно трудоемкий процесс (рис. 4.1-2), сравнимый с добычей угля (окаменелого дерева) шахтерами в XVIII веке. Хотя добыча данных в современной строительной отрасли не столь примитивна, как у рудокопов XII века, это все еще чрезвычайно сложная и рискованная задача.

   Рисунок 4.1-2. ИТ-специалисты и менеджеры по работе с данными должны пройти сложный путь, чтобы подготовить данные к аналитике
Работа по добыче и подготовке данных сегодня скорее предназначена для авантюристов, работающих в узкоспециализированной нише с небольшим и ограниченным набором инструментов для работы с различными типами данных из полуструктурированных, смешанных или закрытых источников. В результате принятие решений на основе данных в современной строительной отрасли меньше похоже на автоматизированный процесс и больше на многодневный ручной труд.
Бизнес-аналитика будет сводится не только к анализу данных —но еще и к генерации кода приложений бизнес аналитики с помощью искусственного интеллекта и чатов больших языковых моделей. 
Ключевые понятия в аналитике данных, которые важно знать:
• Набор данных (Dataset) – Совокупность связанных данных, организованных для анализа.
• Очистка данных (Data Cleaning) – Исправление ошибок или несоответствий в данных для повышения точности.
• Разведочный анализ данных (Exploratory Data Analysis, EDA) – Анализ данных для суммирования их основных характеристик, часто с использованием визуальных методов.
• Корреляция (Correlation) – Мера степени взаимосвязи двух переменных.
• Сводная таблица (Pivot Table) – Инструмент для обобщения, сортировки и анализа данных.
• Добыча данных (Data Mining) – Выявление закономерностей в больших наборах данных.
• Проверка гипотез (Hypothesis Testing) – Определение, подтверждают ли данные гипотезу или опровергают её.
• Визуализация данных (Data Visualization) – Графическое представление данных для выявления закономерностей.
В предыдущих главах мы подробно рассмотрели процессы сбора данных и контроля их качества для использования в популярных бизнес-кейсах и процессах, с которыми работают компании строительной отрасли. 
Аналитика в этом отношении мало чем отличается от других процессов, но все же имеет свои уникальные особенности.
Для процессов аналитики и анализа одним из ключевых этапов является визуализация данных. Этот этап позволяет визуализировать информацию, что крайне важно для извлечения ценных аналитических сведений.

Визуализация данных
В
 современной строительной отрасли, где проектные данные характеризуются сложностью и многоуровневой структурой, визуализация играет ключевую роль. Визуализация данных позволяет руководителям проектов и инженерам визуализировать сложные закономерности и тенденции, скрытые в больших, разнородных объемах данных.
Визуализация данных облегчает понимание состояния проекта: распределение ресурсов, динамики затрат или использование материалов. Благодаря графикам и диаграммам сложная и сухая информация становится доступной и понятной, позволяя быстро определить ключевые области, требующие внимания, и выявить потенциальные проблемы.


   Рисунок 4.1-3. Визуализация данных — это первый шаг на пути 
к анализу бизнес-процессов и аналитике
Визуализация данных не просто облегчает интерпретацию информации, она является важнейшим этапом в аналитическом процессе и принятии обоснованных управленческих решений. Перед принятием ключевых решений руководители проектов с большей вероятностью будут использовать визуальные представления данных, а не сухие и трудно интерпретируемые цифры из электронных таблиц или текстовых сообщений.
Данные, не подкрепленные визуализацией, подобны строительным материалам, беспорядочно разбросанным по стройплощадке: Их потенциал неясен. Только когда из них возникает четкая визуализация, как из кирпича и бетона - дом, становится ясно, какую ценность они представляют. Пока дом не построен, невозможно сказать, станет ли груда материалов небольшой хижиной, роскошной виллой или небоскребом.
Компании располагают данными из различных систем (рис. 1.2-1), финансовыми операциями и обширными текстовыми данными. Однако использование этих данных в интересах бизнеса зачастую представляет собой сложную задачу. В таких ситуациях визуализация становится важным инструментом для передачи смысла данных, который помогает представить информацию в форматах, понятных любому специалисту, например в виде приборных панелей, графиков и диаграмм.
Процесс переваривания и преобразования информации в визуальные графические формы, такие как диаграммы, графики, улучшает понимание и интерпретацию данных человеческим мозгом и позволяет руководителям проектов и аналитикам быстро оценивать сложные сценарии и принимать обоснованные решения, основанные на фактах, а не на интуиции (более подробно создание визуализаций будет рассмотрено в главе "ETL и автоматизация процессов").

   Рисунок 4.1-4. Различные виды визуализации созданы для того, чтобы помочь человеческому мозгу лучше понять и осмыслить сухую информацию чисел 
Визуализация данных позволяет выявить тенденции развития бизнеса, которые с помощью анализа и аналитики помогают создавать KPI (ключевые показатели эффективности) для отдельных специалистов и отделов, а также сделать прогноз на следующий квартал или финансовый год, используя исторические данные компании. 

Показатели KPI и информационные панели
В
 современной строительной отрасли управление показателями эффективности (KPIs - "ключевые показатели эффективности") и их визуализация с помощью отчетов и информационных панелей (dashboards) играют важнейшую роль в повышении производительности и эффективности управления проектами.
В строительстве, как и в любом бизнесе, важно иметь четкую стратегию и объективные показатели, по которым можно оценивать успех. Организация, управляемая данными, должна сначала определить ключевые метрики — KPI, которые отражают эффективность строительства, соблюдение сроков и бюджетов.
На уровне компании такими показателями могут быть средняя стоимость квадратного метра, процент завершенных в срок проектов или объем переработанных строительных отходов. В свою очередь, каждая строительная площадка или подразделение будет работать со своими KPI: время выполнения конкретных этапов (фундамент, монтаж, отделка), процент перерасхода материалов, количество внеплановых простоев техники.
Если метрики подобраны неверно, это может привести к неправильным решениям. Например, если компания ориентируется только на стоимость квадратного метра, но не учитывает количество переделок и исправлений, экономия на материалах может привести к снижению качества и росту затрат в будущем.
Грамотно выстроенные показатели позволяют не только следить за ходом работ, но и выявлять узкие места, тестировать новые технологии и улучшать процессы. Как хороший строительный уровень показывает, ровно ли кладутся кирпичи, так и качественные KPI помогают бизнесу двигаться в правильном направлении.


KPI в строительстве служат для оценки различных аспектов проекта, от сроков выполнения до бюджетных расходов.
Для расчета KPI обычно используется формула, включающая фактические и плановые показатели. Например, чтобы рассчитать индивидуальный KPI для сотрудника или целого отдела, необходимо разделить фактические показатели на плановые и умножить полученный результат на 100 %.

   Рисунок 4.1-5. KPI используются для измерения успеха организации, сотрудника или другого субъекта в достижении ключевых целей
При постановке целей важно четко определять, что именно измеряется. Размытые формулировки приводят к некорректным выводам и усложняют контроль. Рассмотрим примеры удачных и неудачных KPI в строительстве.
Хорошие KPI:
✔ "К концу года снизить процент переделок отделочных работ на 10%."
✔ "Увеличить скорость монтажа фасадов на 15% без снижения качества к следующему кварталу."
✔ "Сократить время простоя техники на 20% за счет оптимизации графиков работы к концу года."
Эти метрики четко измеряемы, имеют конкретные значения и временные рамки.
Плохие KPI:
✘ "Мы будем строить быстрее." (Насколько быстрее? Что значит "быстрее"?)
✘ "Мы повысим качество бетонных работ." (Как именно измеряется качество?)
✘ "Мы улучшим взаимодействие подрядчиков на площадке." (Какие критерии показывают улучшение?)
Хороший KPI — это тот, который можно измерить и объективно оценить. В строительстве это особенно важно, поскольку без четких показателей невозможно контролировать эффективность работы и достигать стабильных результатов.

Регулярное измерение показателей KPIs на основе данных, собранных из различных источников, таких как расход материалов, трудочасы и затраты, позволяет руководству проектов эффективно управлять ресурсами и быстро принимать решения. Хранение этих данных в долгосрочной перспективе позволяет анализировать будущие тенденции и оптимизировать процессы.
Для визуализации KPI используются различные графики и диаграммы, которые обычно объединяются в приборные панели.
Дашборды — это инструменты, которые визуализируют количественные оценки, делая их легкодоступными и понятными для всех участников проекта.
Информационные панели обеспечивают централизованное представление проекта или его части, отображая соответствующие показатели в режиме реального времени, что позволяет команде быстро реагировать на любые изменения и динамично адаптироваться к новым обстоятельствам.

   Рисунок 4.1-6. Управление KPI и их визуализация с помощью информационных панелей - ключ к повышению производительности и эффективности проекта
Вот несколько примеров популярных инструментов, в которых можно создавать информационные панели:
● Power BI - инструмент от Microsoft для создания интерактивных отчетов и информационных панелей.
● Tableau и Google Data Studio - мощные инструменты для визуализации данных и создания информационных панелей без необходимости писать код.
● Plotly (рис. 4.1-6, рис. 4.2-12) — это библиотека для создания интерактивных графиков, а Dash - фреймворк для создания веб-приложений для анализа данных. Их можно использовать в комбинации для создания интерактивных приборных панелей.

● Библиотеки Python (рис. 4.2-9 - 4.2-11) – в Python есть множество библиотек для визуализации данных, таких как Matplotlib, Seaborn, Plotly, Bokeh и другие. Их можно использовать для создания графиков и интеграции их в веб-приложение с помощью таких фреймворков, как Flask или Django.
● Библиотеки JavaScript: позволяют создавать интерактивные информационные панели с помощью библиотек JavaScript, таких как D3.js или Chart.js, и интегрировать их в веб-приложение.
 
В строительстве данные обновляются из различных источников, и фиксация времени их ввода и обновления позволяет точно отслеживать, актуализировать и динамизировать проект. Это особенно важно для приборных панелей, поскольку они должны отображать самую актуальную информацию для обеспечения эффективного управления проектом.
Для оценки KPI и создания информационных панелей необходимы актуальные данные и четкий график сбора и анализа информации.
Для обработки потоковых данных проекта необходимо определить время сбора данных для конкретного процесса или для всех бизнес-процессов компании в целом. Это может быть, например, время окончания рабочего дня в 19:00 (рис. 4.1-7): в это время будет запущен первый процесс-скрипт, который соберет данные из различных систем и хранилищ. На следующем этапе эти данные автоматически обрабатываются и преобразуются в структурированный формат. На следующем этапе на основе обработанной информации автоматически создаются отчеты и дашборды или выполняются все те процессы, о которых мы уже подробно рассказывали в предыдущих главах книги. В результате к 05:00 утра у менеджеров уже есть актуальные отчеты о состоянии проекта в нужном формате.


   Рисунок 4.1-7. Данные, автоматически собранные вечером, обрабатываются в течение ночи, чтобы к утру у менеджеров были актуальные отчеты и свежие информационные панели
Эффективное использование данных, соответствие KPI и визуализация с помощью информационных панелей — вот некоторые из ключевых элементов успеха в процессах принятия решений на основе данных.

   Рисунок 4.1-8. Автоматический ETL-конвейер процессов с рисунка 4.1-8 на платформе Prefect, в котором 10 скриптов python запускаются поочередно после 19:00 каждый рабочий день
В целом KPI и информационные панели в строительной отрасли формируют основу для аналитического подхода к управлению проектами. Они не только помогают отслеживать и оценивать текущий статус проектов, но и предоставляют ценные сведения для будущего планирования и оптимизации процессов.

Аналитика и анализ данных
И
нтерпретация данных - это последний шаг в анализе информации, позволяющий понять ее смысл. Этот процесс помогает делать выводы, обобщать информацию, выявлять корреляции и причинно-следственные связи.
Самая большая проблема, с которой сталкиваются компании, пытающиеся внедрять инновации и преобразовывать себя с помощью данных, - это культура "мы всегда так делали". 
-Габи Боко3


Современный бизнес на конкурентном и низко маржинальном строительном рынке в 4 индустриальной парадигме можно сравнить с военными действиями, где успех компании и ее выживание зависят от скорости получения поддержки в виде ресурсов или "боеприпасов", за которыми стоят правильные решения. В отличие от визуализации, которая является элементом разведки, аналитика данных выступает в качестве "боеприпасов" и имеет решающее значение для принятия решений, которые лежат в основе стремления компании получить конкурентное преимущество на рынке.
Анализ данных преобразует собранные данные в структурированную и содержательную информацию, которая служит основой для принятия решений.
Аналитики предоставляют компании обоснованные решения, применяя инструменты визуализации и статистический анализ для изучения данных. Они выявляют тенденции, определяют взаимосвязи между разными типами данных и классифицируют их согласно специфическим критериям.

   Рисунок 4.1-9. Анализ данных превращает собранные данные 
в значимую информацию
Для того чтобы принимать правильные решения в процессе аналитики, важно правильно сформулировать вопросы, которые можно задать данным. Качество принимаемых решений будет напрямую зависеть от качества вопросов, которые задаются данным в процессе аналитики.
Искусство задавать глубокие вопросы - ценный навык, который необходимо развивать в контексте работы с данными. Большинство людей склонны задавать базовые вопросы, ответы на которые требуют минимальных усилий. Однако настоящий анализ начинается с умения задавать продуманные, содержательные вопросы источнику информации.
Ответы на ключевые вопросы и принятие обоснованных решений на основе результатов анализа данных позволяют получить ценные сведения для достижения целей и успешного управления бизнес-процессами (подробнее об инструментах прогнозирования и предсказания в главе "Прогнозирование, предсказание и машинное обучение"). 
Необходимость постоянно обновлять аналитику и информационные панели неизбежно заставляет руководство и руководителей компаний осознать преимущества автоматизации процессов, чтобы повысить скорость принятия решений и снизить влияние человеческого фактора на процесс принятия решений.
Titanic dataset is Hello World в мире аналитики данных и больших данных

   Рисунок 4.1-9. Простая таблица с 11 колонками параметрами
Автоматизация процессов аналитики и обработки данных в целом неразрывно связана с темой ETL (Extract, Transform, Load). Точно так же, как в процессе автоматизации нам необходимо преобразовать данные, в процессе ETL данные извлекаются из различных источников, преобразуются в соответствии с необходимыми требованиями и загружаются в целевые системы для дальнейшего анализа.



ГЛАВА 4.2 
ETL И АВТОМАТИЗАЦИЯ ПРОЦЕССОВ

ETL: переход от ручного управления к автоматизации
С
толкнувшись со стагнацией KPI, несмотря на растущий объем данных и количество специалистов в компании, руководство и администрация приходят к неизбежному осознанию необходимости автоматизации процессов. Это осознание становится стимулом для начала комплексной автоматизации, основной целью которой является снижение сложности бизнес-процессов и уменьшение влияния человеческого фактора.
Упрощение процесса — это формирование автоматизированного процесса, который заменяет традиционные функции ручного управления.

   Рисунок 4.2-1. Аналитика данных помогает компаниям осознать необходимость автоматизации определенных процессов
Вопрос автоматизации, а точнее, "минимизации роли человека в обработке данных", является необратимым и крайне чувствительным для каждой компании. Специалисты в любой области часто не решаются полностью раскрыть свои методы и тонкости работы коллегам-автоматизаторам, осознавая риск потери работы в стремительно развивающейся технологической среде.
Типичную последовательность обработки данных можно описать в контексте популярного примера работы с данными из баз данных САПР (BIM). 

Традиционная обработка данных ("ручной" ETL-процесс) в отделах САПР (BIM) для создания атрибутивных таблиц или создания документации на основе проектных данных происходит в следующем порядке (рис. 4.2-2):
1. Ручное извлечение (Extract): ручное открытие проекта - путем запуска приложения САПР (BIM). 
2. Верификация: на следующем этапе обычно запускается несколько плагинов или вспомогательных приложений, предназначенных для подготовки данных и оценки их качества. 
3. Ручное преобразование (Transform): после подготовки начинается собственно обработка данных, которая требует ручного управления различными программными инструментами. 
4. Ручная загрузка (Load): ручная загрузка преобразованных данных во внешние системы и форматы данных.

 Рисунок 4.2-2. Традиционная ручная ETL обработка, ограниченна желаниями, возможностями отдельного технического специалиста

Этот рабочий процесс является примером ETL-процесса - извлечения, преобразования и загрузки (ETL). Однако в отличие от автоматизированных ETL-процессов, распространенных в других отраслях, его ручное исполнение является типичным и распространенным в строительной отрасли. 

   Рисунок 4.2-3. Пример ETL Pipeline по автоматическому получении графика из данных в файле XLSX без открытия Excel
ETL — это аббревиатура, обозначающая три ключевых компонента обработки данных: Extract, Transform и Load (рис. 4.2-3):
● Извлечение (Extract): этот этап включает в себя сбор данных из различных источников. Эти данные могут иметь различный формат и структуру - от изображений до баз данных.
● Преобразование (Transform): на этом этапе данные обрабатываются и преобразуются. Это может включать очистку данных, агрегирование, проверку и любое применение логики процесса. Цель преобразования - привести данные к формату, необходимому для конечной системы.
● Загрузка (Load): заключительный этап, на котором обработанные данные загружаются в целевую систему, документ или хранилище, например в хранилище данных, озеро данных или базу данных. 

   Рисунок 4.2-4. ETL автоматизирует повторяющиеся задачи обработки данных для эффективного анализа и манипулирования данными



Традиционный ручной или полу автоматизированный ETL процесс обработки данных, распространенный сегодня в строительной отрасли, предполагает наличие менеджера данных или руководителя проекта, который вручную управляет процессом и вручную создает отчеты и документы по нему. Такие традиционные методы обработки данных занимают значительное количество времени в условиях, когда рабочий день строго ограничен временными рамками с 9:00 до 17:00.
В большинстве случаев для автоматизации таких процессов компании прибегают к покупке готовых ERP-подобных решений, которые зачастую дополнительно кастомизируются и настраиваются аутсорсинговым вендором. Такой внешний разработчик в конечном итоге определяет эффективность и производительность системы и, как следствие, напрямую влияет на эффективность всего бизнеса компании, которая приобрела такую систему.
Если компания не готова к эксплуатации или покупке комплексной ERP-системы, в которой процессы выполняются в полу автоматизированном режиме, руководство так или иначе начнет автоматизировать процессы компании вне ERP-систем.
В автоматизированной версии того же рабочего процесса ETL (рис. 4.2-4) общий процесс выглядит как модульный код, который начинается с обработки данных и перевода их в открытую структурированную форму. После получения структурированных данных автоматически, по расписанию, запускаются различные сценарии или модули для проверки изменений, преобразования и отправки сообщений. В автоматизированном рабочем процессе обработка данных упрощается за счет предварительной обработки данных ET(L): структурирования и унификации. 
При традиционных методах обработки данных специалисты работают с данными "как они есть", которые извлекаются из систем или программного обеспечения. При автоматизации процессов данные с помощью ETL переводятся в структурированную, пригодную для использования форму перед обработкой.


   Рисунок 4.2-5. Автоматический процесс, в отличие от традиционной ручной обработки, не ограничен желаниями и ограничениями человека
Создадим практический пример ETL, иллюстрирующий процесс проверки таблиц данных, о котором говорилось в главе "Проверка данных и результаты проверки", для чего будем использовать библиотеку Pandas вместе с ChatGPT. 

ETL Extract: сбор данных
Ч
тобы начать работу с данными, мы воспользуемся кодом для сбора массивов данных, которые необходимо проверить. Для этого мы пройдемся по всем папкам рабочего сервера и соберем все документы определенного формата и содержания, а затем преобразуем данные в структурированную форму, что мы подробно рассмотрели в главах "Преобразование неструктурированных и текстовых данных в структурированную форму" и "Преобразование данных САПР (BIM) в структурированную форму".

   Рисунок 4.2-6. Преобразование данных САПР (BIM) в один большой фрейм данных, который будет содержать все разделы проекта.
В качестве наглядного примера можно привести шаг загрузки данных Extract и получения таблицы всех САПР (BIM) проектов с помощью Dynamo, Pandamo (Pandas + Dynamo) для Revit®, IfcOpenShall для IFC. В нашем примере мы будем использовать конвертеры DataDrivenConstruction [31] для форматов Revit и IFC, чтобы получить структурированные таблицы из всех проектов и объединить их в одну большую таблицу DataFrame

   Рисунок 4.2-7. Преобразование всех файлов RVT и IFC в один большой структурированный (df) DataFrame
В Pandas DataFrame можно загружать не только структурированные форматы, но и данные из многих источников данных, включая следующие базы данных: MySQL, PostgreSQL, SQLite, Microsoft SQL Server, Oracle, Google BigQuery, MariaDB, Amazon Redshift, Teradata, IBM Db2, Snowflake, SAP HANA, ODBC-соединения (через SQLAlchemy или PyODBC), о которых мы более подробно говорили в главе "Структурированные данные".
❏ Чтобы подключиться к базе данных, отправьте текстовый запрос на ChatGPT:
"Пожалуйста, напиши пример подключения к MySQL и преобразования данных в DataFrame".
➤ Ответ ChatGPT:

   Рисунок 4.2-8. Пример подключения Pandas к базе данных MySQL и импорта данных из базы MySQL в DataFrame
Загрузив мультиформатные данные в переменную "df", мы собрали и структурировали их в DataFrame, одну из самых популярных структур данных в мире обработки данных, которая представляет собой двумерную структуру, организующую информацию в таблицу со строками и столбцами. О типах других форматов Parquet, Apache ORC, JSON, Father, HDF5 и хранилищах данных мы подробнее поговорим в главе "Современные технологии обработки данных в строительной отрасли".

ETL Transform: применение правил проверки и трансформации
Ч
тобы преобразовать и проверить собранные данные в процессе ETL, мы будем использовать регулярные выражения для проверки согласованности и целостности атрибутов на основе предопределенных правил. Подробнее о RegEx мы говорили в главе "Перевод требований в структурированную форму".
Regex — это ключ к эффективной проверке строковых данных, позволяющий выполнять автоматические проверки по сложным критериям с помощью нескольких строк кода, значительно упрощая процесс проверки данных.
На этапе "Преобразование" (Transform) управления данными о строительстве для примера в системе RPM (Real Property Management) мы в роли менеджера по недвижимости (рис. 4.2-8) используем регулярные выражения (RegEx), для проверки соответствия форматов идентификатора (атрибут "ID"), гарантийного срока и цикла замены (атрибуты "Гарантийный срок" и "Требования к обслуживанию").

   Рисунок 4.2-9. Менеджер, основываясь на опыте, устанавливает требования к атрибутам и их граничным значениям
Например, из нашего опыта мы знаем, что допустимые значения для атрибута "ID" могут включать "W-NEW", "W-OLD1" или "D-122" или аналогичные значения, где первым символом является буква, за которой следует тире, а затем три буквенных символа 'NEW', 'OLD' или любое трехзначное число.


Для выполнения этой проверки можно использовать следующий шаблон RegEx: ^W-NEW$|^W-OLD[0-9]+$|^D-1[0-9]{2}$. Этот шаблон позволяет проверить, все ли идентификаторы в наборе данных соответствуют заданным критериям. Если какое-либо значение не соответствует данному шаблону, это приведет к ошибке.
Чтобы создать Python-код для преобразования данных и использовать полученные данные для создания таблицы результатов, просто сформулируйте запрос к ChatGPT.

❏ Отправьте текстовый запрос в ChatGPT:
Напиши код для проверки столбцов DataFrame с помощью регулярных выражений, которые проверяют идентификаторы в формате 'W-NEW' или 'W-OLD', энергоэффективность с буквами от 'A' до 'G', гарантийный срок и цикл замены с числовыми значениями в годах ⏎.
➤ Ответ ChatGPT:

   Рисунок 4.2-10. Автоматизация проверки путем применения шаблонов RegEx

Приведенный выше автоматически созданный Python-код использует библиотеку “re“ (регулярные выражения RegEx) для определения функции, которая проверяет каждый атрибут элемента данных в pandas DataFrame. 
Для каждого указанного столбца (атрибута) функция применяет шаблон RegEx для проверки соответствия каждой записи ожидаемому формату и добавляет результаты в виде новых значений (False/True) в новый атрибут столбца DataFrame.
Собрав и преобразовав данные, остается только выгрузить результаты в нужный нам формат – документ, график или приборную панель.

ETL Load: Визуализация результатов в виде диаграмм и графиков
П
олучив ответ в табличной форме (DataFrame), мы можем визуализировать преобразованные сущности, в частности их атрибуты, и показать их вместо цифр и таблиц - в виде приборной панели или набора графиков и диаграмм.
Для визуализации результатов проверки из предыдущей главы (рис. 4.2-9) мы используем библиотеку Matplotlib языка программирования Python (рис. 4.2-10, рис. 4.2-11), которая считается одним из основных инструментов для создания статических, анимированных и интерактивных визуализаций на Python. Чтобы получить код для этой задачи, запрос к ChatGPT можно сформулировать следующим образом.
❏ Текстовый запрос ChatGPT:
Напиши код для визуализации данных DataFrame, приведенных выше, с гистограммой для результатов. ⏎








➤ Ответ ChatGPT:


   Рисунок 4.2-11. Визуализация результатов по проверки значений 4 атрибутов из системы RPM (рис. 4.2-8) в виде гистограммы





❏ Текстовый запрос ChatGPT:
Изобразите те же данные в виде графика из линий. ⏎
➤ Ответ ChatGPT:

   Рисунок 4.2-12. Визуализация данных проверки в виде линейной диаграммы с помощью библиотеки Matplotlib

Не менее важной для визуализации является библиотека Seaborn (рис. 4.2-12), которая построена на базе Matplotlib и добавляет более продвинутые темы оформления и интерфейс для создания графиков. Seaborn особенно хороша для работы с категориальными данными и может помочь легко выявить закономерности и тенденции в данных.
❏ Отправьте текстовый запрос в ChatGPT:
Покажите тепловую карту для результатов. ⏎
➤ Ответ ChatGPT:


   
   Рисунок 4.2-13. Визуализация результатов проверки данных
 с помощью библиотеки Seaborn



Для тех, кто ищет более современный и интерактивный подход, библиотека Plotly (рис. 4.1-6, рис. 4.2-12) предлагает возможность создания высоко интерактивных диаграмм и панелей, которые можно встраивать в веб-страницы и предоставлять пользователю возможность взаимодействия с данными в режиме реального времени.

   Рисунок 4.2-14. Интерактивная 3D-визуализация атрибутов элементов из САПР (BIM) проекта с помощью Plotly
Кроме того, существуют специализированные инструменты, такие как Bokeh и Dash, которые позволяют создавать детальные интерактивные визуализации и веб-приложения для аналитики данных без необходимости глубоких знаний в области веб-разработки. Эти библиотеки позволяют разработчикам и аналитикам быстро и эффективно распространять свои результаты среди коллег и заинтересованных сторон, упрощая принятие решений на основе данных.

ETL Load: Автоматическое создание PDF-документов
Н
а этапе загрузки мы также можем создавать автоматические отчеты и встраивать в них визуализации и любые данные, которые необходимо получить менеджеру или специалисту, ожидающему результатов проверки. Чтобы создать Python-код, генерирующий PDF-файл с гистограммой и описанием результатов анализа данных, достаточно сформулировать запрос к ChatGPT.

❏ Отправьте текстовый запрос в ChatGPT:
Напиши код для создания PDF-файла с гистограммой и описанием результатов проверки данных, которые были получены выше, и Напиши предупреждение в виде текста о том, что некоторые категории не прошли проверку и что необходимо заполнить недостающие данные. ⏎
➤ Ответ ChatGPT:


   Рисунок 4.2-15. Создание PDF-документа, содержащего гистограмму с тестовыми данными и текст с результатами проверки
Автоматически написанное решение, всего из 20 строк кода, с помощью ChatGPT мгновенно создает документ, с визуализацией в виде гистограммы атрибутов, показывающей количество данных, прошедших и не прошедших проверку, а также с добавлением текстового блока краткого описания результатов и рекомендациям по дальнейшим действиям.

ETL Load: Составление отчетов и загрузка в другие системы
Н
а этапе Load мы уже выгрузили результаты трансформации-проверки в виде таблиц, графиков и отчета в формате PDF и теперь экспортируем результат в формат CSV для дальнейшей интеграции с ERP-системами или другими приложениями. Мы также можем выгрузить результат в другие распространенные форматы - XLSX, JSON, XML или загрузить обновленные или новые данные непосредственно в базу данных нужной нам системы.
❏ Отправьте текстовый запрос в ChatGPT:
Напиши код для создания отчета о результатах проверки данных в DataFrame, в котором столбцы с префиксом 'verified_' подсчитываются, переименовываются в 'Passed' и 'Failed', пропущенные значения заменяются на 0, а затем экспортируются в CSV-файл только те строки, которые прошли все проверки.
➤ Ответ ChatGPT:

   Рисунок 4.2-16. Проверенные данные экспортируются в CSV-файл для интеграции с другими системами
В приведенном коде (рис. 4.2-15) последний этап ETL-процесса, "Загрузка", сохраняет проверенные данные в формате CSV, совместимом с внешними системами управления, что позволяет в дальнейшем использовать эти данные в различных операционных процессах.

ETL с помощью ChatGPT: Визуализация данных из PDF-документов
Д
авайте разработаем более полный процесс ETL, описанный одним решением, который поможет специалистам извлекать данные из PDF-документов, анализировать их, а затем интегрировать в другие системы.
Мы предоставим языковой модели ChatGPT ряд запросов для создания кода, который будет автоматически собирать все PDF-файлы, доступные на сервере, извлекать из них данные и преобразовывать их в структурированный формат для дальнейшего анализа и визуализации.




❏ Текстовый запрос в ChatGPT на автоматическое извлечение данных из PDF и создание фрейма данных:
Напиши код для извлечения информации о материалах из PDF-файлов в заданной папке и ее подпапках. Данные в PDF включают название материала, количество и стоимость. Результат необходимо сохранить в DataFrame pandas. ⏎

➤ Ответ ChatGPT:

   Рисунок 4.2-17. Python-код для извлечения данных из PDF-файлов в определенной папке и всех ее подпапках 
После выполнения кода (рис. 4.2-16) приложение обходит каждую папку, открывает каждый найденный PDF-файл, извлекает из него текстовую информацию и сохраняет полученные данные в структурированном фрейме данных Pandas.
Полученный в чате код можно запустить в одной из популярных IDE PyCharm, Visual Studio Code (VS Code), Jupyter Notebook, Spyder, Atom, Sublime Text, Eclipse с плагином PyDev, Thonny, Wing IDE, IntelliJ IDEA с плагином Python, JupyterLab или популярных онлайн-инструментах Kaggle.com, Google Collab, Microsoft Azure Notebooks, Amazon SageMaker.
Чтобы упростить процесс, вместо копирования кода из ChatGPT и использования кода в IDE мы можем загрузить десяток PDF-файлов прямо в чат ChatGPT (рис. 4.2-17) и получить на выходе таблицу, без необходимости видеть код или запускать его. Результатом выполнения этого кода будет таблица с выбранными нами атрибутами.
-
   Рисунок 4.2-18. Результат выполнения кода в программе ChatGPT, которая извлекает данные из PDF-файлов в виде датафрейма с выбранными атрибутами
На следующем этапе мы попросим ChatGPT создать несколько примеров визуализации данных, которые послужат основой для анализа.
❏ Запрашивайте ChatGPT для анализа данных и построения графиков:
Визуализируйте общую стоимость и количество каждого материала из DataFrame. ⏎
➤ Ответ ChatGPT:

   Рисунок 4.2-19. Ответ ChatGPT в виде кода Python для визуализации данных из фрейма данных с помощью библиотеки matplotlib
Результатом выполнения кода будет визуализация атрибутов таблицы в том же чате ChatGPT или в терминале программы IDE в виде графиков затрат и использования материалов в строительных проектах, которые были найдены с помощью кода в PDF-документах.

   Рисунок 4.2-20. Визуализация отклика ChatGPT в виде графиков на основе данных, собранных в DataFrame
Поддержка в разработке идей для написания кода, анализ и выполнение кода, визуализация результатов доступно через простые текстовые запросы в ChatGPT, без необходимости изучать основы программирования. Появление таких инструментов, как ChatGPT, определенно меняет подход к программированию и автоматизации в строительной отрасли.


   Рисунок 4.2-21. ChatGPT помогает формировать черновик кода, который применяется в будущих проектах без необходимости использования ChatGPT
   
   
Используя инструменты, подобные ChatGPT, а также открытые данные и программное обеспечение с открытым исходным кодом, мы можем автоматизировать те процессы, которые ранее осуществлялись только с помощью специализированных, высокозатратных и сложных в обслуживании систем, таких как строительные ERP, EPM, BIM и аналогичные платформы.
Описанная логика выполнения бизнес-задач в процессе ETL, важнейшая часть автоматизации процессов аналитики и обработки данных, является специфической разновидностью более широкого понятия – конвейеров (Pipelines).
REV DAG и Apache Airflow: автоматизация и оркестрация рабочих процессов
Представьте, что вы работаете с большими объемами данных. Каждый день вам нужно:
• Скачивать файлы из разных источников (например, от поставщиков или клиентов).
• Преобразовывать эти данные в нужный формат.
• Отправлять результаты на проверку и создавать отчеты.
Если делать это вручную, это займет много времени и может привести к ошибкам. А что если источник данных изменится? Или если один из этапов не завершится успешно? Вот здесь и приходит на помощь Apache Airflow – инструмент, который помогает автоматизировать такие процессы.
Что такое Apache Airflow?
Apache Airflow – это программа, которая помогает управлять задачами и процессами, связанными с обработкой данных. Можно представить его как "умного ассистента", который следит за тем, чтобы все шаги выполнялись правильно и в нужном порядке.
Основная идея Airflow – описать ваши задачи в виде графа (карты), где каждая задача зависит от другой. Этот график называется DAG (Directed Acyclic Graph) . Давайте разберем, как это работает на простом примере.
Представьте ситуацию: каждый месяц вам нужно:
1. Собрать данные из нескольких Excel-файлов (например, отчеты отделов продаж).
2. Объединить эти данные в один общий файл.
3. Создать на основе этих данных презентацию или PDF-документ.
4. Отправить результаты руководителю.
Если делать это вручную, это займет много времени и может привести к ошибкам. А что если кто-то опоздает с отправкой файла? Или если формат данных изменится? Вот здесь и приходит на помощь Apache Airflow .
Как это работает?
Airflow поможет автоматизировать весь процесс. Мы создадим DAG (Directed Acyclic Graph), который будет описывать последовательность задач:
1. Скачать Excel-файлы из определенной папки.
2. Обработать их, объединить данные в один файл.
3. Создать документ (например, PDF) на основе полученных данных.
4. Отправить результат по электронной почте.


   Рисунок 4.2-21. ChatGPT помогает формировать черновик кода, который применяется в будущих проектах без необходимости использования ChatGPT
Что происходит в этом коде?
1. Чтение Excel-файлов :
• Мы проходим по всем файлам в указанной папке.
• Считываем данные из каждого файла с помощью библиотеки pandas.
• Объединяем данные в один DataFrame.
2. Создание PDF-документа :
• Преобразуем объединенный DataFrame в HTML-таблицу.
• Сохраняем таблицу в виде PDF-файла (в данном случае для простоты используем HTML).
3. Отправка email :
• Используем оператор EmailOperator для отправки PDF-документа по электронной почте.
4. Настройка DAG :
• Указываем порядок выполнения задач: сначала собираем данные, затем создаем PDF, потом отправляем email.
• Задаем расписание выполнения (@monthly – каждое первое число месяца).

Как это выглядит в Airflow?
Когда DAG запускается, вы можете наблюдать за его выполнением через веб-интерфейс Airflow:
1. Зеленый цвет : Задача успешно завершена.
2. Желтый цвет : Задача выполняется.
3. Красный цвет : Задача завершилась с ошибкой.
Если возникает проблема, например, файл не был найден или данные некорректны, Airflow автоматически отправит уведомление.

Почему это удобно?
1. Автоматизация : Вы больше не тратите время на ручное выполнение повторяющихся задач.
2. Надежность : Если что-то пойдет не так, Airflow сразу сообщит об ошибке.
3. Гибкость : Можно легко добавлять новые задачи или менять существующие.

Apache Airflow – отличный инструмент для автоматизации рабочих процессов, связанных с данными. В нашем примере мы показали, как можно собирать данные из Excel-файлов, создавать PDF-документ и отправлять его по email. Это лишь один из множества возможных сценариев использования Airflow.
Теперь вы знаете, как создать свой первый DAG для работы с Excel! Попробуйте адаптировать этот пример под свои задачи и увидите, как Airflow может упростить вашу работу.
В дополнение к Apache Airflow, существуют другие инструменты для оркестрации рабочих процессов. Например, Prefect предлагает более простой синтаксис и лучше интегрируется с Python, что делает его отличным выбором для команд, уже использующих этот язык. Luigi, разработанный Spotify, предоставляет похожую функциональность и хорошо работает с большими данными. Также стоит отметить Kronos и Dagster, которые предлагают современные подходы к созданию пайплайнов с фокусом на модульность и масштабируемость. Выбор инструмента зависит от конкретных потребностей проекта, но все они помогают автоматизировать сложные процессы обработки данных.
Помните: Автоматизация – это ключ к успеху, а создание  Pipeline – ваш надежный помощник!
REV Apache Nifi для маршрутизации и преобразования данных





ГЛАВА 4.3 
АВТОМАТИЧЕСКИЙ ETL КОНВЕЕР (PIPELINES) ДЛЯ ВАЛИДАЦИЯ ДАННЫХ 

Автоматический конвейер данных -ETL
ETL традиционно ассоциируется с задачами обработки данных для аналитики и включает в себя как структурированные, так и неструктурированные данные.
С другой стороны, Pipeline (конвейер) — это более общая концепция, которая может применяться в различных контекстах, включая обработку данных, но не ограничиваясь ею.
Pipeline описывает любую последовательность обработки, в которой выход одного этапа является входом для следующего. Это можно применить не только к данным, но и к потокам задач, операциям в программном обеспечении и другим процессам.




   Рисунок 4.3-1. Pipeline — это последовательность обработки, в которой выход одного этапа становится входом для следующего этапа.
   
Использование Pipeline - ключевой элемент управления при автоматизации процессов и обработке данных. Pipeline позволяют организовать сложные последовательности обработки данных в удобоваримый, последовательный и модульный формат. Это не только улучшает читаемость и поддержку кода, но и значительно упрощает отладку и тестирование различных этапов обработки данных.


   Рисунок 4.3-2. Pipeline процесса проверки данных сокращает время выполнения по сравнению с обработкой при помощи инструментов САПР (BIM) [34]
Автоматизированные конвейерные процессы (рис. 4.1-8) по скорости работы значительно превосходят традиционные методы обработки данных в закрытых приложениях или дорогих и сложных ERP-системах и могут быть настроены на автоматическое выполнение задач (рис. 4.1-7). 
Автоматизация рабочих процессов не только повышает производительность команды, высвобождая время для более значимых и менее рутинных задач, но и служит первым важным шагом на пути внедрения технологий искусственного интеллекта (ИИ) в бизнес-процессы, о чем мы подробнее расскажем в главе "Будущее: Прогнозы и машинное обучение".

REV Процесс проверки данных Pipeline-ETL с помощью ChatGPT
В
 главах "Создание требований и проверка данных" и "Автоматизация ETL и процессов" мы рассмотрели процесс создания требований и проверки данных, который разбит на отдельные блоки кода.
Мы подробно рассмотрели каждый из этапов процесса ETL, и теперь нам предстоит собрать эти отдельные блоки процесса в один связанный, всеобъемлющий код, который выполняет все этапы ETL в едином коде приложения – Pipeline конвейере данных. 
В ходе работы с данными строительных проектов критически важно обеспечивать их качество. Ошибки в данных могут приводить к неверным расчетам, задержкам и даже финансовым потерям. Чтобы минимизировать эти риски, следует проводить систематические проверки. Ниже представлены ключевые категории проверок, которые помогают поддерживать надежность данных:
1. Актуальность – данные должны описывать события в нужном временном интервале. Это гарантирует, что информация остается релевантной и отражает текущую ситуацию.
2. Доступность – данные должны быть легко доступны в требуемом формате. Это ускоряет их использование и делает возможным их интеграцию в другие процессы.
3. Полнота – важно, чтобы в данных присутствовала вся необходимая информация для конкретного бизнес-процесса. Недостающие данные могут привести к ошибкам в расчетах и интерпретации.
4. Согласованность – данные не должны противоречить друг другу. Несогласованные данные вызывают неопределенность и усложняют принятие решений.
5. Точность – информация должна быть корректно заполнена и соответствовать эталонным значениям. Это снижает вероятность ошибок в дальнейшем анализе.
Для каждой из этих проверок необходимо разработать SQL-запросы, формализовать их бизнес-логику и определить каналы оповещения при обнаружении аномалий или несоответствий.
В следующем примере мы создадим автоисполняемый цикл обработки данных в виде Pipeline кода для рассмотренного ранее примера: от загрузки и проверки данных до создания и экспорта структурированных отчетов в формате PDF.
❏ Чтобы получить код, запрос ChatGPT должен быть сформулирован примерно так:
Пожалуйста напиши пример кода, который выполняет загрузку данных из CSV, проверку данных DataFrame с помощью регулярных выражений, проверяет идентификаторы в формате 'W-NEW' или 'W-OLD', энергоэффективность с буквами от 'A' до 'G', гарантийный срок и цикл замены с числовыми значениями в годах и в конце создает отчет с подсчетом пройденных и проваливших проверку значений, генерирует PDF с гистограммой результатов и добавляет текстовое описание. ⏎












➤ Ответ ChatGPT:

   Рисунок 4.3-3. Pipeline автоматизирует полный цикл обработки данных, от загрузки и проверки до создания структурированного отчета в формате PDF

Прозрачность и структурированность процесса проверки данных Pipeline, разбитого на самостоятельные модули, с визуализацией и представлением результатов в легкодоступном формате, делают этот метод одним из наиболее эффективных для комплексного анализа и управления качеством данных в строительной отрасли.
Автоматизация с помощью конвейеров данных позволяет стандартизировать процессы, сделать их многократно используемыми и легко настраиваемыми. Будь то проверка соответствия данных стандартам, создание отчетов или интеграция с другими системами, конвейеры данных обеспечивают единый подход к обработке информации, минимизируя человеческий фактор и повышая точность результатов.

Pipeline-ETL: проверка данных и информации элементов проекта в САПР (BIM)
С
истемы автоматизированного проектирования (BIM) являются одними из самых динамичных и сложно структурированных баз данных в строительных компаниях. Приложения САПР (BIM), обогащающие проекты геометрической и текстовой информацией, включают объемные и текстовые атрибуты для группировки элементов. Эти дополнительные информационные слои играют ключевую роль в автоматизации процессов в ERP-системах строительных компаний, о которых мы говорили в предыдущих главах, посвященных калькуляции затрат, составлению графиков и оценке углеродных выбросов.
Атрибуты сущностей проекта, созданные в отделах САПР (BIM), служат основой для многих бизнес-процессов компании, а эффективность и скорость проверки качества данных в системах САПР (BIM) играют ключевую роль в успехе многих организационных процессов.
Традиционная ручная проверка атрибутов сущностей большого количества проектов САПР (BIM) не только утомительна, но и устарела в эпоху цифровизации. При нынешней лавине проектных моделей процесс проверки проектов в специализированных инструментах САПР (BIM) может занимать дни и даже недели. В конечном итоге процесс валидации данных становится узким местом в рабочих процессах, связанных с данными из моделей для всей компании.

Благодаря автоматизации и использованию структурированных форм данных и структурированных требований производительность проверки возрастает многократно (рис. 4.3-4). 

   Рисунок 4.3-4. Автоматизация увеличивает скорость проверки и обработки данных, что снижает стоимость работ в несколько раз
В ходе сбора данных для строительного проекта менеджеры генерального подрядчика сталкиваются с большим количеством поставщиков данных: проектировочных, архитектурных и инженерных бюро. Эти поставщики предоставляют на ежедневной или еженедельной основе новые версии или фрагменты одного и того же проекта в разнообразных форматах, требующих регулярной проверки на качество. 
Процесс проверки включает выгрузку данных из различных закрытых (RVT, DWG, DGN, NWS и др.) или открытых полуструктурированных и параметрических форматов (IFC, CPXML), в которых к каждому атрибуту и его значениям должны быть применены таблицы правил с использованием регулярных выражений RegEx (рис. 4.3-5). Создание отчета об ошибках и успешно проверенных записях должно завершаться выводом, учитывающим только проверенные сущности, которые могут быть использованы для дальнейших процессов.

   Рисунок 4.3-5. Процесс проверки данных от поставщиков до конечного результата с помощью регулярных выражений и отчетов о проверке
Автоматизация проверки данных из систем САПР (BIM) при потоковом поступлении новых данных заметно снижает необходимость ручного участия в этом процессе (мы рассмотрели каждый из процессов проверки и составления требований к данным в предыдущих главах). 
Благодаря применению автоматизированных конвейеров пользователи системы, ожидающие качественных данных от САПР (BIM) систем, могут мгновенно получать необходимые им выходные данные - таблицы, документы, изображения - и быстро интегрировать их в свои рабочие задачи (рис. 4.3-6). 


   Рисунок 4.3-6. Автоматизация проверки данных революционизирует управление строительными проектами благодаря ускорению процессов
 и интеграции данных

   Рисунок 4.3-7. Автоматизация проверки атрибутов элементов исключает человеческий фактор и снижает вероятность ошибок
Автоматизация контроля, обработки и анализа приводит к революционным изменениям в управлении строительными проектами, особенно в части взаимодействия различных систем в рамках одной организации, без использования сложных и дорогостоящих ERP-систем или закрытых решений от поставщиков САПР (BIM). 
Атрибуты объема и количества, созданные на этапе проектирования, теперь не только способствуют автоматическому созданию проектной документации, но и становятся основой для последующих операций, от составления бюджета до логистики (рис. 4.3-7).
Непрерывный поток информации между различными отделами и процессами приводит к прозрачности процессов и глубокому сотрудничеству между командами, улучшая общую координацию и управление проектом. В результате руководство и менеджмент могут мгновенно реагировать на любые изменения в проекте.

Новые концепции ETL - AIA, BEP, IDS, LOD, COBie
В
 середине 2000-х годов строительная отрасль столкнулась с беспрецедентной проблемой, связанной с быстрым увеличением объема данных в системах управления и обработки данных, особенно тех, которые поступали из отделов САПР (BIM). Такой резкий рост объема данных застал руководителей и менеджеров компаний врасплох, и они оказались не готовы к растущим требованиям к качеству данных и управлению ими.
Пользуясь отсутствием открытых решений и ограниченной конкуренцией на рынке обработки данных, а также используя маркетинговые кампании, связанные с новой аббревиатурой BIM от поставщиков САПР (BIM), новые организации начали создавать новые стандарты и концепции, которые де-юре должны быть направлены на улучшение практики управления данными.
Хотя почти все инициативы, прямо или косвенно поддерживаемые поставщиками САПР (BIM), были направлены на оптимизацию рабочих процессов, они привели к появлению множества стандартов, лоббируемых различными заинтересованными сторонами, что привело строительную отрасль к некоторой двусмысленности и путанице в процессах обработки данных.

Перечислим некоторые из новых стандартов данных, появившихся за последние годы в строительной отрасли:
● BEP (BIM Execution Plan) описывает, как интегрировать и использовать САПР (BIM) в проекте, определяя методы и процессы обработки данных.
● Документ EIR / AIA (Информационные требования заказчика), который готовится заказчиком до объявления тендера и содержит требования к подрядчику в отношении подготовки и предоставления информации. Он служит основой для BEP в соответствующем проекте.
● AIM (Asset Information Model) - часть процесса BIM. После сдачи и завершения проекта модель данных называется "Информационная модель актива" или AIM. Цель AIM - управление, обслуживание и эксплуатация реализованного актива.
● IDS (Information Delivery Specification) определяет, какие данные и в каком формате требуются на разных этапах строительного проекта.
● LOD (Level Of Detail) указывает на уровень детализации САПР (BIM) модели на разных этапах проектирования.
● iLOD — это уровень детализации LOD, с которым информация представлена в BIM-модели. Он определяет, насколько подробной и полной является информация в модели, начиная от базовых геометрических представлений и заканчивая подробными спецификациями и данными.
● eLOD — это уровень детализации LOD отдельных элементов в модели САПР (BIM). Он определяет степень моделирования каждого элемента и связанную с ним информацию, такую как размеры, материалы, эксплуатационные характеристики и другие соответствующие атрибуты.
● APS (Platform Services) и другие продукты от крупных вендоров САПР (BIM), описывают инструменты и инфраструктуру необходимые для создания связанных и открытых моделей данных.

Большинство новых концепций в области обработки данных в строительной отрасли предлагают разнообразные подходы, которые должны быть согласованы с маркетинговыми стратегиями поставщиков САПР, использующих BIM (Building Information Modeling). В результате концепции и некоторые из существующих стандартов строительной отрасли, разработанные и продвигаемые заинтересованными компаниями на протяжении последних десятилетий, часто оказываются избыточными или даже контрпродуктивными в бизнес-процессах компаний, которые теперь вынуждены адаптироваться к новым реалиям. 

   Рисунок 4.3-8. Требования к данным в строительстве сводятся к описанию атрибутов и их граничных значений, описываемых с помощью таблиц
Вместо того чтобы упростить обработку данных, новые концепции чаще порождают дополнительные сложности и споры уже на стадии интерпретации и базовых определений.
Одним из последних примеров новых концепций, является формат IDS (появившийся в 2020 году) который позволяет описать требования к атрибутному составу информационной модели. Требования IDS описывают информацию об атрибутах и их граничных значениях в виде структурированной таблицы (Excel или MySQL), которая затем переводится в разметку полуструктурированного формата XML, называемого специальной аббревиатурой IDS. 
С течением времени в строительной отрасли появляется все больше форматов и методик для контроля и управления данными, хотя данные в строительных проектах, по сути, не отличаются от данных в других сферах. В то время как другие отрасли успешно обходятся стандартизированными подходами к обработке данных, строительство продолжает разрабатывать уникальные требования и концепции.
Вопреки мнению, продвигаемому поставщиками программного обеспечения для САПР (BIM), о том, что работа с данными в строительстве уникальна из-за использования специализированных инструментов, таких как САПР и BIM, форматы данных и методы управления данными в этой отрасли на самом деле не отличаются от аналогичных практик в других отраслях
Количество требований к проектам и форматам САПР (BIM) можно упростить, используя единую таблицу требований с атрибутами-столбцами, подробно описанную в главе "Перевод требований в структурированную форму", без необходимости переводить изначально структурированные требования в не табличные форматы.
Упрощенный подход (рис. 4.3-9), включающий столбцы для идентификаторов сущностей, свойств и граничных значений, позволяет обойтись без преобразования требований в формат IDS-XML, предлагая прямой и менее громоздкий способ обеспечения качества данных, которым пользуются специалисты в других отраслях экономики.

   Рисунок 4.3-9. Требования к данным в других отраслях упрощается 
до описания атрибутов и их граничных значений
Методы и инструменты, используемые для сбора, подготовки и анализа данных в строительстве, не должны принципиально отличаться от тех, что применяются специалистами в других отраслях экономики. 
В то время как концепции и маркетинговые аббревиатуры приходят и уходят, сами процессы проверки требований к данным навсегда останутся неотъемлемой частью корпоративных процессов, так же как требования и проверка влияют на повседневную жизнь людей, которые ежедневно принимают решения на основе старой и новой поступающей информации.

Сравнение проверок качества данных с жизненными потребностями человека
К
ак и в повседневной жизни, мы постоянно сталкиваемся с вопросами проверки данных и принятия решений на основе данных.
Мы ежедневно сталкиваемся с необходимостью принимать решения на основе данных. Это процесс, в котором каждый выбор, будь то стратегический долгосрочный или краткосрочный оперативный, основывается на статистике, анализе информации и тенденциях.
В нашей личной жизни, как и в компании любой отрасли, данные используются для принятия важных решений: выбирая спутника жизни или определяя место жительства, мы невольно создаем в своем сознании двухмерную таблицу, заполненную различными атрибутами. Эти атрибуты, будь то личные качества партнера или характеристики будущего места проживания, играют ключевую роль в принятии решений.

   Рисунок 4.3-10. Выбор места жительства, работы или партнерства основывается на индивидуальных требованиях к атрибутам
Использование структурированных данных и структурированного представления о требованиях (рис. 4.3-10) как в работе, так и в личной жизни, помогает нам быстрее принимать обоснованные и удовлетворяющие нас решения.

   Рисунок 4.3-11. Жизненные ситуации, проходя через атрибутивные требования к жизненным сущностям и процессам, создают субъективную точку зрения

Подход к принятию решений, основанный на данных, распространен не только в профессиональной сфере, но и в нашей личной жизни (рис. 4.3-12):

● Данные как основа (Extract): в бизнесе или в личной жизни, в обоих случаях мы постоянно находимся в процессе сбора и анализа информации. На работе это могут быть отчеты и показатели, а в личной жизни - личный опыт, советы родителей, отзывы и субъективные исследования.
● Критерии оценки (Transform): в профессиональной среде или личной жизни мы устанавливаем похожие критерии, по которым оцениваем различные варианты. В бизнесе это могут быть KPI и показатели рентабельности, а в личной жизни - такие атрибуты, как стоимость, инфраструктура для выбора жилья, харизма и многие другие критерии для выбора партнера для дружбы или совместной жизни.
● Прогнозирование и анализ рисков (Load): В обоих случаях мы принимаем решение на основе собранных данных, которые пропускаем через фильтр критериев и требований, подвергаем оценке потенциальных рисков и возможных последствий, подобно тому, как принятие решений происходит в бизнес-процессах компании.
 

   Рисунок 4.3-12. Бизнес и жизнь в целом — это серия решений, основанных на данных, где качество данных, используемых для принятия решений, является ключевым фактором
Решения, которые мы принимаем - от банальных предпочтений вроде того, что съесть на завтрак, до важных жизненных событий вроде выбора карьеры или спутника жизни, - по своей сути основаны на данных.
Все в нашей жизни взаимосвязано, и как живые организмы, включая человека, следуют законам природы, эволюционируя и приспосабливаясь к меняющимся условиям, так и человеческие процессы, включая методы сбора и анализа данных, отражают эти природные принципы. Тесная взаимосвязь между природой и деятельностью человека подтверждает не только нашу зависимость от природы, но и желание применять законы, отшлифованные миллионами лет эволюции, в разработке архитектурных процессов и систем для принятия решений.
Новые технологии, особенно в строительстве, - яркий пример того, как человечество каждый раз вдохновляется природой для создания лучших, более устойчивых и эффективных решений.

ГЛАВА 4.4 
СОВРЕМЕННЫЕ ТЕХНОЛОГИИ РАБОТЫ С ДАННЫМИ В СТРОИТЕЛЬНОЙ ОТРАСЛИ
Все во Вселенной состоит из мельчайших строительных блоков - атомов и молекул, и со временем все живое и неживое неизбежно возвращается в это исходное состояние. В природе этот процесс происходит с поразительной скоростью, которую мы пытаемся перенести на процессы, управляемые человеком.
В лесу любые живые организмы со временем превращаются в питательную субстанцию, которая служит основой для новых растений. Эти растения, в свою очередь, становятся пищей для новых живых существ, состоящих из тех же атомов, которые миллионы лет назад создали Вселенную.
В мире бизнеса также важно разбивать сложные структуры на наиболее фундаментальные, минимально обрабатываемые единицы - подобно атомам и молекулам в природе. Таким образом, мы можем эффективно хранить данные и управлять ими, превращая их в богатую, плодородную основу, которая становится жизненно важным ресурсом для принятия решений и разработки решений.
Для эффективной обработки и использования данных крайне важно выбрать подходящий формат и решения для хранения - почву для деревьев систем. Хранилища данных должны тщательно поддерживаться, обеспечивая наполнение почвы высококачественными, актуальными данными, а не бесполезным или вредным "хламом". Качественные данные, найденные в информационной почве компаний, позволяют пользователям эффективно отвечать на свои запросы и решать аналитические задачи.
В условиях столь стремительного роста информации традиционные методы хранения, обработки и анализа данных становятся неэффективными. В строительстве уже невозможно полагаться только на бумажные чертежи и локальные базы данных — необходимо переходить к интегрированным цифровым платформам, использованию больших данных и автоматизированным аналитическим системам.


Форматы хранения данных и работа с Apache Parquet
Д
ля анализа и обработки данных, включающих такие операции, как фильтрация, группировка и агрегирование, в приведенных примерах мы использовали Pandas DataFrame, популярный формат для работы с данными. Pandas DataFrame предназначен для эффективной работы с данными в оперативной памяти, но у него нет собственного формата хранения данных. Поэтому, закончив работу с данными, мы экспортируем DataFrame в различные табличные форматы, включая XLSX и CSV. 
Эти форматы обеспечивают совместимость с внешними системами, но недостаточно эффективны с точки зрения объема хранимых данных и возможности версионирования:
• CSV (Comma-Separated Values): Простой текстовый формат, широко поддерживаемый различными платформами и инструментами. Он прост в использовании, но не поддерживает сложные типы данных и сжатие.
• XLSX (Excel Open XML Spreadsheet): Формат файлов Microsoft Excel, поддерживающий такие сложные функции, как формулы, диаграммы и стилизация. Хотя он удобен для ручного анализа и визуализации данных, он не оптимизирован для крупномасштабной обработки данных.
Существует несколько популярных форматов (рис. 4.4-1) для эффективного хранения данных, каждый из которых обладает уникальными преимуществами в зависимости от конкретных требований к хранению и анализу данных:
• Apache Parquet: формат файлов для колоночного хранения данных, оптимизированный для использования в системах анализа данных. Он предлагает эффективные схемы сжатия и кодирования данных, что делает его идеальным для сложных структур данных и обработки больших данных.
• Apache ORC (Optimized Row Columnar - оптимизированная колонна строк): подобно Parquet, ORC обеспечивает высокую степень сжатия и эффективное хранение данных. Он оптимизирован для тяжелых операций чтения и хорошо подходит для хранения озер данных. 
• JSON (JavaScript Object Notation): хотя JSON не так эффективен с точки зрения хранения данных по сравнению с двоичными форматами, такими как Parquet или ORC, он очень доступен и прост в работе, что делает его идеальным для сценариев, где важна читабельность и совместимость с веб-технологиями.
• Feather: быстрый, легкий и простой в использовании формат хранения бинарных колоночных данных, ориентированный на аналитику. Он разработан для эффективной передачи данных между Python (Pandas) и R, что делает его отличным выбором для проектов, в которых задействованы эти среды программирования.
• HDF5 (Hierarchical Data Format version 5 - Иерархический формат данных версии 5): предназначен для хранения и организации больших объемов данных. Он поддерживает широкий спектр типов данных и отлично подходит для работы со сложными коллекциями данных. HDF5 особенно популярен в научных вычислениях благодаря своей способности эффективно хранить и получать доступ к большим наборам данных.




   Рисунок 4.4-1. Сравнение форматов данных с указанием основных 
различий в аспектах хранения и обработки
Возьмем для примера формат Apache Parquet — это свободно распространяемый формат хранения данных на основе столбцов (подобный Pandas), оптимизированный для работы с большими объемами данных. 
Apache Parquet предназначен для эффективного и компактного хранения данных по сравнению с традиционными реляционными базами данных или текстовыми форматами хранения, такими как CSV. 
Ключевые особенности Parquet включают поддержку сжатия и кодирования данных, что значительно уменьшает размер хранилища и ускоряет операции чтения данных за счет работы непосредственно с нужными столбцами, а не со всеми строками данных.



Для наглядного примера того, как легко получить необходимый код для преобразования данных в Apache Parquet, давайте воспользуемся ChatGPT.
❏ Отправьте текстовый запрос в ChatGPT:
Напиши код для сохранения данных из Pandas DataFrame в Apache Parquet. ⏎
➤ Ответ ChatGPT:

   Рисунок 4.4-2. Передача данных Dataframe из оперативной памяти в эффективный для хранения и отслеживания версий формат Apache Parquet



Давайте смоделируем процесс ETL с данными, сохраненными в формате Parquet для фильтрации проектов по определённому значению одного из атрибутов.
❏ Отправьте текстовый запрос в ChatGPT:
Предположим, мы хотим отфильтровать данные и сохранить только те проекты из Apache Parquet, стоимость которых превышает 150 миллионов долларов. ⏎

➤ Ответ ChatGPT:

   Рисунок 4.4-3. Процесс ETL при работе с данными в формате Apache Parquet
Созданный для обеспечения высокоэффективных схем сжатия и кодирования данных, формат Parquet значительно сокращает пространство для хранения и повышает производительность операций поиска данных, что делает его идеальным выбором как для хранения, так и для обработки и анализа данных. Он повышает скорость выполнения запросов и легко интегрируется с различными системами обработки данных, повышая эффективность хранения, доступа и анализа в гибридных архитектурах.
Parquet, формат файлов для колоночного хранения данных, отлично подходит для управления огромными объемами данных в моделях Lakehouse, объединяющих озера данных и хранилища. 
REV DWH хранилища данных и архитектура Data Lakehouse
М
узыкальные композиции состоят из нот, которые, соединяясь, создают сложные музыкальные произведения, а слова создаются из примитивной единицы - буквы-звука. Будь то природа, наука, экономика, искусство или технология, мир демонстрирует удивительное единство и гармонию в своем стремлении к разрушению, структуре, цикличности и созиданию.
Точно так же процессы в системах калькуляции себестоимости разбиваются на мельчайшие структурированные единицы - статьи ресурсов - на уровне калькуляций и расписаний. Затем эти единицы используются для формирования более сложных расчетов и графиков. По такому же принципу работают системы автоматизированного проектирования (BIM), в которых сложные архитектурные и инженерные проекты строятся из базовых элементов - отдельных мельчайших элементов или библиотечных компонентов, из которых создается полная 3D-модель сложного здания или сооружения.
Мельчайшие элементы с их конечной неделимостью являются основными строительными блоками всех бизнес-процессов. Важно с самого начала тщательно продумать, как собирать и хранить эти мельчайшие строительные блоки из различных источников. Также необходимо будет принять решение между такими подходами, как хранилища данных (DWH - Data Warehouses) и озера данных (DL- Data Lakehouse). 

   Рисунок 4.4-4. Сравнение процессов ETL и ELT

Впервые эти вопросы возникли в телекоммуникационной отрасли, затем стали актуальны для финансовых организаций, а теперь с подобными проблемами столкнутся и компании в строительной отрасли.
Концепция цикличности и структурности, присущая природе и науке, находит отражение и в современном мире данных. Как в природе все живые существа возвращаются к атомам и молекулам, так и в мире современных инструментов обработки данных информация стремится перейти к самой примитивной форме. 
Эта идея нашла свое воплощение в архитектуре Data Lakehouse (Озеро данных), где данные, подобно каплям воды, сливаются в единое целое, образуя "озеро" разнородной информации. Разработка концепции Data Lakehouse представляет собой эволюционный шаг в области управления данными, возникший на пересечении Хранилищ данных и Озер данных.
• В традиционных хранилищах данных данные обычно проходят предварительную обработку, преобразование и очистку (ETL - Extract, Transform, Load) перед загрузкой в хранилище (рис. 4.4-4). Это означает, что данные структурируются и оптимизируются для решения конкретных задач аналитики и отчетности. Основной упор делается на поддержание высокой производительности запросов и целостности данных. Однако такой подход может быть дорогостоящим и менее гибким с точки зрения интеграции новых типов данных и быстро меняющихся схем данных.
• Озера данных, с другой стороны, предназначены для хранения больших объемов необработанных данных в их исходном формате. На смену процессу ETL приходит ELT (Extract, Load, Transform), когда данные сначала загружаются в хранилище "как есть" и только потом могут быть преобразованы и проанализированы по мере необходимости. Это обеспечивает большую гибкость и возможность хранения разнородных данных, включая неструктурированные данные, такие как текст, изображения и журналы.


   Рисунок 4.4-5. Сравнение процессов ETL и ELT
Традиционные хранилища данных ориентированы на предварительную обработку данных для обеспечения высокой производительности запросов, в то время как в озерах данных приоритет отдается гибкости: они хранят необработанные данные и преобразуют их по мере необходимости (рис. 4.4-4). 
Хранилища данных, предназначенные для хранения структурированных данных в формате, оптимизированном для аналитических запросов, столкнулись с ограничениями в работе с неструктурированными данными и масштабируемостью. В ответ на эти проблемы появились озера данных (Data Lakes), предлагающие гибкое хранение больших объемов разнородных данных.

   Рисунок 4.4-6. Современные концепции в мире хранения данных направлены на хранение и обработки всех типов данных


Data Lakehouse — это архитектурный подход, который стремится объединить гибкость и масштабируемость озер данных с управляемостью и производительностью запросов в хранилищах данных (рис. 4.4-6). Ключевые особенности Data Lakehouse включают:
• Открытый формат хранения данных: использование открытых форматов для хранения данных, таких как Parquet (Apache), обеспечивает эффективность и оптимизацию запросов.
• Схема только для чтения: в отличие от традиционного подхода к схеме только для записи в DWH, Lakehouse поддерживает схему только для чтения, что позволяет более гибко управлять структурой данных.
• Гибкость и масштабируемость: поддерживает хранение и анализ структурированных и неструктурированных данных, обеспечивая высокую производительность запросов за счет оптимизации на уровне хранилища.
Таким образом, Data Lakehouse предлагает компромиссное решение, сочетающее преимущества обоих подходов, что делает его идеальным для современных аналитических нагрузок, требующих гибкости в обработке данных.
Data Lakehouse — это синтез озер данных и хранилищ данных, сочетающий гибкость и масштабируемость первых с управляемостью и оптимизацией запросов вторых.


   Рисунок 4.4-7. Data Lakehouse - поколение систем хранения данных, созданных для удовлетворения сложных и постоянно меняющихся требований 
Проблемы озёр данных
Хранилища данных появились для объединения информации из разных систем в единую модель, удобную для отчетности. Данные извлекались, преобразовывались под нужный формат и загружались (ETL). Идея была хорошей, но со временем процесс стал слишком сложным — добавление новых данных теперь занимает месяцы, что вызывает недовольство.
Разочарование в хранилищах и интерес к «большим данным» привели к появлению озер данных. Вместо сложного ETL теперь данные просто загружаются в полуструктурированное хранилище, а их обработка происходит уже на этапе анализа.
Однако этот подход перенес основную нагрузку на аналитиков, которым приходится разбираться в данных самостоятельно. В результате больше времени уходит на поиск и понимание информации, а не на сам анализ. К тому же, бизнес-аналитики, привыкшие работать с инструментами вроде Tableau или QlikView, оказываются за бортом, так как озера данных требуют куда более сложных навыков.
4o
Сегодня многие компании активно внедряют озера данных — большие хранилища, в которых собирается информация из всех возможных источников. Идея кажется простой: если все данные находятся в одном месте, их легче анализировать. Однако на практике все не так гладко.
Представьте, что компания решила полностью отказаться от привычных систем учета и управления, заменив их одним огромным озером данных, к которому у всех есть доступ. Что произойдет? Скорее всего, начнется хаос: данные будут дублироваться, противоречить друг другу, а критически важная информация окажется потерянной или искаженной.
Даже если озеро данных используется только для аналитики, с ним возникают серьезные трудности:
1. Данные сложно понять.
В обычных системах у данных есть четкая структура, а в озере — это просто огромное скопление файлов и таблиц. Чтобы что-то найти, специалисту приходится разбираться, что означает каждая строка и столбец.
2. Безопасность под вопросом.
В компании не все сотрудники должны видеть или изменять любую информацию. Однако многие озера данных не предусматривают четких правил доступа, что создает риски.
3. Данные могут быть неточными.
Если в одном месте хранится много версий одной и той же информации, сложно понять, какая из них актуальна. В результате принимаются решения на основе устаревших или ошибочных данных.
4. Сложно подготовить данные для работы.
Данные нужно не только хранить, но и представлять в удобной форме — в виде отчетов, графиков, таблиц. В традиционных системах это делается автоматически, а в озерах данных требует дополнительной обработки.
Раньше каждая программа сама хранила и обрабатывала данные, но теперь компании хотят перейти к единому, более гибкому решению. Мы рассмотрим примеры тех, кто уже делает это, а также обсудим новые технологии, такие как графовые базы данных и семантические системы, которые помогают упорядочить данные и сделать их действительно полезными.




REV Облачные решения, SaaS, CRUD b
Традиционная модель SaaS, которая революционизировала доставку программного обеспечения, переживает значительные изменения. В условиях экосистем, управляемых ИИ, гиперсвязности и компонуемых архитектур мы наблюдаем сдвиг, способный переосмыслить подход к управлению данными.
Как отметил Сатья Наделла, глава Майкрософт мы движемся от модели CRUD (Create, Read, Update, Delete) к будущему, в котором данные, управляемые ИИ, и контекстуальный интеллект бесшовно повышают продуктивность. 
"Software as a Service is essentially just a thin UI layer on top of a database."
→ SaaS-приложения постепенно сводятся к пользовательскому интерфейсу, взаимодействующему напрямую с базами данных через ИИ-агентов.
Строительная отрасль — не исключение. Эта эволюция трансформирует управление данными, принятие решений и работу команд на всех этапах проекта, от планирования до эксплуатации.
Строительная отрасль исторически начиналась с проприетарных решений для управления данными проектов. Позже стандартизация управления данными и их согласование с РСУБД (реляционными СУБД) и SQL сделали их стандартами де-факто в индустрии. Сегодня большинство систем управления строительными проектами базируются на популярных SQL-решениях — Oracle, MySQL, Microsoft SQL Server или PostgreSQL. Однако традиционная модель управления данными ограничивала возможности отрасли, приводя к созданию типичной архитектуры: объектного моделировщика поверх базы данных SQL.
С переходом к SaaS BIM- и PM-системам необходимость получения одобрения ИТ-отдела для выбора баз данных исчезает. Управление данными становится невидимым для заказчика, что открывает возможность выбора лучших инструментов для конкретных задач. Это ведет к развитию полиглотской персистентности, в рамках которой системы управления строительными проектами используют несколько баз данных и специализированных решений для работы с различными типами информации. Современные строительные платформы выходят за рамки реляционных баз данных, интегрируя различные подходы к хранению и обработке данных.
Сегодня управление данными в строительной отрасли претерпевает "кембрийский взрыв", в котором появляются новые технологии, подходы и инструменты. В отличие от прошлого, когда единственным решением были реляционные базы данных, современные архитектуры предполагают гибкий набор инструментов, включающий графовые базы, NoSQL, time-series базы и другие специализированные решения. Разработчикам BIM/PM необходимо адаптироваться к этой реальности, расширяя свои знания и инструментарий для управления данными в новом цифровом ландшафте.
Также важно отметить, что распространение моделей искусственного интеллекта, таких как языковые модели, может стимулировать развитие гибридных архитектур. Вместо полного отказа от облачных решений, мы можем увидеть интеграцию облачных сервисов с локальными системами управления данными. Например, федеративное обучение (federated learning) позволяет использовать мощные модели ИИ без необходимости перемещения чувствительных данных в облако. Таким образом, компании смогут сохранять контроль над своими данными, одновременно получая доступ к передовым технологиям.
В результате мы можем наблюдать не конец SaaS и облачных решений, а их эволюцию в сторону более гибридных и адаптивных подходов. Будущее строительной отрасли будет основано на сочетании облачных сервисов, локальных решений и интеллектуальных моделей, работающих вместе для создания более эффективных и безопасных систем управления данными.

REV ые базы данных - DataOps и VectorOps
Появление генеративных моделей и, что еще важнее, их широкая доступность, радикально изменили привычный ландшафт информационных технологий. Это не обошло стороной и базы данных. Оказалось, что большие языковые модели (LLM) взаимодействуют с SQL не просто хорошо, а, возможно, даже лучше, чем с большинством других языков программирования. Это открывает новые возможности для реляционных баз данных и усиливает их актуальность.
Например, я использую языковую модель, чтобы упростить взаимодействие неквалифицированного пользователя с базой данных. Пользователь задает вопрос на естественном языке, а затем я дополняю его запрос описанием структуры базы данных и прошу нейросеть построить корректный SQL-запрос.
Параллельно с этим векторные базы данных, которые изначально появились в среде машинного обучения и искусственного интеллекта, становятся востребованными далеко за пределами узкого круга специалистов по обучению моделей. Теперь они находят применение среди тех, кто эксплуатирует большие языковые модели, например, для поиска информации, персонализации контента и аналитики.
Тем, кто занимается базами данных, стоит обратить внимание на векторные хранилища. Их распространение указывает на новый этап в развитии баз данных, где классические реляционные системы и AI-ориентированные технологии начинают переплетаться, формируя гибридные решения будущего.

Инженерия данных развилась в такие специализированные области, как DataOps и VectorOps, чтобы решить проблемы управления данными и векторными вкраплениями, соответственно. С появлением больших языковых моделей (LLM), таких как GPT-4, управление высокоразмерными структурами данных становится все более важным.
LangChain, фреймворк для разработки приложений на основе LLM, интегрируется с процессами DataOps и VectorOps и использует векторные базы данных для создания интерактивных приложений с учетом данных.
Пользователи, разрабатывающие сложные и масштабные AI-приложения, будут применять специализированные базы данных для векторного поиска. В то же время те, кому нужны лишь отдельные AI-функции для интеграции в существующие приложения, скорее выберут встроенные возможности векторного поиска в уже используемых ими базах данных.
Formularbeginn

Formularende


Прежде чем приступить к созданию хранилища данных, необходимо разработать и утвердить на уровне управления данными политику и стандарты управления данными.
DataOps фокусируется на улучшении сотрудничества, интеграции и автоматизации потоков данных в организациях. Внедрение практик DataOps способствует точности, согласованности и доступности данных, что крайне важно для приложений, ориентированных на данные и использующих LLM.
Ключевые технологии DataOps включают Apache Kafka для потоковой передачи данных в режиме реального времени, Apache Airflow для управления рабочими процессами и Apache NiFi для маршрутизации и преобразования данных.
При внедрении DataOps в строительные процессы стоит учитывать четыре фундаментальных аспекта:
1. Люди и инструменты важнее, чем данные
Многие считают, что основная проблема – в разрозненных хранилищах данных. На самом деле, проблема заключается в изолированных командах и инструментах.
В строительстве с данными работают:
• инженеры данных и ETL-разработчики, интегрирующие информацию;
• специалисты по анализу данных и машинному обучению;
• команды визуализации и BI-аналитики;
• эксперты по управлению проектами и контролю качества.
У каждого из них – свой инструментарий. Важно выстроить экосистему, где данные свободно передаются между всеми участниками процесса, обеспечивая единую версию правды.
2. Автоматизация тестирования и поиск системных ошибок
В строительных данных всегда есть погрешности: неточности в моделях, ошибки в расчетах, устаревшие спецификации. Решение – регулярное тестирование данных и устранение повторяющихся ошибок.
Используйте DataOps для внедрения автоматического контроля качества данных:
• создавайте тесты, проверяющие корректность BIM-моделей;
• анализируйте ошибки и выявляйте закономерности;
• фиксируйте и устраняйте системные сбои в каждом спринте.
Чем больше вы автоматизируете проверку данных, тем меньше ошибок перейдет в производственные системы.
3. Данные должны тестироваться так же, как программный код
Большинство строительных приложений – это в первую очередь приложения для работы с данными. Однако часто данные остаются без должного контроля.
Например, если алгоритмы машинного обучения обучены на неточных данных, модели дают неверные прогнозы, что ведет к финансовым потерям.
DataOps требует тестирования данных по тем же принципам, что и программный код:
• проверяйте данные на логические несоответствия;
• создавайте стресс-тесты с экстремальными сценариями;
• отслеживайте влияние данных на прогнозные модели.
Только проверенные данные должны использоваться для принятия решений.
4. Наблюдаемость данных без ущерба для производительности
Мониторинг данных – не просто логирование и сбор метрик, а стратегический инструмент. Чтобы DataOps работал эффективно, наблюдаемость данных должна быть встроена на всех этапах: от проектирования до эксплуатации.
Принцип «Гиппократовой клятвы наблюдаемости» в DataOps: мониторинг не должен замедлять систему. В строительных проектах важно не просто собирать данные, но и делать это без ущерба для скорости работы инструментов.

DataOps в строительстве: от слов к делу
DataOps – это не дополнительная нагрузка для специалистов по данным, а основа их работы. Внедряя DataOps, строительные компании могут перейти от хаотичного управления данными к эффективной экосистеме, где данные работают на бизнес.
Начните с этих шагов:
• объедините команды и инструменты вокруг единого контура данных;
• автоматизируйте тестирование и поиск ошибок;
• внедрите строгий контроль качества данных;
• обеспечьте сквозную наблюдаемость данных.
В мире Data-Driven Construction данные – это не просто хранилища информации, а ключевой инструмент принятия решений. Используйте DataOps, чтобы вывести вашу компанию на новый уровень эффективности.

Управления данными (Data Governance), минимализм данных (Data Minimalism) и болота данных (Data Swamp) 
П
онимание и внедрение концепций управления данными (Data Governance), минимализма данных (Data Minimalism) и предотвращения создания болота данных (Data Swamp) - ключевые факторы успешного управления данными и обеспечения их ценности для бизнеса.

   Рисунок 4.4-8. Одними из ключевых аспектов управления данными являются Data Governance и Data Minimalism
● Управление данными (Data Governance) — это фундаментальный компонент управления данными, обеспечивающий надлежащее и эффективное использование данных во всех бизнес-процессах. Речь идет не только об установлении правил и процедур, но и об обеспечении доступности, надежности и безопасности данных:
○ Определение и классификация данных: четкое определение и классификация сущностей позволяет организациям понять, какие сущности необходимы в компании, и определить, как их следует использовать.
○ Права доступа и управление: разработка политик и процедур доступа к данным и управления ими гарантирует, что только авторизованные пользователи смогут получить доступ к определенным данным.
○ Защита данных от внешних угроз: защита данных от внешних угроз - один из ключевых аспектов управления данными. Сюда входят не только технические меры, но и обучение сотрудников основам информационной безопасности.

● Минимализм данных (Data Minimalism) — это подход к сокращению данных до наиболее ценных и значимых при формировании атрибутов и сущностей (рис. 4.4-8), что позволяет сократить расходы и повысить эффективность использования данных:
○ Упрощение процесса принятия решений: сокращение числа объектов и их атрибутов до наиболее значимых упрощает процесс принятия решений за счет сокращения времени и ресурсов, необходимых для анализа и обработки данных.
○ Фокусировка на важном: выбор наиболее релевантных сущностей и атрибутов позволяет сосредоточиться на информации, которая действительно важна для бизнеса, устраняя шум и ненужные данные.
○ Эффективное распределение ресурсов: минимизация данных позволяет более эффективно распределять ресурсы, снижая затраты на хранение и обработку данных, повышая их качество и безопасность.
Логическая последовательность работы с данными должна начинаться не просто с создания данных (рис. 4.4-8), а с понимания сценариев использования, которые создадут минимальные требования к атрибутам и их граничным значениям, которые, в свою очередь, являются основой для создания необходимых сущностей. 
Подробнее о моделировании данных на концептуальном, логическом и физическом уровне мы говорили в главе "Моделирование данных: концептуальная, логическая и физическая модель".

   Рисунок 4.4-9. Чтобы избежать беспорядка в хранилище данных, начинать процесс создания данных необходимо со сбора требований к атрибутам 
В традиционных бизнес-процессах строительных компаний обработка данных чаще напоминает сброс данных в болото, где сначала создаются данные, а затем специалисты пытаются интегрировать их в другие системы и инструменты. 
● Болото данных (Data Swamp) — это результат неконтролируемого сбора и хранения данных без надлежащей организации, структурирования и управления, в результате чего данные становятся неструктурированными, сложными для использования и малоценными. Как предотвратить превращение озер информации в болота:
○ Управление структурой данных: обеспечение структурированности и классификации данных помогает предотвратить "болото данных", делая их упорядоченными и легкодоступными.
○ Понимание и интерпретация данных: четкое описание происхождения данных, их модификаций и значений гарантирует, что данные будут поняты и интерпретированы правильно.
○ Поддержание качества данных: регулярное обслуживание и очистка данных помогают поддерживать их качество, актуальность и ценность для аналитических и бизнес-процессов.
Интегрируя принципы управления данными и минимализма данных в процессы управления данными, а также активно предотвращая превращение хранилищ данных в болото данных, организации могут максимально использовать потенциал своих данных. 
Симбиотическое сочетание хранения, обработки и управления данными открывает перед компаниями новые горизонты извлечения ценных сведений из Big Data, позволяя не просто накапливать информацию, но и активно использовать ее для стратегического планирования и повышения эффективности бизнес-процессов.
REV Lowcode- no code 
Зрелость подхода, основанного на моделях, является большим благом для сторонников подхода, ориентированного на данные; все больше функциональности системы может быть реализовано без написания дополнительного кода. Мы строили системы без кода приложений (и с очень небольшим количеством архитектурного кода), поэтому мы знаем, что этот подход можно сочетать с подходом, ориентированным на данные. 

REV Параметрическое создание проектов
Одним из примеров Low code является визуальное программирование 


IOT Интернет вещей и смарт-контракты
Интернет вещей (IoT) представляет собой новую волну цифровой трансформации, в рамках которой каждое устройство получает собственный IP-адрес и становится частью глобальной сети. Сегодня умные контроллеры уже встроены в заводское оборудование, автомобили, бытовую технику, но большинство из них работают в изолированных локальных сетях или вовсе не подключены.
Эта ситуация стремительно меняется. Яркий пример — устройства вроде Nest (принадлежащего Google), которые позволяют удаленно управлять климатом в доме через интернет. В ближайшие несколько лет количество подключенных IoT-устройств достигнет десятков миллиардов, а их разнообразие и сложность продолжат расти.
Сложность данных становится серьезным вызовом. Несмотря на усилия международных организаций по стандартизации, множество конкурирующих стандартов лишь усложняют ландшафт IoT. Однако компании могут взять под контроль этот хаос, используя Data-Centric подход.
Хотя IoT-устройств существует бесконечное множество, их функции можно свести к двум основным категориям:
• Датчики — устройства, собирающие данные о мире (температура, влажность, химический состав, электропотребление).
• Исполнительные механизмы — устройства, изменяющие состояние мира (включение отопления, открытие дверей, запуск тревоги).
Вместо того чтобы рассматривать IoT как новую отдельную систему, Data-Centric подход позволяет органично вписать его в существующую бизнес-модель. Устройства IoT — это те же самые активы, что и в системах управления запасами. Здания в IoT — те же объекты, что и в управлении недвижимостью. Информация должна быть единой, чтобы избежать хаоса разрозненных «сильосистем».

Смарт-контракты и блокчейн: автоматизация бизнес-логики
Блокчейн продолжает оставаться на волне популярности, но его наиболее заметное применение — криптовалюты — далеко не единственная возможность технологии. Гораздо больше перспектив открывают смарт-контракты — алгоритмы, автоматически выполняющие условия соглашений при наступлении заданных событий.
Сегодня в отсутствии единой модели данных смарт-контракты представляют собой просто код, который согласовывают участники. Однако при Data-Centric подходе возможно создать общую модель параметров контракта, закодировать ее в блокчейне и автоматизировать выполнение условий.
Например, в системе управления поставками смарт-контракт может отслеживать доставку груза с IoT-датчиков и автоматически переводить оплату при его прибытии. Или в страховании блокчейн-контракт может фиксировать погодные условия и компенсировать ущерб в случае стихийного бедствия без участия посредников.
Data-Centric подход к IoT и блокчейну позволяет избежать хаоса разрозненных данных и создать единую, понятную, прозрачную систему. Вместо того чтобы строить новый сложный технологический мир на отдельных фрагментах информации, его можно сформировать вокруг данных как основного актива.

 REV Большие данные 

Большие данные — это не холодный мир алгоритмов, лишенный человеческого влияния. Напротив, они работают в связке с нашими инстинктами, ошибками и творчеством. Именно несовершенство человеческого мышления позволяет находить нестандартные решения и делать прорывы.
Большие данные — это мощный ресурс, но не универсальный ответ на все вопросы. Они выявляют закономерности и направляют решения, но не всегда объясняют причины. Их сила заключается в масштабе и скорости обработки информации, но без критического мышления и правильного анализа они могут ввести в заблуждение.



Суть больших данных — это прогнозирование. Вопреки распространенному мнению, это не попытка «научить» компьютер мыслить как человек, а применение математических алгоритмов к огромным массивам информации для выявления закономерностей.
В строительстве это уже проявляется:
✔ Предсказание аварий — анализ данных с датчиков техники и рабочих зон позволяет выявлять потенциально опасные ситуации и предотвращать инциденты.
✔ Оптимизация поставок — алгоритмы прогнозируют потребность в материалах, сокращая излишки и задержки.
✔ Умное планирование — системы моделируют возможные риски на основе погоды, загруженности дорог и состояния стройплощадки.
Главное преимущество этих технологий — способность постоянно обучаться и совершенствоваться по мере накопления данных. В ближайшем будущем искусственный интеллект будет не просто помогать строителям, а принимать ключевые решения — от проектирования до эксплуатации зданий.

Термин «большие данные» не имеет четкого определения, но в строительной отрасли его значение становится все более очевидным. Первоначально концепция возникла из-за того, что объем информации превысил возможности традиционных методов обработки. Теперь данные больше не умещаются в локальную память компьютеров, а требуют новых инструментов, таких как распределенные вычисления и облачные технологии.
С развитием цифровых решений в строительстве стали использоваться методы обработки больших данных, аналогичные тем, что применяются в IT-индустрии. Например, технологии BIM (Building Information Modeling) позволяют не только моделировать здания, но и собирать, анализировать и прогнозировать данные на всех этапах жизненного цикла проекта. Благодаря таким инструментам, как Pandas и Apache Parquet, структурированные и неструктурированные данные могут быть объединены, упрощая доступ к информации и снижая потери на анализ.
Однако ключевым изменением становится отказ от строгой причинно-следственной аналитики в пользу корреляций. В эпоху больших данных важно не только знать, почему что-то происходит, но и понимать, какие паттерны поведения материалов, затрат и процессов влияют на результаты проекта. Это позволяет не только минимизировать ошибки при проектировании, но и строить более точные прогнозные модели.

Одной из самых сложных задач в переходе к Data-Centric подходу является инвентаризация данных. Для крупной компании с миллиардными оборотами это может означать управление миллионом различных элементов данных. На первый взгляд, проблему можно решить с помощью репозитория метаданных — единого хранилища, где описаны все данные. Однако на практике это редко приносит реальную пользу.
Основная сложность заключается в том, что миллион элементов данных невозможно охватить в полном объеме. Метаданные, которые должны помогать в управлении информацией, часто оказываются либо слишком скудными, либо тривиальными. Например, если в базе есть поле "Дата заказа", его описание в метаданных может звучать как "Это дата заказа". Очевидно, что такая информация бесполезна. Гораздо ценнее было бы указать, о какой именно дате идет речь: дате размещения, дате вступления в силу или дате, которая запускает обязательства.
Еще одна проблема — отсутствие информации о реальном использовании данных. Часто невозможно понять, используется ли конкретное поле на практике, является ли оно статичным или может изменяться. Названия элементов данных тоже редко дают четкое представление о сути информации.
Эта хаотичность мешает эффективному управлению данными. Чтобы инвентаризация работала, необходим более осмысленный подход к метаданным, который выходит за рамки простых описаний. Только так можно превратить необозримую массу данных в структурированный, понятный и управляемый ресурс.

Один из ключевых этапов профилирования данных — построение гистограмм для каждого столбца в каждой таблице. Гистограмма представляет собой сводный подсчет частоты встречаемости значений, что позволяет быстро выявить ключевые закономерности в данных.
Например, если в столбце каждое значение встречается только один раз, это, скорее всего, первичный ключ или другой уникальный идентификатор, такой как номер социального страхования. Если же два столбца из разных таблиц или даже разных баз данных имеют схожие гистограммы, велика вероятность, что они содержат одни и те же данные или тесно связаны между собой.
Некоторые инструменты профилирования данных идут дальше и пытаются автоматически определить вероятную семантику данных, снижая нагрузку на аналитиков. Вместо ручного изучения тысяч столбцов система предлагает первые гипотезы о том, что они означают. Такой подход может ускорить анализ данных в разы, освобождая специалистов от рутинной работы и позволяя сосредоточиться на более сложных задачах.


Статистика
В строительной аналитике интуитивно кажется, что чем больше данных, тем точнее прогнозы. Однако еще в 1934 году статистик Ежи Нейман доказал, что ключ к точности — не размер выборки, а её случайность.
Это меняет подход к анализу данных в строительстве. Вместо того чтобы накапливать бесконечные объемы информации, достаточно правильно организовать выборку. Например, случайные точки мониторинга на стройплощадке могут дать более точную картину состояния объекта, чем полный, но несбалансированный набор данных.
После определенного объема данных каждая новая единица информации дает все меньше полезного результата. Вместо бесконечного сбора информации важно сосредоточиться на её репрезентативности и методах анализа.
Раньше строительство основывалось на гипотезах и опыте: инженеры предполагали, как поведет себя материал, какие нагрузки выдержит конструкция и как долго продлится проект, а затем проверяли эти предположения на практике. С появлением больших данных подход меняется — теперь решения принимаются не на основе догадок, а на основе анализа огромных массивов информации.
Современные алгоритмы могут прогнозировать срок службы здания, выявлять слабые места в проекте и даже предсказывать риски еще до начала строительства. Датчики фиксируют колебания грунта, изменение температуры и уровень вибрации, а система анализирует эти параметры, выдавая точные рекомендации. Вместо поиска подтверждений гипотез мы получаем готовые ответы, основанные на реальных данных.
Чем больше информации, тем точнее прогнозы. Строительство перестает быть искусством интуиции и становится наукой точных предсказаний.




Применение больших данных в строительстве
В
ладение большими массивами структурированных данных - это ключ к миру Больших Данных (Big Data) - области, где современные технологии позволяют объединять и анализировать огромные объемы информации.
Большие данные — это внушительный объем информации, который может включать в себя все: от данных датчиков грузовых лифтов (рис. 4.4-9) до метеорологических сводок со строительной площадки. При правильном использовании Большие данные становятся основой для аналитики, прогнозного моделирования и принятия решений.
Большие данные оказывают трансформирующее воздействие на строительную отрасль, влияя на неё различными способами. Вот несколько примеров такого влияния:
• Анализ инвестиционного потенциала: использует показатели прошлых проектов для прогнозирования прибыльности и окупаемости будущих проектов.
• Предиктивное обслуживание: использует исторические данные для прогнозирования отказов оборудования до их возникновения, сокращая время простоя.
• Оптимизация цепочки поставок: оптимизация доставки материалов и прогнозирование сбоев в цепочке поставок.
• Анализ энергоэффективности: помогает проектировать здания, потребляющие меньше энергии.


• Мониторинг безопасности: использование носимых устройств и датчиков для мониторинга безопасности работников и условий окружающей среды на объекте.
• Контроль качества: контролирует строительные процессы в режиме реального времени для обеспечения соответствия стандартам и нормам.
• Управление трудовыми ресурсами: анализирует производительность и прогнозирует потребности в рабочей силе, чтобы оптимизировать распределение человеческих ресурсов.
• Анализ данных из САПР (BIM): улучшает планирование и управление, позволяя избежать конфликтов при проектировании и проблем с обслуживанием.
Трудно найти область в строительстве, где аналитика данных была бы не востребована. Аналитика подразумевает сбор данных, причём чем больше данных собрано, тем выше качество аналитических выводов и точность прогнозов. Следовательно, аналитика, анализ данных и принятие на их основе решений тесно связаны с концепцией больших данных.


   Рисунок 4.4-10. IOT-устройства или устройства передачи данных на строительной площадке могут производить до 1 терабайта данных в день
В области больших данных ключевым навыком является преобразование данных различных форматах в структурированную форму, их очистка и подготовка к анализу, а также умение выявлять значимые идеи и формулировать соответствующие вопросы для их визуализации и анализа. Давайте рассмотрим примеры аналитики и прогнозирования на основе публичных наборов данных с использованием инструментов больших данных.


Pandas и библиотеки по работе с колончатыми данными






Большие данные: анализ данных датасета миллиона разрешений на строительство Сан-Франциско
О
бщедоступные данные о более чем миллионе разрешений (рис. 4.4-10) на строительство (записи в двух наборах данных) из "Департамента зданий Сан-Франциско" [29] позволяют нам использовать сырую CSV таблицу для анализа не только строительной активности в городе, но и для критического анализа последних тенденций и истории строительной отрасли Сан-Франциско за последние 40 лет, с 1980 по 2019 год.
Примеры кода, использованные для создания визуализаций атрибутов сущностей (рис. 4.4-11 - 4.4-15), а также визуальные графики с кодом, пояснениями и комментариями можно найти на платформе Kaggle по запросу "Сан-Франциско. Строительный сектор 1980-2019 гг.".

   Рисунок 4.4-11. Наборы данных содержат информацию о выданных разрешениях на строительство с различными атрибутами объектов

   Рисунок 4.4-12. Тепловая карта (Pandas и Seaborn), визуализирующая столбцы атрибутов сущности и помогающая выявить взаимосвязи между парами атрибутов
Из таблицы, предоставленной Департаментом зданий Сан-Франциско, не видно никаких тенденций или выводов. Сухие цифры не являются основой для принятия решений. Чтобы сделать данные визуально понятными, как мы обсуждали в главе "Визуализация данных", они были визуализированы с помощью различных библиотек из главы "Загрузка ETL: визуализация результатов в виде графиков".
Проанализировав данные, с помощью Pandas DataFrame и библиотек для визуализации Python, о стоимости 1 137 695 разрешений [29], можно сделать вывод, что строительная активность в Сан-Франциско тесно связана с экономическими циклами, особенно в бурно развивающейся технологической отрасли Силиконовой долины. 
Экономические бумы и спады оказывают значительное влияние на количество и стоимость строительных проектов. Например, первый пик строительной активности совпал с бумом электроники в середине 1980-х годов (рис. 4.4-12 - использовались Pandas и Matplotlib), а последующие пики и спады были связаны с пузырем доткомов и технологическим бумом последних лет.

   Рисунок 4.4-13. В сфере недвижимости Сан-Франциско технологический бум подстегнул спрос на квартиры, а "пузырь доткомов" 
повлиял на торговые площади
В Сан-Франциско большая часть из 91,5 миллиарда долларов, вложенных в строительство и реконструкцию, - почти 75 % - сосредоточена в центре города (рис. 4.4-13 - использовались Pandas и библиотека визуализации Folium) и в радиусе 2 км от центра города, что отражает более высокую плотность инвестиций в этих центральных зонах. 

Средняя стоимость разрешений на строительство значительно варьируется в зависимости от района, при этом заявки в центре города стоят в три раза дороже, чем за его пределами, из-за более высокой стоимости земли, рабочей силы, материалов и строгих строительных норм, требующих применения более дорогих материалов для повышения энергоэффективности.

   Рисунок 4.4-14. В Сан-Франциско 75 процентов инвестиций в строительство (91,5 миллиарда долларов) сосредоточено в центре города
Набор данных позволяет рассчитать средние цены на ремонт не только по типам домов, но и по районам города и отдельным адресам. В Сан-Франциско динамика стоимости ремонта жилья демонстрирует отчетливые тенденции для разных типов ремонта и жилья (рис. 4.4-14 - использовались Pandas и Matplotlib). Ремонт кухни заметно дороже, чем ремонт ванной комнаты: средний ремонт кухни в односемейном доме стоит около 28 000 долларов по сравнению с 25 000 долларов в двух семейном доме. 

   Рисунок 4.4-15. В СФ ремонт кухонь обходится почти в два раза дороже ремонта ванных комнат, и домовладельцам необходимо откладывать по 350 долларов ежемесячно в течение 15 лет, чтобы покрыть постоянно расходы на основной ремонт жилья
Инфляцию стоимости строительства в Сан-Франциско с годами можно проследить, проанализировав данные, сгруппированные по типам жилья и годам (рис. 4.4-15 - использовались Pandas и Seaborn), которые показывают постоянный рост средней стоимости ремонта с 1990 года и выявляют краткосрочные трехлетние циклы в стоимости ремонта многоквартирных домов. 

   Рисунок 4.4-16. С 1980 по 2019 год стоимость ремонта ванных комнат в СФ выросла в пять раз, в то время как ремонт крыши и кухни подорожал в три раза, а ремонт лестниц - только на 85%.
Исследование данных от строительного департамента Сан-Франциско позволяет выявить, что стоимость строительства в городе чрезвычайно переменчива и часто непредсказуема, оказываясь под влиянием множества факторов. Среди этих факторов - экономический рост, технологические инновации и уникальные требования различных видов жилья. 
В прошлом для проведения подобного анализа требовались глубокие знания в программировании и аналитике. Однако с появлением инструментов вроде ChatGPT и LLaMa, процесс стал доступен и прост для широкого круга специалистов в строительной отрасли, начиная от обычных строителей и заканчивая высшим руководством компаний.



   Рисунок 4.4-17. Переход к визуально понятным данным переводит управление с ручного на автоматизированное принятие решений на основе данных
Подобно тому, как мы анализировали данные из табличного набора данных "строительного управления Сан-Франциско", мы можем визуализировать и анализировать любые наборы данных - от изображений и документов до данных IOT или данных из моделей САПР (BIM).
Пример больших данных на основе данных САПР (BIM)
В
 этой главе мы проанализируем большой набор данных, используя данные из различных систем САПР (BIM). Для создания большого набора данных был использован специализированный автоматизированный веб-краулер (скрипт), настроенный на автоматический поиск и сбор проектных файлов с сайтов, предлагающих бесплатные архитектурные модели в форматах Revit® и IFC. За несколько дней краулер успешно нашел и скачал 4 596 файлов IFC и 6 471 файл Revit® [30].
После сбора проектов в форматах Revit® и IFC разных версий и их конверсии в структурированный формат CSV с помощью бесплатных SDK для реверс-инжиниринга почти 10 тысяч проектов были собраны в один большой файл-таблицу Apache Parquet и загружен для анализа в Pandas DataFrame (рис. 4.4-18) - форму данных, о которой мы говорили в параграфе "DataFrame - популярная структура данных".


   Рисунок 4.4-18. Структурированные данные проекта позволяют объединить любое количество проектов в одну двухмерную таблицу
Данные из этой масштабной коллекции содержат следующие сведения: набор файлов IFC содержит около 4 миллионов сущностей (строк) и 24 962 атрибута (столбцов), а набор файлов Revit®, состоящий примерно из 6 миллионов сущностей (строк), содержит 27 025 различных атрибутов (столбцов).

Эти информационные наборы охватывают миллионы элементов, для каждого из которых были дополнительно получены и добавлены в общую таблицу – координаты геометрии BoundingBox (прямоугольник, определяющий границы объекта в проекте) и созданы изображения каждого элемента в формате PNG и геометрии в открытом формате XML - DAE (Collada).

   Рисунок 4.4-19. Набор данных из 1,5 млн элементов и визуализация (библиотека missingno) заполненности первых 100 атрибутов 
Таким образом, мы получили всю информацию о десятках миллионов элементов из 4 596 проектов IFC и 6 471 проекта Revit®, где все атрибуты-свойства всех элементов-сущностей и их геометрия (BoundingBox) были переведены в структурированную форму одной таблицы (DataFrame).
Такие огромные объемы структурированных данных открывают безграничные возможности для анализа и принятия решений. Примером анализа такого набора данных может служить проект "5000 проектов IFC и Revit®" [32], доступный на Kaggle. Этот готовый проект Jupyter Notebook содержит не только код решений, но и наглядную визуализацию результатов анализа.
С помощью библиотеки Pandas (о которой мы подробно рассказывали в главе "Pandas: Незаменимый инструмент в анализе данных") был проведен общий анализ всех элементов из всех проектов.

   Рисунок 4.4-20. Примеры анализа данных из форматов САПР (BIM)
Например, используя метаинформацию о проектах, можно определить, для каких городов были созданы проекты, отобразив эту информацию на карте (рис. 4.4-19 - использовались Pandas и библиотека визуализации Folium). Из этого набора данных также можно узнать, в какое время дня, недели или месяца были сохранены или изменены файлы проектов. 

   Рисунок 4.4-21. Визуализация геометрического положения всех колонн и размеров всех окон до 3 метров в проектах из списка под графиками
Аналитический код Pipeline для этого примера и сам набор данных доступны на сайте Kaggle под названием "5000 проектов IFC и Revit® | DataDrivenCo-nstruction.io" [32]. Этот готовый Pipeline вместе с набором данных можно скопировать и запустить в одной из популярных IDE: PyCharm, Visual Studio Code (VS Code), Jupyter Notebook, Spyder, Atom, Sublime Text, Eclipse с плагином PyDev, Thonny, Wing IDE, IntelliJ IDEA с плагином Python, JupyterLab или популярных онлайн-инструментах Kaggle.com, Google Collab, Microsoft Azure Notebooks, Amazon SageMaker.
Благодаря анализу этой информации на основе данных прошлых проектов специалисты могут эффективно прогнозировать потребности в материалах и рабочей силе и оптимизировать проектные решения еще до начала строительства. 
Аналитические данные, полученные в результате обработки и изучения огромных массивов структурированных данных, играют решающую роль в процессе принятия решений в строительной отрасли.
Но вернемся к реалиям строительной отрасли: в то время как в Сан-Франциско уже появляются самодвижущиеся такси, компании, работающие в строительной отрасли, все еще остаются часто бумажными предприятиями, где решения принимаются скорее на основе интуиции и опыта, чем на основе данных.
В этой аналогии строительные компании можно сравнить с водителями, которые отвечают за движение из пункта А в пункт Б и в конечном итоге доставляют заказчику конечный продукт в виде готового здания. 
Заглядывая в будущее, строительные компании должны осознать, что будущие достижения в области открытых данных и открытых инструментов нарушат традиционный подход к оценке стоимости и сроков реализации проектов и лишат возможности спекулировать на непрозрачных данных об объемах и ценах. 
Процесс ухода от спекуляций за счёт непрозрачности данных происходит в финансовой, сельскохозяйственной, розничной или логистической отраслях, которые сегодня в значительной степени зависят от технологий больших данных и машинного обучения, где на цифровых рыночных площадках статистически рассчитывается в течение нескольких секунд цена и стоимость поездки/транзакции/процесса. 

Подобно движению по регулируемой дороге без вмешательства человека, будущие строительные процессы станут автоматизированными в оценке стоимости и времени и менее зависимыми от человеческого влияния (рис. 4.4-21), что в корне изменит характер процесса "путешествия" в строительстве.

   Рисунок 4.4-22. Стоимость и время "пути" в процессе строительства будут определяться с помощью машинного обучения и статистических инструментов
С введением новых норм в почти каждой стране мира, обязывающих передавать модели САПР (BIM) клиентам или банкам, финансирующим строительные проекты, стало возможным обеспечить прозрачность данных о стоимости и объемах работ. Это делает практику спекуляций на этих параметрах практически невозможной. Особенно это актуально в случаях, когда заказчик обладает навыками самостоятельно и быстро анализировать объемы работ и актуальные цены на рынке, что для крупных заказчиков и финансовых организаций в наше время не является трудной задачей.

   Рисунок 4.4-23. Машинное обучение и искуственный интеллект помогут нам только заполнить не заполненные (белые, пустые) значения наших таблиц на основе (чёрные значения) данных которые мы собрали

В строительстве проблемы редко возникают мгновенно — большинство аварий и сбоев развиваются постепенно, оставляя после себя предупреждающие сигналы. Именно здесь на помощь приходит предиктивная аналитика, позволяя выявлять потенциальные неисправности еще до того, как они станут критическими.
Датчики, установленные на строительной технике, несущих конструкциях или инженерных системах, фиксируют вибрации, температурные колебания, уровень нагрузки и другие параметры. Анализируя эти данные, алгоритмы могут обнаружить отклонения от нормы, сигнализируя о возможных поломках. Например, если бетонная балка дает минимальные трещины, а кран начинает работать с небольшими задержками, система распознает эти изменения и предупреждает инженеров еще до возникновения серьезных проблем.
Такой подход снижает затраты на ремонты, предотвращает аварии и повышает безопасность на стройплощадке. Вместо того чтобы устранять последствия, можно заранее вмешаться и скорректировать процесс. Предиктивная аналитика превращает строительство из реактивной отрасли в проактивную, где будущее можно не просто планировать, но и предсказывать.



Финансовые трудности, а также риск банкротства и нехватка ликвидности подтолкнут строительные компании к внедрению автоматизации, больших данных и аналитики в свою деятельность как единственных инструментов выживания и повышения эффективности в современных реалиях.
Доступность больших объемов открытых данных и осознание того, что на их основе можно создавать прогнозные модели, открывают двери в мир статистики, прогнозирования и машинного обучения.


ГЛАВА 4.5 
БУДУЩЕЕ: ПРОГНОЗЫ И МАШИННОЕ ОБУЧЕНИЕ

BlackRock: Машинное обучение и искусственный интеллект изменят то, как мы работаем и как строим
Б
азы данных различных систем в строительном бизнесе с их со временем неизбежно разрушающейся инфраструктурой - это питательная среда для будущих решений.
Серверы компании, подобно лесу, богаты биомассой важной информации, зачастую скрытой под землей, в недрах серверов и папок. Массы данных из различных систем, созданных сегодня - после использования и падения на дно сервера, после многолетнего окаменения - станут топливом для языковых моделей в будущем. На этих внутрикорпоративных моделях будут построены внутренние чаты компании (например, отдельный экземпляр ChatGPT или LlaMa), позволяющие быстро и удобно формировать необходимые графики, панели и документы.

   Рисунок 4.5-1. Как деревья превращаются в уголь, так и информация превращается со временем - в ценную структурированную информацию

Окаменение растительной массы в сочетании с давлением и температурой создало однородную и уникально структурированную гомогенную массу деревьев разных пород, живших в разное время, - древесный уголь [35]. Так же и информация, записанная на жестких дисках в разных форматах и в разное время под давлением и температурой менеджмента качества, в итоге образует однородную структурированную массу ценной информации.
Эти слои информации впоследствии обнаруживаются внутри компании опытными аналитиками, которые начинают постепенно извлекать ценную информацию из, казалось бы, давно неактуальных данных. 
В тот момент, когда эти созревшие пласты данных, благодаря аналитикам, начинают не просто сгорать конвейерах аналитики и принятиях решений, а течь по бизнес-процессам, компания готова к следующему переходу - к теме машинного обучения и искусственного интеллекта.


   Рисунок 4.5-2. Угасание технологий создания данных и применение инструментов аналитики открывают путь к теме машинного обучения

Как рассказал в интервью Bloomberg в сентябре 2023 года влиятельный генеральный директор BlackRock - одного из крупнейших в мире финансовых фондов (которому принадлежат крупные пакеты акций почти всех крупнейших компаний, производящих строительное программное обеспечение, а также компаний, владеющих самым большим количеством недвижимости в мире [36]): 
"ИИ обладает огромным потенциалом. Он изменит то, как мы работаем, то, как мы живем. ИИ и робототехника изменят то, как мы работаем и как мы строим, и мы сможем использовать ИИ и робототехнику как средство для создания гораздо большей производительности" [37].
Л.Ф. Генеральный директор BlackRock®, Сентябрь 2023 г.

   Рисунок 4.5-3. Технологии искусственного интеллекта и робототехника станут главной движущей силой будущего для повышения производительности 
в строительной отрасли
Эпоха, когда стратегические решения зависели от интуиции отдельных руководителей, уходит в прошлое. В условиях растущей конкуренции и сложных экономических условий субъективный подход становится слишком рискованным и неэффективным. Компании, продолжающие полагаться на личные мнения вместо объективного анализа данных, теряют возможность оперативно реагировать на изменения и упускают конкурентные преимущества.
Современный бизнес требует перехода от мнений к фактам, от интуиции к проверенным аналитическим методам. Если раньше ключевые решения принимались исходя из личного опыта, то сегодня они основаны на глубоком анализе исторических данных, прогнозных моделях и алгоритмах машинного обучения. Это не просто эволюция подходов — это необходимость, без которой компании теряют конкурентоспособность.

   Рисунок 4.5-4. Эра решений принимаемых HIPPO (мнение самого высокооплачиваемого сотрудника) уйдёт в прошлое
Руководители, которые привыкли полагаться исключительно на собственные ощущения, сталкиваются с новой реальностью: авторитет больше не определяет качество решений. В центре управления теперь находятся системы, анализирующие миллионы параметров, выявляющие скрытые закономерности и предлагающие оптимальные стратегии. Организации, адаптирующиеся к этим изменениям, не только повышают эффективность, но и закладывают основу для будущего роста, в котором успех определяется не мнением, а объективными данными.
Машинное обучение (ML) работает за счет обработки больших объемов данных, используя статистические методы для имитации некоторых аспектов человеческого мышления. Однако большинство компаний не располагает такими наборами данных, а если они и есть, то часто недостаточно аннотированы. Здесь могут помочь семантические технологии и трансферное обучение — метод, позволяющий ML быть эффективнее при работе с небольшими объемами данных.
Суть трансферного обучения в том, что вместо обработки каждой задачи с нуля можно использовать знания, полученные в смежных областях. Человеческое мышление устроено так же. Упрощая модель данных и делая ее более элегантной, можно снизить сложность задачи для алгоритмов ML, что уменьшает потребность в больших объемах информации.
Главная причина, по которой компании избегают внедрения ML, — его непрозрачность. Большинство моделей работают как "черные ящики", не объясняя, как именно они приходят к своим выводам. Это ведет к проблемам: алгоритмы могут укреплять стереотипы, институционализировать предвзятость и даже создавать курьезные ситуации, как в случае с чат-ботом Microsoft, который быстро превратился в токсичный инструмент общения.

Предсказания и прогнозы на основе исторических данных
С
обранные данные о проектах компании позволяют строить модели, прогнозирующие стоимость и временные характеристики будущих, еще не реализованных проектов без трудоемких расчетов.




Подробнее о традиционных методах расчёта оценки сметной стоимости проектов мы говорили в главе «Методы расчета сметной стоимости проектов. Ресурсный метод». В этой же главе мы уже упомянули «параметрический» и «экспертный метод» оценки, как важные компоненты современных подходов к анализу стоимости и времени проектов, которые обогащают процесс оценки за счет использования статистики и алгоритмов машинного обучения.
Машинное обучение можно сравнить с ребёнком, который пытается вставить прямоугольный блок в круглое отверстие. На начальных этапах алгоритм пробует множество подходов, сталкиваясь с ошибками и несоответствиями. Этот процесс может показаться неэффективным, однако он обеспечивает важное обучение: анализируя каждую ошибку, модель улучшает свои прогнозы и принимает всё более точные решения.
В строительной отрасли, где данные часто бывают разрозненными и неточными, машинное обучение действует аналогично. Оно обучается на исторических данных, пробует разные гипотезы, пока не находит наиболее подходящие пути решения задач, таких как прогнозирование стоимости проекта или оптимизация графика. Как и в случае с ребёнком, метод проб и ошибок становится ключевым для адаптации и построения более точных моделей.
Ручной и полуавтоматический расчет цен и временных атрибутов проекта в будущем будет дополнен мнением и расчетами моделей машинного обучения. Новые данные будут генерироваться из существующей информации, подобно тому, как ChatGPT создает новый текст, изображения и код на основе существующих данных, собираемых годами со всего интернета [38].
Так же как сегодня мы используем наш опыт и знания в виде субъективной статистики для прогнозирования будущих событий, будущее строительных проектов будет определяться сочетанием старых знаний и математических алгоритмов моделей машинного обучения.
Машинное обучение (ML - Machine learning) — это класс методов для решения задач искусственного интеллекта. Алгоритмы машинного обучения распознают закономерности в больших массивах данных и используют их для самообучения. Каждый новый набор данных позволяет математическим алгоритмам совершенствоваться и адаптироваться в соответствии с полученной информацией, что позволяет постоянно повышать точность рекомендаций и предсказаний.

   Рис. 4.5-5. Качественные и структурированные исторические данные компании - материал, на основе которого строятся прогнозы
В качестве примера рассмотрим задачу предсказания цены дома на основе его размера, площади участка, количества комнат и географического положения (широты и долготы).
Один из способов решения проблемы прогнозирования цены дома - разработка классического алгоритма, который анализирует эти четыре характеристики и рассчитывает ожидаемую цену на основе определенного правила или формулы (рис. 4.5-5). Такой метод требует точного знания формулы расчета цены дома, что зачастую невозможно на практике.

   Рисунок 4.5-7. Для оценки стоимости дома можно использовать классический алгоритм с фиксированной формулой
В качестве альтернативы создадим алгоритм машинного обучения, который будет генерировать модель на основе предварительного понимания проблемы и исторических данных, которые могут быть неполными.
В примере с ценообразованием машинное обучение используется для разработки различных математических алгоритмов и моделей на основе неполных знаний о механизме формирования цены. Модель, управляемая данными, подстраивается и адаптируется к данным о стоимости и сроках строительства аналогичных проектов.

   Рисунок 4.5-6. В отличие от классической оценки по формулам, алгоритм машинного обучения обучается на исторических данных
В контексте машинного обучения под наблюдением (supervised machine learning) каждый проект в обучающем наборе данных содержит как входные атрибуты (например, данные о стоимости и времени строительства аналогичных зданий), так и ожидаемые выходные значения (например, стоимость или время). Подобный набор данных используется для создания и настройки модели машинного обучения. 
Чем больше набор данных и чем выше качество данных в нем, тем точнее будет модель и тем точнее будут результаты прогнозов.

   Рис. 4.5-8. Модель ML, обученная на данных о стоимости и графике выполнения прошлых проектов, с некоторой вероятностью определит
 стоимость и график выполнения нового проекта
После создания и обучения модели для оценки строительства нового проекта достаточно предоставить модели новые атрибуты для нового проекта, и модель с определенной вероятностью предоставит расчетные результаты, основанные на ранее изученных закономерностях.

REV Ключевые концепции машинного обучения
М
ашинное обучение использует различные термины для описания своих компонентов (рис. 4.4-8):
● Метки (Labels): это целевые переменные или атрибуты, которые должна предсказать модель. Пример: стоимость строительства (например, в долларах), продолжительность строительных работ (например, в месяцах).
● Характеристики (Features): это независимые переменные или атрибуты, которые служат входными данными для модели. В модели прогнозирования они используются для предсказания меток. Примеры: площадь участка (в квадратных метрах), количество этажей здания, общая площадь здания (в квадратных метрах), географическое положение (широта и долгота), тип материалов, использованных при строительстве. Количество характеристик также определяет размерность данных.
● Модель (Model): это набор различных гипотез, одна из которых приближает целевую функцию, которую нужно предсказать или аппроксимировать. Пример: модель машинного обучения, использующая методы регрессионного анализа для прогнозирования стоимости и сроков строительства.
● Алгоритм обучения (Learning Algorithm): это процесс поиска наилучшей гипотезы в модели, которая точно соответствует целевой функции, используя набор обучающих данных. Пример: Алгоритм линейной регрессии, KNN или случайного леса, анализирующий данные о стоимости и сроках строительства для выявления взаимосвязей и закономерностей.
● Обучение (Training): в процессе обучения алгоритм анализирует обучающие данные, находя закономерности, которые соответствуют взаимосвязи между входными атрибутами и целевыми метками. Результатом этого процесса является обученная модель машинного обучения, готовая к прогнозированию. Пример: процесс, в котором алгоритм анализирует исторические данные о строительстве (стоимость, время, характеристики объекта) для создания прогнозной модели.


   Рисунок 4.4-9. ML использует метки и атрибуты для создания моделей, которые обучаются на данных с помощью алгоритмов для
 предсказания результатов
Основная цель машинного обучения - наделить компьютеры способностью автоматически усваивать знания без вмешательства или помощи человека и соответствующим образом корректировать свои действия [39].
Машинное обучение - это не волшебство, это математика, данные и подбор шаблонов, а не настоящий интеллект. Машинное обучение или модель искусственого интеллеката - это программа, которая была обучена на данных распознавать определенные закономерности или принимать определенные решения без дальнейшего вмешательства человека.
Таким образом, в будущем роль человека будет заключаться лишь в предоставлении машине когнитивных возможностей - он будет задавать условия, веса и параметры, а модель машинного обучения будет делать все остальное.

Пример использования машинного обучения для нахождения стоимости и сроков проекта
В
 будущем основной бизнес-процесс строительной компании - оценка стоимости и сроков - будет дополнен оценками, полученными при помощи моделей машинного обучения. Этот шаг в автоматизации расчета стоимости и сметы не только повысит точность и эффективность, но и станет отправной точкой для разработки и внедрения моделей машинного обучения в другие бизнес-процессы компании.
Важно уметь быстро определить, сколько времени займет строительство объекта и какова будет его общая стоимость. Эти вопросы о сроках и стоимости проекта традиционно занимают центральное место в сознании как заказчиков, так и строительных компаний с момента зарождения строительной отрасли.

   Рис. 4.5-10. В строительных проектах ключевыми факторами успеха 
являются оценки сроков и стоимости строительства


В следующем примере будут извлечены ключевые данные из прошлых проектов, и на их основе будет разработана модель машинного обучения, которая позволит нам точно оценить стоимость и сроки реализации новых строительных проектов.
Рассмотрим три проекта с тремя ключевыми атрибутами: количеством квартир (где 100 квартир эквивалентны числу 10 для простоты визуализации), количеством этажей и условной мерой сложности строительства по шкале от 1 до 10, где 10 - самый высокий показатель сложности. В машинном обучении процесс преобразования и упрощения таких значений, как 100 в 10 или 50 в 5, называется "нормализацией".
Нормализация в машинном обучении — это процесс приведения различных числовых данных к единому масштабу для облегчения их обработки и анализа. Этот процесс особенно важен, когда данные имеют разные масштабы и единицы измерения.
Предположим, что в первом проекте (рис. 4.5-10) было 50 квартир, 7 этажей и оценка сложности 2, что означало относительно простое строительство. Во втором проекте было уже 80 квартир, 9 этажей и относительно сложный проект. При таких условиях строительство первого и второго многоквартирного дома заняло 270 и 330 дней, а общая стоимость проекта составила 4,5 и 5,8 миллиона долларов соответственно.

   Рисунок 4.5-11. Пример набора данных из трех проектов с различными атрибутами позволяет использовать прошлые данные для оценки времени и стоимости будущего проекта X
При построении модели машинного обучения для таких данных основной задачей является определение критических атрибутов, или меток, для прогнозирования, в данном случае - времени и стоимости строительства.
Имея небольшой набор данных, мы будем использовать информацию о предыдущих строительных проектах для планирования новых: используя алгоритмы машинного обучения, мы должны предсказать стоимость и продолжительность строительства нового проекта X на основе заданных атрибутов нового проекта, таких как 40 квартир, 4 этажа и относительная высокая сложность проекта - 7.
Чтобы создать прогностическую модель машинного обучения, нам нужно выбрать алгоритм для ее создания. Алгоритм в машинном обучении — это как рецепт, который учит компьютер, как делать прогнозы или принимать решения на основе данных. 
Чтобы проанализировать данные о прошлых строительных проектах и предсказать время и стоимость будущих проектов (рис. 4.5-10), можно использовать один из популярных алгоритмов машинного обучения:
● Линейная регрессия (Linear regression): этот алгоритм пытается найти прямую зависимость между атрибутами, например, между количеством этажей и стоимостью строительства. Цель - найти линейное уравнение, которое наилучшим образом описывает эту связь, что позволяет делать прогнозы.
● Алгоритм к-ближайших соседей (K-nearest neighbors (k-NN)). этот алгоритм сравнивает новый проект с прошлыми проектами, которые были похожи по размеру или сложности. k-NN классифицирует данные на основе того, какие из k (количество) обучающих примеров находятся ближе всего к ним. В контексте регрессии результатом является среднее значение или медиана из k ближайших соседей.
● Деревья решений (Decision Trees): это модель прогнозного моделирования, которая разделяет данные на подмножества, основанные на различных условиях, используя древовидную структуру. Каждый узел дерева представляет собой условие или вопрос, ведущий к дальнейшему разделению данных, а каждый лист - окончательное предсказание или результат. Алгоритм делит данные на более мелкие группы на основе различных характеристик, например, сначала по количеству этажей, затем по сложности и так далее, чтобы сделать прогноз.
Давайте рассмотрим алгоритмы машинного обучения для оценки стоимости нового проекта на примере двух популярных алгоритмов: линейной регрессии и алгоритма к-ближайших соседей (K-nearest neighbors).

Прогноз стоимости и времени проекта при помощи линейной регрессия и ChatGPT
Л
инейная регрессия - это фундаментальный алгоритм анализа данных, позволяющий предсказать значение переменной на основе линейной связи с одной или несколькими другими переменными. Эта модель предполагает, что существует прямая линейная связь между зависимой переменной и одной или несколькими независимыми переменными, и цель алгоритма - найти эту связь. 
Простота и понятность линейной регрессии сделали ее основным инструментом в различных областях на протяжении многих десятилетий. При работе с одной переменной линейная регрессия заключается в нахождении наилучшим образом подходящей линии, проходящей через точки данных. 
Эта линия представлена уравнением, в котором при вводе значения независимой переменной (X) получается прогнозируемое значение зависимой переменной (Y). Этот процесс позволяет эффективно прогнозировать Y на основе известных значений X, используя линейную зависимость между ними. Пример нахождения такой статистически усредненной линии можно увидеть на примере оценки данных о разрешениях на строительство в Сан-Франциско на рисунке 4.4-15, где инфляция рассчитывалась для различных типов объектов.
Давайте загрузим таблицу данных проекта (рис. 4.5-10 из предыдущей главы) непосредственно в ChatGPT и попросим его построить для нас простую модель машинного обучения.
❏ Отправьте текстовый запрос в ChatGPT:
Необходимо показать построение простой модели машинного обучения для прогнозирования стоимости и времени реализации нового проекта X (прикрепленное изображение) ⏎.





➤ Ответ ChatGPT:

   Рисунок 4.5-12. ChatGPT использует линейную регрессию для создания 
модели машинного обучения для прогнозирования стоимости и времени проекта
ChatGPT автоматически распознал таблицу из приложенного изображения и преобразовал данные из визуального формата в массив (array) таблиц. Этот массив был использован в качестве основы для создания признаков и меток, на основе которых была создана модель машинного обучения. 
С помощью базовой линейной регрессионной модели, которая была обучена на "чрезвычайно маленьком" наборе данных, были сделаны прогнозы для гипотетического проекта нового строительства, обозначенного как Project X. В нашей задаче этот проект характеризуется наличием 4 квартир, 4 этажей и уровнем сложности 7 (рис. 4.5-10). 


Согласно прогнозам, сделанным с помощью линейной регрессионной модели, основанной на ограниченном наборе данных (рис. 4.5-11):
• Продолжительность строительства составит примерно 238 дней (238,4444444)
• Общая сумма расходов составит приблизительно 3 042 338 долларов (3042337,777)
Для дальнейшего изучения гипотезы о стоимости проекта полезно поэкспериментировать с различными алгоритмами и методами машинного обучения. Поэтому спрогнозируем те же значения стоимости и времени для нового проекта X на основе небольшого набора исторических данных с помощью алгоритма K-Nearest Neighbours (k-NN).

Прогнозы стоимости и времени проекта при помощи алгоритма K-nearest neighbor (k-NN)
В
 качестве дополнительного прогноза для оценки стоимости и продолжительности нового проекта используем алгоритм k-Nearest Neighbours (k-NN). Алгоритм K-Nearest Neighbors (k-NN) — это метод машинного обучения под наблюдением (supervised machine learning), применяемый как для классификации, так и для регрессии. В этом подходе каждый проект представляется как точка в многомерном пространстве, где каждое измерение соответствует определенному атрибуту проекта.
В нашем случае, учитывая три атрибута каждого проекта, мы представим их как точки в трехмерном пространстве. Таким образом, наш предстоящий проект X будет локализован в этом пространстве с координатами (4, 4, 7). Следует отметить, что в реальных условиях количество точек и размерность пространства могут быть на порядки больше.
Алгоритм K-NN (k-nearest neighbors) работает путем измерения расстояния между желаемым проектом X и проектами в обучающей базе данных. Сравнивая эти расстояния, алгоритм определяет проекты, которые находятся ближе всего к точке проекта X. 
Например, если второй проект из нашего исходного датасета расположен значительно дальше от Х (рис. 4.5-12), чем другие проекты, его можно исключить из дальнейшего анализа. 
Этот метод позволяет оценить сходство между проектами, что, в свою очередь, помогает сделать выводы о возможной стоимости и сроках реализации нового проекта на основе аналогичных проектов, которые были реализованы ранее.

   Рисунок 4.5-13. В алгоритме K-NN проекты представляются как точки в многомерном пространстве, и для оценки сходства и прогнозирования выбираются ближайшие проекты на основе расстояний
Работа k-NN включает в себя несколько ключевых этапов:
1. Подготовка данных: сначала загружаются обучающие и тестовые наборы данных. Обучающие данные используются для "тренировки" алгоритма, а тестовые - для проверки его эффективности.
2. Выбор параметра K: выбирается число K, которое указывает, сколько ближайших соседей (точек данных) должно учитываться в алгоритме. Значение K очень важно, поскольку оно влияет на результат.
3. Процесс классификации и регрессии для тестовых данных:
a. Вычисление расстояний: для каждого элемента из тестовых данных вычисляется расстояние до каждого элемента из обучающих данных (рис. 4.5-12). Для этого могут использоваться различные методы измерения расстояний, такие как евклидово расстояние (наиболее распространенный метод), манхэттенское расстояние или расстояние Хэмминга.
b. Сортировка и выбор K ближайших соседей: после вычисления расстояний они сортируются и выбираются K ближайших точек к тестовой точке.
c. Определение класса или значения тестовой точки: если это задача классификации, класс тестовой точки определяется на основе наиболее часто встречающегося класса среди K выбранных соседей. Если это задача регрессии, то вычисляется среднее значение (или другая мера центральной тенденции) значений K соседей.
4. Завершение процесса: как только все тестовые данные будут классифицированы или для них будут сделаны прогнозы, процесс будет завершен.
Алгоритм k-nearest neighbors (k-NN) эффективен во многих практических приложениях и является одним из основных инструментов в арсенале специалистов по машинному обучению. Этот алгоритм популярен благодаря своей простоте и эффективности, особенно в задачах, где взаимосвязи между данными легко интерпретировать.
В нашем примере после применения алгоритма K-ближайших соседей были определены два проекта (из нашей небольшой выборки) с наименьшим расстоянием до проекта X (рис. 4.5-12). На основе этих проектов алгоритм определяет среднее значение их цены и продолжительности строительства. После анализа (рис. 4.5-13) алгоритм приходит к выводу, что проект X будет стоить примерно 3 800 000 долларов и займет около 250 дней.

   Рисунок 4.5-14. Алгоритм K-nearest neighbors определяет стоимость и график проекта X, анализируя два наиболее близких проекта в выборке

Алгоритм k-Nearest Neighbors (k-NN) особенно популярен в задачах классификации и регрессии, например, в рекомендательных системах, где он используется для предложения товаров или контента на основе предпочтений, схожих с интересами конкретного пользователя. Кроме того, k-NN широко используется в медицинской диагностике для классификации типов заболеваний на основе симптомов пациента, в распознавании образов и в финансовом секторе для оценки кредитоспособности клиентов.
В нашей упрощенной задаче для визуализации в трехмерном пространстве использовалось три атрибута, но реальные проекты в среднем включают сотни или тысячи атрибутов (см. набор данных из главы "Пример больших данных на основе данных САПР (BIM)"), что значительно увеличивает размерность пространства и сложность представления проектов в виде векторов.


   Рисунок 4.5-15. В упрощенном примере для 3D-визуализации использовались три атрибута, в то время как реальные проекты имеют большое 
количество атрибутов
Применение различных алгоритмов к одному и тому же набору данных для проекта X, в котором 40 квартир, 4 этажа и уровень сложности 7, дало разные прогнозные значения. Алгоритм линейной регрессии предсказал время завершения 238 дней и стоимость 3 042 338 долларов, в то время как алгоритм k-NN предсказал 250 дней и 3 882 000 долларов.

Точность таких предсказаний повышается с увеличением объема наборов данных и улучшением качества признаков и меток. Интеграция методов предварительной обработки данных, таких как нормализация и обнаружение выбросов, может значительно улучшить работу модели, обеспечив чистоту входных данных и их пригодность для анализа. Кроме того, для оценки обобщенности и устойчивости модели к различным наборам данных можно использовать методы кросс-валидации.
И модели машинного обучения, и профессиональные сметные расчеты, выполняемые отделами калькуляции для крупных проектов, сталкиваются с существенной неопределенностью и возможностью ошибок, причем иногда ошибки в моделях машинного обучения могут быть меньше, чем в традиционных сметах. Поэтому, хотя модели машинного обучения, возможно, и не станут основным источником для принятия решений по бюджетированию, они будут все чаще становиться второстепенной, но влиятельной точкой зрения в компаниях. 
Модели машинного обучения будут играть все более заметную роль в процессах принятия решений строительными компаниями, дополняя традиционные методы прогнозирования и расчетов.

И даже если вам кажется что хаос ваших задач не возможно параметизировать- знайте что всегда найдётся математическое объяснения любым происходящем вокруг вас событиям. 
Добавить что галлюцинации есть но это всё будет подходить под кривую из видео топлеса про хаос - много вариация но они все будут примерно в одном направлениии, хотя конечно результат может быть немного другим

«Хаос — это порядок, который нужно расшифровать»
Жозе Сарамаго «Двойник»

Глава 5. Угрозы строительному бизнесу и что делать
REV Уберизация и открытые данные это угроза для строительного бизнеса
Нужно исследования компания – которая сказала что большая часть не приносит прибыли – найти в отчёте маккинзи или мировой экономический форум




В строительстве традиционно основой считались материалы: бетон, сталь, кирпич. Но с развитием цифровых технологий становится очевидно, что информация играет не меньшую роль, чем физические ресурсы.
Сегодня мы можем не просто возводить здания, а предсказывать их поведение, анализируя миллионы данных: нагрузки, климатические условия, динамику эксплуатации. Виртуальные модели, BIM-системы и сенсорные технологии фиксируют не только физические параметры, но и взаимодействие всех элементов проекта во времени.
Строительство превращается в процесс управления информацией. Чем точнее и полнее данные, тем эффективнее проектирование, возведение и эксплуатация зданий. В будущем ключевым ресурсом станет не бетон и арматура, а способность собирать, анализировать и использовать информацию.




	
Инвесторы и заказчики, финансирующие строительство, в будущем неизбежно поймут ценность открытых данных и аналитики исторических данных. Это откроет возможности для автоматизации расчётов сроков и стоимости проектов, что позволит лучше контролировать расходы и быстрее выявлять избыточные затраты. Например, если объёмы бетона на стройплощадке можно будет автоматически проверять по простым плоским MESH данным проекта со структурированной метаинформацией без использования CAD (BIM) и их сложных геометрических ядер, станет сразу очевидно, насколько завышены сметные расчёты.
Такая открытость и прозрачность данных представляет угрозу для строительных компаний, которые привыкли зарабатывать на непрозрачности процессов и запутанных отчётах, где можно спрятать спекуляции и скрытые издержки за сложными и закрытыми форматами и платформами передачи данных. Поэтому строительные компании вряд ли будут заинтересованы в полноценном внедрении открытых данных в свои бизнес процессы. Если данные будут доступны и легко обрабатываемы для заказчика, их можно будет проверять автоматически, что исключит возможность завышать объёмы и манипулировать сметами. 

БИМ и традиционные процессы похожи на скульптуры 16 века. Но чтобы сделать точно такую же новую скультптуру мы вместо стамески и нескольких рабочих будем получить данные при помощи 3D Пинтера данных и процессов, которые будут поставлять нам модели данных, обученные на исторических данных.


Потеря контроля над расчётами объёмов и стоимости уже обернулась трансформацией в других отраслях экономики, позволяя клиентам напрямую достигать своих целей. Цифровизация и прозрачность данных трансформировали многие традиционные бизнес-модели, как это произошло с таксистами после появления Uber, с отельерами после прихода Airbnb и с розничными продавцами после развития Amazon, где прямой доступ к информации и автоматизация расчетов существенно снизили роль посредников.

Рис. 35. Строительный бизне вскоре столкнётся с теми же процессами, с которыми пришлось столкнуться таксистам, отельерам продавцам 10 лет назад
Инвесторы, заказчики и банки уже начали требовать прозрачности и в строительной отрасли. Процесс открытия и неограниченного доступа к данным неизбежен, и со временем открытые данные станут новым стандартом. Поэтому вопросы внедрения открытых форматов будут наиболее востребованны именно у инвесторов, заказчиков, банков и частных инвестиционных фондов (private equity) — тех, кто в итоге является конечным пользователем построенных объектов.
Движение инвестора, заказчика от идеи до готового здания, в будущем будет сродни путешествию на автопилоте - без водителя в виде строительной компании, обещает стать независимым от спекуляций и неопределенности.

Рис. 36. Переход от принятия решений на основе мнений важных специалистов (HIPPO) к анализу данных в строительной отрасли: сегодня и завтра
Данные и процессы во всех видах экономической деятельности человека ничем не отличаются от того, с чем приходится иметь дело профессионалам в строительной отрасли. Эра открытых данных и автоматизации неизбежно изменит строительный бизнес так же, как это уже произошло в банковском деле, торговле, сельском хозяйстве и логистике. В этих отраслях роль посредников и традиционные способы ведения бизнеса уступают место автоматизации и роботизации, не оставляя места для неоправданных наценок и спекуляций.
В долгосрочной перспективе строительные компании, которые сегодня доминируют на рынке, устанавливая стандарты цены и качества услуг, могут потерять свою роль ключевого посредника между заказчиком и его строительным проектом.

В книге «Deep Thinking», мемуарах бывшего чемпиона мира по шахматам Гарри Каспарова о событиях, приведших к его сокрушительному поражению от суперкомпьютера Big Blue компании IBM, Каспаров ясно говорит, что роль компьютеров не в том, чтобы дублировать ум великого игрока (хотя он утверждает, что у IBM были шпионы в его лагере и человеческие гроссмейстеры, обучавшие машину между матчами). Скорее, роль ИИ должна заключаться в том, чтобы делать то, что мы делаем плохо, сочетая человеческое творчество с непоколебимым разумом и проницательностью, подкрепленными чистыми данными.
«Компьютерный анализ взорвал эту ленивую традицию анализировать шахматные партии, как будто это сказки», - писал Каспаров. «»Движки» не заботятся о сюжете. Они раскрывают реальность того, что единственная история в шахматной партии - это каждый отдельный ход, слабый или сильный. Это не так весело и интересно, как метод повествования, но это правда, и не только в шахматах. Человеческая потребность понимать вещи как историю, а не как серию дискретных событий, может привести к множеству ошибочных выводов."

Открытые структуированные данные и процессы станут для заказчиков и инвесторов основой для точных оценок стоимости и сроков проекта, устраняя возможность для строительных компаний спекулировать на непрозрачных данных и сложных форматах. Это одновременно и вызов, и возможность для индустрии переосмыслить свою роль и адаптироваться к новой среде, где прозрачность и эффективность станут ключевыми факторами успеха. Но где в этой истории останется BIM?










REV С ЧЕГО СТОИТ НАЧАТЬ 

Культура
"Данные сами по себе не меняют компании. Их меняют люди, которые умеют правильно с ними работать."
Строительная отрасль традиционно ориентирована на опыт и интуицию. Прорабы, инженеры и руководители привыкли полагаться на личные наблюдения и эмпирические знания. Однако в эпоху цифровизации успешные компании строят свою работу на данных. Чтобы данные действительно работали, необходимо не просто внедрить технологии, а сформировать культуру работы с данными – от рабочих на стройке до топ-менеджеров.

1. Что такое культура работы с данными?
Культура данных – это когда каждое решение принимается на основе фактов, а не предположений.
📌 Пример:
Если раньше начальник участка определял сроки работ "на глаз", то теперь он использует аналитику из BIM-модели, данные датчиков и прогнозы погодных условий, чтобы рассчитать точные сроки.
Культура данных включает три ключевых элемента:
✅ Доступность данных – информация должна быть прозрачной и доступной для всех участников процесса.
✅ Привычка полагаться на цифры – сотрудники должны доверять данным, а не только личному опыту.
✅ Готовность учиться – данные меняют процессы, и этому нужно адаптироваться.
"Если компания не строит культуру работы с данными, никакие технологии её не спасут."

2. Как создать культуру данных в строительной компании?
📍 1. Данные должны быть частью ежедневных процессов
Данные не должны быть чем-то «отдельным» – они должны стать неотъемлемой частью рабочих процессов.
❌ Плохо: Сотрудники заполняют отчёты, но никто их не анализирует.
✅ Хорошо: Данные из отчетов автоматически попадают в дашборды, где руководители видят реальную картину проекта.
📍 2. Обучение сотрудников
Люди не боятся технологий – они боятся, что не смогут их освоить.
🔹 Прораб должен понимать, как интерпретировать данные из BIM-модели.
🔹 Инженер должен уметь анализировать показатели энергоэффективности здания.
🔹 Руководитель должен принимать решения, опираясь на отчёты Power BI.
"Обучение работе с данными – это не про IT. Это про грамотное управление строительными проектами."
📍 3. Лидеры должны задавать тон
Если руководство продолжает полагаться на интуицию, а не на аналитику, сотрудники не воспримут данные всерьез.
📌 Пример:
Компания внедрила систему анализа затрат, но директор продолжает утверждать бюджеты "на глаз". В итоге сотрудники тоже игнорируют данные.
📍 4. Доверие к данным
Данные должны быть точными и проверенными. Если отчёты содержат ошибки, никто им не будет доверять.
✅ Решение: автоматическая валидация данных, контроль качества на уровне ETL.

3. Какие ошибки мешают построить культуру данных?
🚧 Ошибка 1. Данные есть, но ими никто не пользуется
“У нас есть ERP-система, но отчёты по-прежнему составляют в Excel.”
Решение: обучение, автоматизация аналитики, интеграция BI-инструментов.
🚧 Ошибка 2. Руководство не верит в данные
"Мы всегда так делали, зачем нам эти цифры?"
Решение: кейсы успешного внедрения, наглядные дашборды, показывающие выгоду.
🚧 Ошибка 3. Данные разрознены
"Одни цифры в бухгалтерии, другие в BIM, третьи у прораба."
Решение: интеграция всех систем, использование структурированных форматов данных.

Заключение
🚀 Строительная компания с культурой данных:
✅ Принимает решения на основе цифр, а не догадок.
✅ Автоматизирует сбор и обработку данных.
✅ Обучает сотрудников работать с информацией.
✅ Инвестирует в качество данных и аналитику.
"Цифровая трансформация – это не про технологии. Это про людей, которые умеют работать с данными."


Организация, ориентированная на данные, должна не только предоставлять сотрудникам доступ к информации, но и поощрять культуру любознательности. Важно создать среду, где каждый может задавать вопросы, оспаривать предположения и предлагать дополнительные тесты. Здоровые дебаты и открытое обсуждение данных помогают находить более точные решения и развивать бизнес на основе фактов, а не догадок.
Корпоративного лидера, который нашел религию в данных и аналитике, никто не заменит.
-Рассел Гласс

Коротко нужно подумать. А какие задачи в своей компании я смогу автоматизировать или какой параметр нужно предсказать согласно аналитики.

Следует помнить, что нет ничего более сложного в организации, сомнительного в успехе и опасного в проведении, чем инициирование изменений. Новатор наживает врагов среди тех, кто процветал при старом порядке, и получает лишь вялую поддержку от тех, кто хотел бы процветать при новом. Их поддержка невелика... отчасти потому, что люди вообще недоверчивы и никогда не доверяют новым вещам, пока не проверят их на собственном опыте.
Никколо Макиавелли

Как вариант можно подумать про центр передового опыта (COE) по моделированию данных

Лидер будущего - это человек, умеющий спрашивать.
Маршалл Голдсмит


Инвентаризация
Одним из первых материалов, которые вам понадобятся, будет исчерпывающая инвентаризация ваших систем и баз данных. Если вы крупная компания, то, скорее всего, такие данные уже есть, и вам просто нужно к ним подключиться. Если же вы средняя или малая компания, то, возможно, вам придется заняться этим самостоятельно. Это не так сложно, как кажется. Ваш ИТ-отдел знает основные приложения. 

Приняв парадигму Data-Centric, будьте готовы к мощному сопротивлению. Против вас окажется не только внешняя среда, но и ваша собственная организация.
Важно понимать: крупные изменения не происходят просто потому, что они логичны или доказуемы. Переход к Data-Centric настолько радикален, что вызовет целый спектр «иммунных реакций» системы, направленных на его подавление. Успех в этом процессе зависит не только от аргументов в пользу нового подхода, но и от вашей готовности к сопротивлению — и от стратегии, позволяющей его преодолеть.


Инерционное сопротивление — самое сложное, потому что оно неосознанное и не направлено лично на вас. В крупных организациях руководители привыкли работать по определённым правилам: учитывать бюджетные циклы, поддерживать нужные инициативы и следовать сложившимся нормам продвижения проектов.
Никто не захочет менять для этой работы потребуется руководитель достаточно высокого уровня, чтобы заниматься этими вопросами, и в то же время достаточно низкого, чтобы у него было время и желание заниматься долгосрочным проектом изменений такого рода. 
Это очень плохая новость. Однако, что интересно, есть много вещей, которых эти изменения не требуют.
Вы найдете множество альтернатив с открытым исходным кодом для многих частей вашей архитектуры, а в тех случаях, когда вы предпочитаете комфорт коммерческой поддержки, их приверженность открытым стандартам предотвращает блокировку поставщиков. 
Ключевые показатели и стимулы показывают, идет ли ситуация в компании к улучшению или, наоборот, усложняется. Под «областью данных» мы понимаем всю совокупность управляемых данных внутри организации. Ее структура описывается схемами — метаданными, необходимыми для понимания информации. Чем больше схем, тем сложнее система, а значит, тем труднее с ней работать.
Сложность всего "ландшафта данных" компании — важный индикатор того, идет ли развитие в правильном направлении. Каждый новый проект неизбежно добавляет определенный уровень сложности, поэтому важно соотносить этот фактор с ожидаемой локальной рентабельностью инвестиций. Если сложность растет быстрее, чем выгоды, проект может принести больше вреда, чем пользы.


Где-то проекты получают поддержку, если решают нормативные вопросы, где-то — если создают ощущение срочности ("горящая платформа"), а в других компаниях важны долгосрочные планы. Руководители давно научились вписывать свои инициативы в нужный контекст, даже не задумываясь о стратегиях, которыми пользуются.

Если вы хотите создать устойчивую экосистему, неважно, в какой индустрии или технологическом секторе, начинать нужно с потребностей клиента. Решив проблемы на стороне спроса, вы автоматически сформируете новые роли, бизнес-модели и партнерские отношения — ведь предложение всегда следует за спросом.
Снижение затрат и повышение эффективности увеличивают спрос, а это, в свою очередь, создает лучшие возможности для тех, кто умеет быстро адаптироваться. Однако запуск B2C с нуля — сложная задача, требующая значительных ресурсов и времени. Поэтому венчурные инвесторы чаще выбирают точечные решения, которые уже вписываются в существующий рынок и решают конкретные проблемы, вместо рискованных инвестиций в полностью новые модели.
Работа с данными не сводится только к анализу — важно, чтобы результаты имели реальную ценность для бизнеса. Чтобы этого добиться, нужно придерживаться нескольких ключевых принципов:
1️⃣ Задавайте правильные вопросы. Вместо догадок лучше напрямую общаться с ключевыми заинтересованными сторонами и конечными пользователями, чтобы понять их реальные потребности.
2️⃣ Используйте бизнес-метрики. Работа с данными должна опираться на показатели эффективности (KPI), которые действительно важны для компании.
3️⃣ Поддерживайте связь с командой. Регулярные обновления и обсуждения помогают избежать недопонимания и направляют работу в нужное русло.
4️⃣ Думайте с позиции бизнеса. Представьте, что вам нужно построить этот процесс с нуля — как бы вы подошли к задаче, если бы были владельцем бизнеса?
5️⃣ Будьте открыты к обратной связи. Даже если вы эксперт в данных, именно бизнес-команда лучше всех понимает свою область, и их опыт необходим для успеха.
В конечном итоге, успешная работа с данными требует именно этих пяти вопросов. Они помогут создать систему, в которой аналитика становится ценным инструментом для бизнеса, а не просто техническим процессом.


Сбор данных, его анализ и предсказание должны происходить в пюреадьном времени
• Это наша цель
Подумай как выглядит роадмап в будущее у тебя?


  Как эти принципы, основанные на данных, могут быть реализованы в малых и средних фирмах для улучшения сотрудничества?
• Использование открытых данных и стандартных форматов (например, IFC, CSV, Parquet) снижает зависимость от дорогостоящего ПО.
• Автоматизация через простые ETL-процессы (извлечение, трансформация, загрузка) уменьшает ручной труд.
• Внедрение общих DataFrames для обмена данными между специалистами упрощает совместную работу【7】.
  Как можно эффективно обмениваться данными, не жертвуя при этом конкурентными преимуществами и безопасностью?
• Локальные базы данных (например, DuckDB, SQLite) вместо облачных сервисов обеспечивают безопасность.
• Использование гранулярных данных (минимально необходимые данные без передачи всей модели) позволяет делиться только нужной информацией【6】.
• Применение ролевого доступа и шифрования при передаче данных.
  Как такой подход может способствовать регенеративному дизайну и циркулярности?
• Анализ данных жизненного цикла материалов позволяет минимизировать отходы и повторно использовать конструкции.
• Структурированные данные помогают моделировать энергопотребление зданий и снижать выбросы CO2【7】.
• BIM + Open Data позволяют легко анализировать устаревшие проекты для повторного использования.
  Можно ли упростить комплексное выполнение проекта (IPD) с помощью этих методов?
• Автоматизация QTO (Quantity Take-Off) и расчетов затрат снижает количество ошибок【7】.
• Единые базы данных (Data Lakes) позволяют всем участникам проекта работать с актуальной информацией.
• Использование Pandas/SQL и простых дашбордов заменяет сложные ERP-системы.
  Как можно интегрировать агентский подход в эти рабочие процессы?
• Использование LLM (Large Language Models) для автоматического анализа данных и подготовки отчетов【6】.
• Интеллектуальные чат-боты могут помогать инженерам запрашивать данные естественным языком.
• Внедрение "агентных" ETL-процессов, где модели ИИ работают с проектными данными.
  Могут ли графовые базы данных помочь нам визуализировать цепочку мыслей и лучше понять суть?
• Да, графовые базы (Neo4j) хорошо подходят для анализа взаимосвязей в BIM-моделях и цепочках поставок.
• Визуализация проектных зависимостей через графовые структуры может упростить анализ рисков и планирование.
  Возможно ли использовать локальную, самостоятельно размещаемую модель вместо того, чтобы полагаться на большие языковые модели, такие как ChatGPT?
• Да, можно развернуть Llama 2, Mistral, GPT4All на локальном сервере.
• Для работы с данными в строительстве достаточно легковесных моделей + Pandas + SQL.
• Локальные модели лучше для конфиденциальных данных и офлайн-анализа【7】.
•   Для малых и средних фирм – используйте открытые форматы данных (IFC, CSV), автоматизацию ETL и общие DataFrames для эффективного обмена.
•   Обмен данными и безопасность – локальные базы (DuckDB, SQLite), гранулярные данные и шифрование.
•   Регенеративный дизайн – анализ жизненного цикла материалов, CO2-расчеты, повторное использование конструкций.
•   Упрощение IPD – автоматизация QTO, Data Lakes и замена сложных ERP-систем легкими дашбордами.
•   Агентский подход – LLM-модели для анализа данных, чат-боты для BIM, интеллектуальные ETL-процессы.
•   Графовые базы – визуализация BIM-зависимостей и анализ проектных рисков (Neo4j).
•   Локальные модели – Llama 2, Mistral, GPT4All для конфиденциальных данных и офлайн-анализа.
• Исследователи ИИ часто закладывают в системы заранее запрограммированные знания. Это кажется хорошей идеей: сначала всё работает, приносит быстрые результаты и удовлетворение. Но со временем такой подход приводит к застою, потому что система ограничена тем, что в неё вложили.
• Настоящие прорывы происходят не благодаря ручному программированию, а через масштабирование вычислений, обучение на огромных данных и поиск оптимальных решений. Этот успех даётся нелегко, потому что противоречит привычному, человеко-центричному взгляду на развитие ИИ.

• Когда мало инструментов можно продавать, но когда их тысячи или миллионы - то здесь всё превращается в консалтинг. Все БИМ консалтеры превратятся в консалтеров, которые будут создавать приложения

• Не делайте акцент на создание супер приложения с попыткой 



REV ЗАКЛЮЧЕНИЕ
Люди в оседлый период времени - перешли на глобальный Хом офисе в глобальном масштабе.
Если организации хотят принять менталитет, ориентированный на данные, - если должна быть создана корпоративная культура, которая понимает и почитает данные, - то глубокое понимание данных должно быть заложено в навыках и характеристиках всех сотрудников на всех уровнях, особенно внутри бизнеса.
-Accenture3 найти ссылку
Записи на глиняных табличках ознаменовали начало эры данных в строительной отрасли, а персональные компьютеры и развитие Интернета принесли в строительную отрасль лавину оцифрованных данных. Массы этой информации, появившиеся за последнее десятилетие, проложат путь к неизбежному развитию темы автоматизации и роботизации в строительной отрасли. В современном мире, где информация проникает во все сферы жизни, строительная отрасль стоит на пороге кардинальных перемен. 

   Рисунок 4.5-16. Качественные и структурированные исторические данные компании — это материал для создания эффективного бизнеса
Данные и процессы во всех видах экономической деятельности человека ничем не отличаются от того, с чем приходится иметь дело профессионалам в строительной отрасли. Эра открытых данных и автоматизации неизбежно изменит строительный бизнес так же, как это уже произошло в банковской сфере, торговле, сельском хозяйстве и логистике. В этих отраслях роль посредников и традиционные способы ведения бизнеса уступают место автоматизации и роботизации, не оставляя места для неоправданных наценок и спекуляций. 
В перспективе строительная компания, которая сегодня доминирует на рынке, устанавливая стандарты цен и качества услуг, может потерять свою роль ключевого посредника между заказчиком и его строительным проектом.




   Рисунок 4.5-17. Заказчик в строительной отрасли с большей вероятностью станет доверять решениям, основанным на данных 
В этой книге мы рассмотрели основные концепции работы с данными, с которыми сталкиваются сегодня и будут сталкиваться в будущем специалисты, работающие в строительной отрасли. Мы узнали, как собирать данные, создавать требования к данным и проверять их качество. Мы подробно рассмотрели основные примеры использования данных в строительной отрасли и изучили вопросы калькуляции затрат и планирования работ, а также работу строительных ERP-систем, которые являются ключевыми для управления процессами в компаниях строительной отрасли.
Мы узнали об основных тенденциях в обработке данных, которые уже актуальны в различных отраслях и которые только намечаются к применению в строительстве. Мы научились визуализировать и анализировать данные с помощью различных методов и инструментов. Мы также уделили внимание автоматизации процессов с помощью инструментов ChatGPT и Pipeline и рассмотрели применение машинного обучения и прогностических моделей в строительных проектах.

Изучив методы, принципы и инструменты, представленные в этой книге, вы сможете начать принимать в своей компании решения, основанные на данных, а не на интуиции или запустить в ChatGPT цепочку модулей кода, которые будут обрабатывать данные, генерируя нужную вам информацию в нужном формате. А в будущем вы, возможно, сможете реализовать сценарии, описанные в этой книге, для извлечения новой информации для вашего проекта, используя методы машинного обучения и данные из прошлых проектов.
Готовность брать знания и применять их на практике - ключ к успеху в эпоху цифровой трансформации.
Использование роботизации, автоматизации процессов и прогнозирования обещает строительной отрасли стать более автономной и менее зависимой от человеческого фактора. Движение от идеи к готовому зданию, напоминающее движение на автопилоте без водителя в лице строительной компании и навигатора с картой в лице проектной компании, обещает стать независимым от спекуляций и неопределенности. 
Открытые данные и процессы станут основой для более точных оценок стоимости и сроков реализации проектов, лишая строительные компании возможности спекулировать на непрозрачных данных. Это одновременно и вызов, и возможность для отрасли переосмыслить свою роль и адаптироваться к новой среде, где прозрачность и эффективность станут ключевыми факторами успеха.
Многим придется изменить привычный образ мышления, а для этого нужен стимул. Ваша компания должна пересмотреть свой подход к обмену данными.
Спасибо, что вы готовы к переменам. Добро пожаловать в новую эру!























Данные как главный двигатель технологий
Еще в античные времена римские строители использовали математические расчеты для возведения акведуков и дорог. В Средние века архитекторы готических соборов стремились к точным пропорциям, опираясь на геометрию и законы статики. В эпоху индустриализации появились стандартизированные строительные нормы, а вместе с ними — стремление к точности в расчетах нагрузок, устойчивости конструкций и сроков строительства.
Сегодня строительство вступает в новую фазу, где измерения выходят за пределы традиционной геометрии. Датчики на стройплощадках фиксируют вибрации, влажность и температурные колебания, анализируя состояние зданий в реальном времени. Искусственный интеллект прогнозирует сроки сдачи объектов, опираясь на массивы данных. Лазерное сканирование и цифровые двойники позволяют проектировать и управлять зданиями с беспрецедентной точностью.
Как говорил лорд Кельвин, «измерять — значит знать». В строительстве это означает, что доступ к данным — не просто инструмент, а ключевой фактор успеха, влияющий на безопасность, эффективность и устойчивость проектов.



Современные компании строят свои IT-системы вокруг приложений. Каждую бизнес-задачу — будь то автоматизация отчетов или управление клиентами — решают с помощью нового приложения или системы приложений. Эти решения могут быть разработаны с нуля, куплены или арендованы в облаке, но суть одна: каждое такое решение создаёт свою собственную модель данных и работает по своим правилам. В результате данные разрастаются в виде изолированных «островов» или «силосов». Со временем в крупных компаниях таких разрозненных систем становится тысячи, усложняя работу и замедляя изменения.
Раньше в строительстве ключевым приоритетом была точность. Ограниченные данные требовали скрупулезных расчетов — каждый миллиметр на чертеже, каждая тонна бетона учитывались с предельной внимательностью. Но с приходом больших данных акцент смещается: важнее не абсолютная точность в отдельных элементах, а способность видеть всю картину целиком.

Теперь можно анализировать не только точечные показатели, но и их динамику во времени. Например, вместо того чтобы точно фиксировать, сколько бетона ушло на каждый этаж, можно отслеживать общий темп строительства и прогнозировать задержки. Вместо жесткого контроля каждого поставщика можно выявлять закономерности в цепочках поставок и оптимизировать их.

Этот подход напоминает картину импрессиониста: вблизи мазки кажутся хаотичными, но отойдя на шаг, мы видим целостное произведение. Так же и в строительстве — переход от строго детализированного контроля к анализу больших массивов данных помогает глубже понимать процессы и принимать более взвешенные решения.





Однако, несмотря на развитие ERP-систем и их интеграцию с новыми инструментами, компании столкнулись с серьезной проблемой – рост сложности самих систем опережал их полезность. Первоначальная идея создания единой платформы, охватывающей все бизнес-процессы, привела к чрезмерной централизации, где любые изменения требовали значительных ресурсов и времени на адаптацию.
В результате многие компании, стремясь повысить гибкость, начали использовать дополнительные специализированные приложения, что привело к фрагментации данных. Информация, которая должна была быть легко доступной в рамках одной системы, на практике оказывалась распределенной между множеством несовместимых инструментов. Это усложнило управление данными, привело к дублированию информации и замедлило процессы принятия решений.
И если тысячелетиями инженерам в строительной отрасли для управления проектом требовались лишь глиняные таблички или листы бумаги, то в современную эпоху специалисты компаний работают с различными цифровыми системами, базами данных и разными формами и форматами данных, требующими взаимной интеграции и координации. Из этой кооперации и рождаются процессы, на которых и строится бизнес вокруг строительного проекта.


   
Данные — новое золото в строительстве
В строительной отрасли идет настоящая «золотая лихорадка» — охота за ценностью, скрытой в данных. Вместо традиционного поиска причинно-следственных связей компании переходят к анализу корреляций, выявляя неожиданные зависимости и тренды.
Каждый проект, каждый отчет, каждый датчик на стройплощадке содержит данные, которые могут повысить эффективность:
✔ Сокращение простоев — анализ графиков работ и поставок помогает предсказывать задержки и устранять их заранее.
✔ Минимизация брака — алгоритмы выявляют факторы, повышающие риск ошибок, до их возникновения.
✔ Оптимизация затрат — обработка данных из предыдущих проектов позволяет точнее прогнозировать бюджеты.
Сейчас разгорается гонка: кто первым научится правильно интерпретировать строительные данные, тот получит преимущество.
Данные похожи на айсберг: на поверхности видна лишь малая часть их потенциала, тогда как основная ценность скрыта в глубине. Компании, которые умеют извлекать эту скрытую информацию, получают значительное преимущество. Важно оценивать данные не только по их текущему использованию, но и по возможностям, которые они откроют в будущем.
Многие компании сидят на неиспользованных информационных «гейзерах» — огромных массивах данных, которые когда-то были собраны, использованы один раз (или вовсе не использованы) и просто хранятся из-за низкой стоимости хранения. Ученые называют такие архивы «гробницами данных» — местами, где ценная информация лежит без движения.
В строительстве это особенно заметно: тысячи проектов в закрытых форматах DWG, RVT или IFC пылятся на серверах компаний, кажущиеся бесполезным грузом. Но на самом деле эти данные — ключ к анализу прошлых ошибок, автоматизации процессов и созданию новых решений. Главное — научиться их извлекать и использовать.


Способы управления строительными проектами стремительно меняются, превращаясь в поток прогнозов, основанных на анализе больших данных. Всё чаще решения принимаются не людьми, а алгоритмами, которые выявляют скрытые закономерности. Но готовы ли мы доверять процессам, которые невозможно объяснить привычной логикой?

Автоматизированные системы уже определяют оптимальные сроки строительства, перераспределяют ресурсы и даже рекомендуют материалы без участия человека. Искусственный интеллект анализирует миллионы факторов и предлагает решения, которые кажутся интуитивно неверными, но на практике оказываются эффективными.
Если врач может полагаться на диагноз, поставленный алгоритмом, не понимая его логики, то как это повлияет на строительную отрасль? Смогут ли инженеры и архитекторы доверять системе, которая предлагает изменить проект, основываясь лишь на вероятностных моделях? Границы между расчетом и интуицией стираются, а вместе с ними меняются и принципы управления строительными процессами.
Строительная отрасль, как и весь мир, переживает переход к эпохе тотального анализа данных. То, что раньше не поддавалось измерению — вариативность материалов, сложные взаимодействия подрядчиков, влияние погоды на строительные процессы — теперь превращается в точные прогнозные модели. Вместо поиска причинно-следственных связей инженеры всё чаще опираются на корреляции, где важен не ответ на вопрос «почему», а точность предсказания «что будет».
Это меняет саму природу решений: алгоритмы предлагают варианты, которые кажутся нелогичными с точки зрения опыта, но подтверждаются статистикой. Проектирование и управление стройкой всё больше зависят от машинного обучения, а человеческая интуиция отступает перед математически выверенными расчетами.
Но остаётся главный вопрос: если интуиция, опыт и даже риск становятся второстепенными, как сохранить место для творчества, свободы инженерных решений и гибкости в ситуациях, когда данных недостаточно? Где проходит грань между прогрессом и слепой верой в алгоритмы?
Эра больших данных приносит в строительную отрасль три ключевых сдвига в мышлении, которые взаимосвязаны и усиливают друг друга.
Во-первых, теперь можно анализировать не отдельные показатели, а огромные массивы информации — от датчиков на стройплощадке до исторических данных по проектам. Это позволяет видеть полную картину, а не отдельные фрагменты.
Во-вторых, точность уступает место реальной вариативности. Вместо стремления к идеальному порядку инженеры учатся работать с неполными, хаотичными данными, извлекая из них полезные закономерности.
В-третьих, на смену поиску жестких причинно-следственных связей приходит анализ корреляций. Мы больше не спрашиваем, почему возникает задержка или перерасход бюджета — мы просто знаем, что она происходит при определенных условиях и можем заранее её предотвратить.


ОБ АВТОРЕ

Меня зовут Артем Бойко. Мой путь в строительной отрасли начался с работы шахтёром после окончания Санкт-Петербургского горного университета по специальности "Шахтное и подземное строительство. Моя карьера развивалась по разным направлениям, от горнорабочего на сланцевой шахте до монтажника лифтов и промышленного альпиниста. Мне выпала честь работать на самых разных проектах, от строительства частных домов до крупных промышленных объектов в нескольких странах мира.
С 2013 года моя карьера перешла от строительства к планированию и управлению данными. Я работал на различных должностях в малых, средних и крупных строительных компаниях в Центральной Европе, от проектировщика до менеджера по управлению данными. Что касается управления данными, мой опыт заключается в работе с данными в различных системах, таких как ERP, САПР (BIM), MEP, FEM. Я занимался оптимизацией и автоматизацией процессов, а также анализом и обработкой данных на этапах планирования, расчетов и выполнения строительных работ в компаниях, занимающихся строительством промышленных, жилых, инфраструктурных и коммунальных объектов.
Мой вклад в профессиональное сообщество выражается в участии в роли докладчика на конференциях, охватывающих вопросы САПР (BIM), noBIM, ERP, 5D и искусственного интеллекта, а также в статьях, опубликованных в европейских изданиях, посвященных строительной отрасли. Одним из моих заметных достижений является создание "Истории BIM" [40], всеобъемлющей карты важных программных решений для управления данными в строительной отрасли. Моя серия статей из 7 частей "Развитие BIM и лоббистские игры" получила широкое признание и была переведена на несколько языков.
Моя страсть к повышению доступности данных в строительной отрасли нашла отражение в создании нескольких стартапов, предлагающих решения по обеспечению доступности данных из различных закрытых систем и решений.
Большое спасибо, что дочитали эту книгу до конца! Я буду рад, если эта книга поможет вам лучше понять тему данных в строительной отрасли.






ОТЗЫВЫ ЧИТАТЕЛЕЙ

Я всегда рад отзывам моих читателей. Мне бы очень хотелось узнать, что вы думаете об этой книге - что вам понравилось, а что нет. Ваши отзывы очень важны для меня, так как они помогают мне писать статьи и создавать книги, которые 
будут действительно ценными для вас.
Чтобы прислать мне свои мысли или критику, просто 
напишите по адресу boikoartem@gmail.com. 
или отправьте мне сообщение на LinkedIn: https://www.linkedin.com/in/boikoartem/  

Я буду чрезвычайно признателен за любые упоминания о книге Data-Driven Construction в социальных сетях - обмен опытом чтения помогает распространять информацию и оказывает огромную поддержку моей работе. 





ССЫЛКИ

Bibliography

[1] J. A. Wheeler, "Information, physics, quantum: the search for links," 1990. 



1. Сьюзан Д. Гиллеспи, "Глина: запутанность Земли в эпоху глины", URL: https://ufl.pb.unizin.org/imos/chapter/clay/ (дата обращения: 5 февраля 2024 г.).
2. "Папирус III века до н. э. Египетский музей, Каир. Язык - греческий", URL: https://www.facebook.com/429710190886668/posts/595698270954525 (дата обращения: 5 февраля 2024 г.).
3. Иэн Маккью, "История ERP", URL: https://www.netsuite.com/portal/resource/articles/erp/erp-history.shtml (дата обращения: 5 февраля 2024 г.).
4. Бернард Марр, "Сколько данных мы создаем каждый день? The Mind-Blowing Stats Everyone Should Read", URL: https://www.forbes.com/sites/bernardmarr/2018/05/21/how-much-data-do-we-create-every-day-the-mind-blowing-stats-everyone-should-read (дата обращения: 5 февраля 2024 г.).
5. Graduate Programs, "Сколько данных производится каждый день?". Northeastern University, URL: https://graduate.northeastern.edu/resources/how-much-data-produced-every-day/ (дата обращения: 5 февраля 2024 г.).
6. Том Салливан, "ИИ и глобальная "датасфера": сколько информации будет у человечества к 2025 году?", URL: https://www.datauniverseevent.com/en-us/blog/general/AI-and-the-Global-Datasphere-How-Much-Information-Will-Humanity-Have-By-2025.html (дата обращения: 5 февраля 2024 г.).
7.  Cloud.Google, "Примеры ценообразования", URL: https://cloud.google.com/storage/pricing-examples (дата обращения: 5 февраля 2024 г.).
8. Stackoverflow, "Stack Overflow Developer Survey 2023", URL: https://survey.stackoverflow.co/2023/ (accessed February 5, 2024).
9. Википедия, "SQL", URL: https://en.wikipedia.org/wiki/SQL (дата обращения: 5 февраля 2024 г.).
10. Артем Бойко, "Lobbykriege um Daten im Bauwesen | Techno-Feudalismus und die Geschichte von BIMs", URL: https://youtu.be/S-TNdUgfHxk?si=evM_v28KQbGOG0kI&t=1360 (accessed 5 February 2024).
11. White Paper, "Building Information Modeling", URL: https://www.laiserin.com/features/bim/autodesk_bim.pdf (дата обращения: 5 февраля 2024 г.).
12. Артем Бойко, "Лоббистские войны и развитие BIM. Часть 5: BlackRock - мастер всех технологий. Как корпорации контролируют открытый исходный код", URL:
https://boikoartem.medium.com/lobbyist-wars-and-the-development-of-bim-d72ad0111a7d (accessed February 5, 2024).
13. Артем Бойко, "Лоббистские войны и развитие BIM. Часть 2: открытый BIM VS закрытый BIM. Европа VS остальной мир", URL:
https://bigdataconstruction.com/lobbyist-wars-and-the-development-of-bim-part-2-open-bim-vs-closed-bim-revit-vs-archicad-and-europe-vs-the-rest-of-the-world/ (accessed February 5, 2024).
14. Thomas Krijnen, Jakob Beetz, "A SPARQL query engine for binary-formatted IFC building models", URL: https://www.sciencedirect.com/science/article/abs/pii/S092658051731049X (accessed February 5, 2024).
15, Мэри Шеклетт, "Структурированные и неструктурированные данные: Ключевые различия", URL: https://www.datamation.com/big-data/structured-vs-unstructured-data/ (дата обращения: 5 февраля 2024 г.).
16. IBM Cloud Education, "Структурированные и неструктурированные данные: What's the Difference?", URL: https://www.ibm.com/blog/structured-vs-unstructured-data/ (дата обращения: 5 февраля 2024 г.).
17. Крейг Вулард, "Осмысление роста неструктурированных данных", URL: https://automationhero.ai/blog/making-sense-of-the-rise-of-unstructured-data/ (дата обращения: 5 февраля 2024 г.).
18. PePy, "Python Packages Download Stats", https://www.pepy.tech/projects/pandas (дата обращения: 5 февраля 2024 г.).
19. Роман Орак, "Как обработать DataFrame с миллионами строк за секунды", URL: https://towardsdatascience.com/how-to-process-a-dataframe-with-millions-of-rows-in-seconds (дата обращения: 5 февраля 2024 г.).
20. Çağlar Uslu, "What is Kaggle?", URL: https://www.datacamp.com/blog/what-is-kaggle (дата обращения: 5 февраля 2024 г.).
21. Open Design Alliance, "Members: Основатели и корпоративные члены", URL: https://www.opendesign.com/member-showcase (дата обращения: 5 февраля 2024 г.).
22. G Hammond, 'Embodied Carbon - The Inventory of Carbon and Energy (ICE)', URL: https://greenbuildingencyclopaedia.uk/wp-content/uploads/2014/07/Full-BSRIA-ICE-guide.pdf (доступ получен 5 февраля 2024 г.).
23. GitHub DataDrivenConstruction, "CO2_calculating the embodied carbon", URL:
https://github.com/datadrivenconstruction/CO2_calculating-the-embodied-carbon (accessed February 5, 2024).
24. Statista, "Количество предприятий в строительном секторе в Великобритании в 2021 году, по размеру предприятия", URL:
https://www.statista.com/statistics/677151/uk-construction-businesses-by-size/ (accessed February 5, 2024).
25. Forge, "Flex token cost", URL: https://www.autodesk.com/buying/flex?term=1-YEAR&tab=flex (дата обращения: 5 февраля 2024 г.).
26. Артем Бойко, "Забудьте о BIM и демократизируйте доступ к данным", 17. Kolloquium Investor - Hochschule - Bauindustrie, URL: https://www.bim.bayern.de/wp-content/uploads/2023/06/Kolloquium-17-TUM-Bauprozessmanagment-und-Bay-Bauindustrie.pdf  
27. Джефф Хилл, Джоди Фолдези, Сантьяго Феррер, Марк Фридман, Эндрю Лох и Фрэнк Плашке, "Решение загадки производительности строительной отрасли", URL: https://www.bcg.com/publications/2015/engineered-products-project-business-solving-construction-industrys-productivity-puzzle (дата обращения: 5 февраля 2024 г.).
28. Беннет Сайферс и Кори Доктороу, "Конфиденциальность без монополии: Защита данных и совместимость", URL: https://www.eff.org/wp/interoperability-and-privacy (дата обращения: 5 февраля 2024 г.).
29. Артем Бойко, "Сан-Франциско. Строительный сектор 1980-2019" URL: https://www.kaggle.com/search?q=San+Francisco.+Building+sector+1980-2019. (дата обращения: 5 февраля 2024 г.).
30. Артем Бойко, "Kaggle: RVT IFC Files 5000 Projects", URL: https://www.kaggle.com/datasets/artemboiko/rvtifc-projects (accessed February 5, 2024).
31. DataDrivenConstruction, Convertors, URL: https://datadrivenconstruction.io/index.php/convertors/ (accessed February 5, 2024).
32. "5000 проектов IFC&RVT | DataDrivenConstruction.io", URL: https://www.kaggle.com/code/artemboiko/5000-projects-ifc-rvt-datadrivenconstruction-io (дата обращения: 5 февраля 2024 г.).


33. Изабелла Дайнингер, Бернд Кох, Ральф Баукнехт, Матиас Лангханс, "Использование цифровых моделей для декарбонизации производственной площадки: Пример соединения модели здания, производственной модели и энергетической модели", TU München, URL: https://www.researchgate.net/publication/374023998_Using_Digital_Models_to_Decarbonize_a_Production_Site_A_Case_Study_of_Connecting_the_Building_Model_Production_Model_and_Energy_Model (дата обращения: 5 февраля 2024 г.).
34. DataDrivenConstruction, "Трубопровод в строительстве", URL: https://datadrivenconstruction.io/index.php/pipeline-in-construction/ (дата обращения: 5 февраля 2024 г.).
35. Plant Fossils, "Conditions Required for Plant Fossil Preservation", Berkeley Lab, URL: https://ucmp.berkeley.edu/IB181/VPL/Pres/PresTitle.html (доступ получен 5 февраля 2024 г.).
36. Артем Бойко, "Лоббистские войны и развитие BIM. Часть 5: BlackRock - мастер всех технологий. Как корпорации контролируют открытый исходный код", URL:
https://bigdataconstruction.com/autodesk-oracle-blackrock-open-source/ (accessed February 5, 2024).
37. Bloomberg, "Финк из BlackRock об облигациях, слияниях и поглощениях, рецессии в США, выборах: Full Interview", URL: https://www.bloomberg.com/news/videos/2023-09-29/blackrock-s-fink-on-m-a-recession-election-full-intv-video (accessed February 5, 2024).
38. Шрея Йохри, "Создание ChatGPT: От данных к диалогу", URL: https://sitn.hms.harvard.edu/flash/2023/the-making-of-chatgpt-from-data-to-dialogue/ (дата обращения: 5 февраля 2024 г.).
39. Педро Домингос, "Несколько полезных вещей, которые нужно знать о машинном обучении", URL: https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf (дата обращения: 5 февраля 2024 г.).
40. Артем Бойко, "Карта истории BIM", URL: https://bigdataconstruction.com/history-of-bim/ (дата обращения: 5 февраля 2024 г.).





РЕКЛАМНЫЕ ВОЗМОЖНОСТИ 
У вас есть возможность использовать решения и материалы DataDrivenConstruction для распространения информации о вашем продукте. Ваша реклама может быть интегрирована в бесплатные инструменты DataDrivenConstruction и в эту книгу, чтобы охватить широкую аудиторию профессионалов в области строительства.

ПОДДЕРЖИТЕ СВОЙ УСПЕХ
DataDrivenConstruction — это платформа, где технологии встречаются с творчеством, а инновации поощряются. Мы приглашаем вас стать частью нашей сети и использовать наши рекламные возможности для дальнейшего развития вашего бизнеса и бренда.






СООБЩЕСТВА DDC
Присоединяйтесь к сообществу DataDrivenConstruction, где вы найдете открытые и бесплатные советы и инструменты, способные преобразить ваш бизнес с помощью данных. Это место, где вы можете свободно задавать вопросы и делиться своими проблемами и решениями. Каждый член нашего сообщества ценен, и мы особенно приветствуем ваши идеи и отзывы:
DataDrivenConstruction.io: https://datadrivenconstruction.io  
DDC LinkedIn: https://www.linkedin.com/company/datadrivenconstruction/  
Twitter: https://twitter.com/datadrivenconst
Телеграмм DDC: https://t.me/datadrivenconstruction
DDC YouTube: https://www.youtube.com/@datadrivenconstruction  

Вместе мы сможем добиться большего!








2 | DATA-DRIVEN CONSTRUCTION







3 | DATA-DRIVEN CONSTRUCTION

3 | DATA-DRIVEN CONSTRUCTION







